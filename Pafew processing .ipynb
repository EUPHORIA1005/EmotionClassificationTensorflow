{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8778ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.signal import medfilt\n",
    "from scipy.signal import wiener\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "genders = ['male', 'female']\n",
    "labels = ['Happy', 'Surprise', 'Disgust', 'Angry', 'Fear', 'Sad', 'Neutral'] # 0-6, 7 classes\n",
    "\n",
    "def preprocess_data(dataPath, train):\n",
    "    if train:\n",
    "        path = os.path.join(dataPath, 'train')\n",
    "        output_dir = os.path.join(dataPath, 'train.csv')\n",
    "    else:\n",
    "        path = os.path.join(dataPath, 'val')\n",
    "        output_dir = os.path.join(dataPath, 'val.csv')\n",
    "    folders = glob.glob(os.path.join(path, '*'))\n",
    "    folders.sort()\n",
    "\n",
    "    with open(output_dir, 'a+') as csv_output_file:\n",
    "        fieldnames = ['User', 'Person_min', 'Max', 'Min', 'Mean', 'Var', 'Mean Abs Diff', 'Mean Abs Second Diff', 'Emotion', 'Gender', 'Age'] # The features extracted\n",
    "        writer = csv.DictWriter(csv_output_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for dir in folders:\n",
    "            with open(os.path.join(dir, 'EDA.csv')) as csv_file:\n",
    "                csv_reader = csv.reader(csv_file)\n",
    "                line_count = 0\n",
    "                data = [] # all data for one person\n",
    "                time_stamp = [] # time stamp for each item\n",
    "\n",
    "                for row in csv_reader:\n",
    "                    if line_count == 0:\n",
    "                        start_time = float(row[0])\n",
    "                    elif line_count == 1:\n",
    "                        freq = float(row[0])\n",
    "                    elif line_count>2 :\n",
    "                        data.append(float(row[0]))\n",
    "                        time_stamp.append(start_time + float((line_count-2)/freq))\n",
    "                    line_count += 1\n",
    "\n",
    "                #person_Max = max(data)\n",
    "                #person_Min = min(data)\n",
    "                data = (data - np.average(data)) / (np.std(data)) # standartization filter\n",
    "                #data = (np.array(data) - float(person_Min)) / (float(person_Max) - float(person_Min)) # normalised data for each person\n",
    "                #data = medfilt(data, 11) # median filter; can be substituted by your preprocessing methods\n",
    "                #data = wiener(data)\n",
    "                #data = savgol_filter(data, 11, 5)\n",
    "                person_Max = max(data)\n",
    "                person_Min = min(data)\n",
    "                \n",
    "            \n",
    "                log = open(os.path.join(dir, 'log.txt'), 'r')\n",
    "                log_count = 0\n",
    "                for line in log:\n",
    "                    if log_count == 0:\n",
    "                        user = line.split(';')[0].split(':')[-1]\n",
    "                        age = line.split(';')[1].split(':')[-1]\n",
    "                        gender = line.split(';')[2].split(':')[-1]\n",
    "                        gender = genders.index(gender.lower())\n",
    "                        log_count += 1\n",
    "                    elif log_count == 1:\n",
    "                        log_count += 1\n",
    "                    else:\n",
    "                        st = float(line.split(';')[1]) # start time of each video\n",
    "                        et = float(line.split(';')[3]) # end time of each video\n",
    "                        video_name = line.split(';')[2]\n",
    "                        if \"_\" in video_name:\n",
    "                            emotion_label = line.split(';')[2].split('.')[0][:-10] # emotion label of each video\n",
    "                        else:\n",
    "                            emotion_label = line.split(';')[2].split('.')[0][:-9]  # emotion label of each video\n",
    "                        emotion_label = labels.index(emotion_label)\n",
    "\n",
    "                        index = np.where(np.logical_and((np.array(time_stamp) >= st), (np.array(time_stamp) <= et)))\n",
    "                        data_list = data[index[0]]\n",
    "                        if len(data_list)== 0:\n",
    "                            break\n",
    "                        diff_list = [data_list[k+1]-data_list[k] for k in range(len(data_list)-1)]\n",
    "                        abs_diff_list = abs(np.array(diff_list))\n",
    "                        second_diff_list = [diff_list[k + 1] - diff_list[k] for k in range(len(diff_list) - 1)]\n",
    "                        abs_second_diff_list = abs(np.array(second_diff_list))\n",
    "                        writer.writerow({'User': user, 'Person_min': person_Min,  'Max': max(data_list), 'Min': min(data_list), 'Mean': np.mean(data_list), 'Var': np.var(data_list), 'Mean Abs Diff': np.mean(abs_diff_list), 'Mean Abs Second Diff': np.mean(abs_second_diff_list),'Emotion': emotion_label, 'Gender': gender, 'Age': age})\n",
    "                log.close()\n",
    "        csv_file.close()\n",
    "    csv_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8285489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and reading dat\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "os.remove('train.csv')\n",
    "preprocess_data('', train=1)\n",
    "os.remove('val.csv')\n",
    "preprocess_data('', train=0)\n",
    "\n",
    "\n",
    "Data_train = pd.read_csv(\"train.csv\", sep = \",\")\n",
    "#Data_train = shuffle(Data_train)\n",
    "#Data_train[Data_train.User == \"Person_25\"].head(10)\n",
    "#Data_train.head(20)\n",
    "\n",
    "Data_val = pd.read_csv(\"val.csv\")\n",
    "#Data_val = shuffle(Data_val)\n",
    "#Data_val[Data_val.User == \"Person_25\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca097b4",
   "metadata": {},
   "source": [
    "# Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22e78213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import seaborn as sns\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(16, 10))\n",
    "# plt.plot(np.arange(0, 1000, 1), Data_train.Mean.iloc[:1000], scaley = 100)\n",
    "# plt.title(\"Mean variations\")\n",
    "# plt.legend([\"y = mean common variation\"])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f27eba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #Max\tMin\tMean\tVar\tMean Abs Diff\tMean Abs Second Diff\tEmotion\n",
    "\n",
    "# sns.set(rc = {'figure.figsize':(16, 10)})\n",
    "# sns.set_theme(style=\"darkgrid\")\n",
    "# sns.scatterplot(data = Data_train, x = \"Mean\", y = Data_train.index, hue = \"Emotion\", palette = \"tab10\", x_bins= 150)\n",
    "# #sns.lineplot(data = Data_train.iloc[:1500], x = Data_train.Mean.iloc[:1500], y = np.arange(0, 1500, 1), hue = \"Emotion\", palette = \"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81e60458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a21b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data_train.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "909a835f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Person_min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Var</th>\n",
       "      <th>Mean Abs Diff</th>\n",
       "      <th>Mean Abs Second Diff</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.225095</td>\n",
       "      <td>-0.980049</td>\n",
       "      <td>-0.831819</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>0.063326</td>\n",
       "      <td>0.114377</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.728419</td>\n",
       "      <td>-0.896161</td>\n",
       "      <td>-0.790007</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.049470</td>\n",
       "      <td>0.084974</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.644532</td>\n",
       "      <td>-0.896161</td>\n",
       "      <td>-0.753136</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>0.054144</td>\n",
       "      <td>0.097866</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.644532</td>\n",
       "      <td>-0.938105</td>\n",
       "      <td>-0.729771</td>\n",
       "      <td>0.003119</td>\n",
       "      <td>0.058719</td>\n",
       "      <td>0.107024</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.560645</td>\n",
       "      <td>-0.770363</td>\n",
       "      <td>-0.650419</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.049434</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.476757</td>\n",
       "      <td>-0.728419</td>\n",
       "      <td>-0.576271</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>0.054527</td>\n",
       "      <td>0.099295</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.434814</td>\n",
       "      <td>-0.644532</td>\n",
       "      <td>-0.519835</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.054760</td>\n",
       "      <td>0.097070</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.267039</td>\n",
       "      <td>-0.476757</td>\n",
       "      <td>-0.329043</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.064822</td>\n",
       "      <td>0.103861</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.225095</td>\n",
       "      <td>-0.392870</td>\n",
       "      <td>-0.301751</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.049434</td>\n",
       "      <td>0.083887</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.225095</td>\n",
       "      <td>-0.392870</td>\n",
       "      <td>-0.283275</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>0.057323</td>\n",
       "      <td>0.101243</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.183152</td>\n",
       "      <td>-0.476757</td>\n",
       "      <td>-0.302845</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>0.066061</td>\n",
       "      <td>0.121529</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.278196</td>\n",
       "      <td>-0.308983</td>\n",
       "      <td>-0.215626</td>\n",
       "      <td>0.010521</td>\n",
       "      <td>0.083883</td>\n",
       "      <td>0.159090</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.141208</td>\n",
       "      <td>-0.308983</td>\n",
       "      <td>-0.193638</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.047936</td>\n",
       "      <td>0.087588</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.099297</td>\n",
       "      <td>-0.225095</td>\n",
       "      <td>-0.169807</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.049930</td>\n",
       "      <td>0.079690</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.057353</td>\n",
       "      <td>-0.225095</td>\n",
       "      <td>-0.138676</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.056343</td>\n",
       "      <td>0.101445</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          User  Person_min       Max       Min      Mean       Var  \\\n",
       "984  Person_25   -3.161054 -0.225095 -0.980049 -0.831819  0.005871   \n",
       "985  Person_25   -3.161054 -0.728419 -0.896161 -0.790007  0.001863   \n",
       "986  Person_25   -3.161054 -0.644532 -0.896161 -0.753136  0.002122   \n",
       "987  Person_25   -3.161054 -0.644532 -0.938105 -0.729771  0.003119   \n",
       "988  Person_25   -3.161054 -0.560645 -0.770363 -0.650419  0.002002   \n",
       "989  Person_25   -3.161054 -0.476757 -0.728419 -0.576271  0.003171   \n",
       "990  Person_25   -3.161054 -0.434814 -0.644532 -0.519835  0.002138   \n",
       "991  Person_25   -3.161054 -0.267039 -0.476757 -0.329043  0.003040   \n",
       "992  Person_25   -3.161054 -0.225095 -0.392870 -0.301751  0.001950   \n",
       "993  Person_25   -3.161054 -0.225095 -0.392870 -0.283275  0.002120   \n",
       "994  Person_25   -3.161054 -0.183152 -0.476757 -0.302845  0.003395   \n",
       "995  Person_25   -3.161054  0.278196 -0.308983 -0.215626  0.010521   \n",
       "996  Person_25   -3.161054 -0.141208 -0.308983 -0.193638  0.001600   \n",
       "997  Person_25   -3.161054 -0.099297 -0.225095 -0.169807  0.001341   \n",
       "998  Person_25   -3.161054 -0.057353 -0.225095 -0.138676  0.001805   \n",
       "\n",
       "     Mean Abs Diff  Mean Abs Second Diff  Emotion  Gender  Age  \n",
       "984       0.063326              0.114377        2       0   23  \n",
       "985       0.049470              0.084974        2       0   23  \n",
       "986       0.054144              0.097866        2       0   23  \n",
       "987       0.058719              0.107024        2       0   23  \n",
       "988       0.049434              0.081600        2       0   23  \n",
       "989       0.054527              0.099295        2       0   23  \n",
       "990       0.054760              0.097070        2       0   23  \n",
       "991       0.064822              0.103861        6       0   23  \n",
       "992       0.049434              0.083887        6       0   23  \n",
       "993       0.057323              0.101243        6       0   23  \n",
       "994       0.066061              0.121529        6       0   23  \n",
       "995       0.083883              0.159090        6       0   23  \n",
       "996       0.047936              0.087588        6       0   23  \n",
       "997       0.049930              0.079690        6       0   23  \n",
       "998       0.056343              0.101445        6       0   23  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_train[Data_train.User == \"Person_25\"].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66ea7f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Person_min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Var</th>\n",
       "      <th>Mean Abs Diff</th>\n",
       "      <th>Mean Abs Second Diff</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.350926</td>\n",
       "      <td>-0.476757</td>\n",
       "      <td>-0.409106</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.055925</td>\n",
       "      <td>0.095458</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.308983</td>\n",
       "      <td>-0.476757</td>\n",
       "      <td>-0.384915</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.055925</td>\n",
       "      <td>0.089130</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.308983</td>\n",
       "      <td>-0.476757</td>\n",
       "      <td>-0.374634</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.034318</td>\n",
       "      <td>0.063914</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.308983</td>\n",
       "      <td>-0.560645</td>\n",
       "      <td>-0.384804</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.058721</td>\n",
       "      <td>0.096121</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.267039</td>\n",
       "      <td>-0.434814</td>\n",
       "      <td>-0.349480</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.061418</td>\n",
       "      <td>0.100976</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.823431</td>\n",
       "      <td>0.655689</td>\n",
       "      <td>0.756704</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.045935</td>\n",
       "      <td>0.079690</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.823431</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>0.767506</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.039322</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.865375</td>\n",
       "      <td>0.655689</td>\n",
       "      <td>0.754458</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.056240</td>\n",
       "      <td>0.105342</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.865375</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>0.783955</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.039322</td>\n",
       "      <td>0.067110</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.907318</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>0.813444</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.060818</td>\n",
       "      <td>0.105963</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.907318</td>\n",
       "      <td>0.739544</td>\n",
       "      <td>0.834870</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.051930</td>\n",
       "      <td>0.096470</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.865375</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.052430</td>\n",
       "      <td>0.090510</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.907318</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>0.828091</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.051813</td>\n",
       "      <td>0.094373</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>1.494497</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>0.842232</td>\n",
       "      <td>0.017541</td>\n",
       "      <td>0.088379</td>\n",
       "      <td>0.167770</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.907318</td>\n",
       "      <td>0.739544</td>\n",
       "      <td>0.853038</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.068158</td>\n",
       "      <td>0.123035</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          User  Person_min       Max       Min      Mean       Var  \\\n",
       "672  Person_25   -3.161054 -0.350926 -0.476757 -0.409106  0.001893   \n",
       "673  Person_25   -3.161054 -0.308983 -0.476757 -0.384915  0.001969   \n",
       "674  Person_25   -3.161054 -0.308983 -0.476757 -0.374634  0.001350   \n",
       "675  Person_25   -3.161054 -0.308983 -0.560645 -0.384804  0.002980   \n",
       "676  Person_25   -3.161054 -0.267039 -0.434814 -0.349480  0.002364   \n",
       "677  Person_25   -3.161054  0.823431  0.655689  0.756704  0.001864   \n",
       "678  Person_25   -3.161054  0.823431  0.697600  0.767506  0.001137   \n",
       "679  Person_25   -3.161054  0.865375  0.655689  0.754458  0.002514   \n",
       "680  Person_25   -3.161054  0.865375  0.697600  0.783955  0.001753   \n",
       "681  Person_25   -3.161054  0.907318  0.697600  0.813444  0.002497   \n",
       "682  Person_25   -3.161054  0.907318  0.739544  0.834870  0.001788   \n",
       "683  Person_25   -3.161054  0.865375  0.697600  0.817439  0.001723   \n",
       "684  Person_25   -3.161054  0.907318  0.697600  0.828091  0.002519   \n",
       "685  Person_25   -3.161054  1.494497  0.697600  0.842232  0.017541   \n",
       "686  Person_25   -3.161054  0.907318  0.739544  0.853038  0.002849   \n",
       "\n",
       "     Mean Abs Diff  Mean Abs Second Diff  Emotion  Gender  Age  \n",
       "672       0.055925              0.095458        2       0   23  \n",
       "673       0.055925              0.089130        2       0   23  \n",
       "674       0.034318              0.063914        2       0   23  \n",
       "675       0.058721              0.096121        2       0   23  \n",
       "676       0.061418              0.100976        2       0   23  \n",
       "677       0.045935              0.079690        3       0   23  \n",
       "678       0.039322              0.066298        3       0   23  \n",
       "679       0.056240              0.105342        3       0   23  \n",
       "680       0.039322              0.067110        3       0   23  \n",
       "681       0.060818              0.105963        3       0   23  \n",
       "682       0.051930              0.096470        3       0   23  \n",
       "683       0.052430              0.090510        3       0   23  \n",
       "684       0.051813              0.094373        3       0   23  \n",
       "685       0.088379              0.167770        3       0   23  \n",
       "686       0.068158              0.123035        3       0   23  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_val[Data_val.User == \"Person_25\"].head(15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a95ae",
   "metadata": {},
   "source": [
    "####  Data is distributed normally. No NaN values. Sad and happy emotions have more samples than others -> might have to equalize value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e786f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3554, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5291, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging val and train data\n",
    "print(Data_train.shape, Data_val.shape)\n",
    "Data_train = pd.merge(Data_train, Data_val, how = 'outer')\n",
    "Data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7072b73",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08962cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, ReLU\n",
    "from tensorflow.keras.regularizers import L1, L2, L1L2\n",
    "\n",
    "def initModelGRU(shape, outputUnits, outputActivation) -> tf.keras.Model:\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    inputs = tf.keras.Input(shape = (shape))\n",
    "    expand = tf.expand_dims(inputs, axis = 2)\n",
    "                                                            #dropout better than L reg\n",
    "    gru1 = tf.keras.layers.GRU(128, return_sequences = True, recurrent_dropout = 0.25, activation = 'relu')(expand) \n",
    "    flatten = tf.keras.layers.Flatten()(gru1)  \n",
    "                                                        #use softmax for prob distribution!\n",
    "    outputs = tf.keras.layers.Dense(outputUnits, activation = outputActivation)(flatten)    \n",
    "    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "def initModelBasic(shape, outputUnits) -> tf.keras.Model:\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(tf.keras.Input(shape = (shape)))\n",
    "    \n",
    "    model.add(Dense(16, activation = 'linear'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    \n",
    "    model.add(Dense(16, activation = 'linear'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    \n",
    "    model.add(Dense(outputUnits, activation = 'softmax'))\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9176b7a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 9)]               0         \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (None, 9, 1)             0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 9, 128)            50304     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 8071      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,375\n",
      "Trainable params: 58,375\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/600\n",
      "105/105 [==============================] - 5s 19ms/step - loss: 1.9358 - sparse_categorical_accuracy: 0.1816 - val_loss: 1.9213 - val_sparse_categorical_accuracy: 0.2034\n",
      "Epoch 2/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.9292 - sparse_categorical_accuracy: 0.1918 - val_loss: 1.9157 - val_sparse_categorical_accuracy: 0.1914\n",
      "Epoch 3/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.9231 - sparse_categorical_accuracy: 0.1903 - val_loss: 1.9064 - val_sparse_categorical_accuracy: 0.2065\n",
      "Epoch 4/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.9211 - sparse_categorical_accuracy: 0.1978 - val_loss: 1.9078 - val_sparse_categorical_accuracy: 0.2028\n",
      "Epoch 5/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.9203 - sparse_categorical_accuracy: 0.1915 - val_loss: 1.9080 - val_sparse_categorical_accuracy: 0.1996\n",
      "Epoch 6/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.9187 - sparse_categorical_accuracy: 0.1960 - val_loss: 1.9013 - val_sparse_categorical_accuracy: 0.2141\n",
      "Epoch 7/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.9147 - sparse_categorical_accuracy: 0.1963 - val_loss: 1.9023 - val_sparse_categorical_accuracy: 0.2110\n",
      "Epoch 8/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.9142 - sparse_categorical_accuracy: 0.1924 - val_loss: 1.8992 - val_sparse_categorical_accuracy: 0.1984\n",
      "Epoch 9/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.9105 - sparse_categorical_accuracy: 0.2011 - val_loss: 1.9011 - val_sparse_categorical_accuracy: 0.1870\n",
      "Epoch 10/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.9107 - sparse_categorical_accuracy: 0.1918 - val_loss: 1.9029 - val_sparse_categorical_accuracy: 0.2053\n",
      "Epoch 11/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.9058 - sparse_categorical_accuracy: 0.1987 - val_loss: 1.8969 - val_sparse_categorical_accuracy: 0.2059\n",
      "Epoch 12/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.9032 - sparse_categorical_accuracy: 0.2110 - val_loss: 1.8984 - val_sparse_categorical_accuracy: 0.1788\n",
      "Epoch 13/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.9001 - sparse_categorical_accuracy: 0.2014 - val_loss: 1.8877 - val_sparse_categorical_accuracy: 0.2059\n",
      "Epoch 14/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8986 - sparse_categorical_accuracy: 0.2113 - val_loss: 1.8959 - val_sparse_categorical_accuracy: 0.1788\n",
      "Epoch 15/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8940 - sparse_categorical_accuracy: 0.2119 - val_loss: 1.8937 - val_sparse_categorical_accuracy: 0.1870\n",
      "Epoch 16/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8973 - sparse_categorical_accuracy: 0.2038 - val_loss: 1.8950 - val_sparse_categorical_accuracy: 0.1858\n",
      "Epoch 17/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8916 - sparse_categorical_accuracy: 0.2110 - val_loss: 1.8879 - val_sparse_categorical_accuracy: 0.1946\n",
      "Epoch 18/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8888 - sparse_categorical_accuracy: 0.2140 - val_loss: 1.8825 - val_sparse_categorical_accuracy: 0.2110\n",
      "Epoch 19/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8835 - sparse_categorical_accuracy: 0.2272 - val_loss: 1.8855 - val_sparse_categorical_accuracy: 0.1996\n",
      "Epoch 20/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8836 - sparse_categorical_accuracy: 0.2131 - val_loss: 1.8800 - val_sparse_categorical_accuracy: 0.1908\n",
      "Epoch 21/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8828 - sparse_categorical_accuracy: 0.2173 - val_loss: 1.8824 - val_sparse_categorical_accuracy: 0.2015\n",
      "Epoch 22/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8770 - sparse_categorical_accuracy: 0.2233 - val_loss: 1.8793 - val_sparse_categorical_accuracy: 0.2053\n",
      "Epoch 23/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8755 - sparse_categorical_accuracy: 0.2167 - val_loss: 1.8883 - val_sparse_categorical_accuracy: 0.2059\n",
      "Epoch 24/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8762 - sparse_categorical_accuracy: 0.2164 - val_loss: 1.8768 - val_sparse_categorical_accuracy: 0.2147\n",
      "Epoch 25/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8671 - sparse_categorical_accuracy: 0.2236 - val_loss: 1.8969 - val_sparse_categorical_accuracy: 0.2009\n",
      "Epoch 26/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8674 - sparse_categorical_accuracy: 0.2227 - val_loss: 1.8835 - val_sparse_categorical_accuracy: 0.2084\n",
      "Epoch 27/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8667 - sparse_categorical_accuracy: 0.2260 - val_loss: 1.8850 - val_sparse_categorical_accuracy: 0.1958\n",
      "Epoch 28/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8669 - sparse_categorical_accuracy: 0.2203 - val_loss: 1.8751 - val_sparse_categorical_accuracy: 0.2040\n",
      "Epoch 29/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8661 - sparse_categorical_accuracy: 0.2278 - val_loss: 1.8746 - val_sparse_categorical_accuracy: 0.2185\n",
      "Epoch 30/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8605 - sparse_categorical_accuracy: 0.2257 - val_loss: 1.8773 - val_sparse_categorical_accuracy: 0.2059\n",
      "Epoch 31/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8594 - sparse_categorical_accuracy: 0.2239 - val_loss: 1.8744 - val_sparse_categorical_accuracy: 0.2160\n",
      "Epoch 32/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8581 - sparse_categorical_accuracy: 0.2299 - val_loss: 1.8624 - val_sparse_categorical_accuracy: 0.2254\n",
      "Epoch 33/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8581 - sparse_categorical_accuracy: 0.2293 - val_loss: 1.8861 - val_sparse_categorical_accuracy: 0.2110\n",
      "Epoch 34/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8555 - sparse_categorical_accuracy: 0.2224 - val_loss: 1.8617 - val_sparse_categorical_accuracy: 0.2280\n",
      "Epoch 35/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8604 - sparse_categorical_accuracy: 0.2221 - val_loss: 1.8638 - val_sparse_categorical_accuracy: 0.2223\n",
      "Epoch 36/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8498 - sparse_categorical_accuracy: 0.2356 - val_loss: 1.8615 - val_sparse_categorical_accuracy: 0.2236\n",
      "Epoch 37/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8481 - sparse_categorical_accuracy: 0.2374 - val_loss: 1.8611 - val_sparse_categorical_accuracy: 0.2349\n",
      "Epoch 38/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8473 - sparse_categorical_accuracy: 0.2368 - val_loss: 1.8663 - val_sparse_categorical_accuracy: 0.2368\n",
      "Epoch 39/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8419 - sparse_categorical_accuracy: 0.2410 - val_loss: 1.8696 - val_sparse_categorical_accuracy: 0.2141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.8455 - sparse_categorical_accuracy: 0.2404 - val_loss: 1.8647 - val_sparse_categorical_accuracy: 0.2091\n",
      "Epoch 41/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8448 - sparse_categorical_accuracy: 0.2428 - val_loss: 1.8723 - val_sparse_categorical_accuracy: 0.2173\n",
      "Epoch 42/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8399 - sparse_categorical_accuracy: 0.2443 - val_loss: 1.8500 - val_sparse_categorical_accuracy: 0.2380\n",
      "Epoch 43/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8372 - sparse_categorical_accuracy: 0.2323 - val_loss: 1.8616 - val_sparse_categorical_accuracy: 0.2324\n",
      "Epoch 44/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8430 - sparse_categorical_accuracy: 0.2386 - val_loss: 1.8473 - val_sparse_categorical_accuracy: 0.2462\n",
      "Epoch 45/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.8343 - sparse_categorical_accuracy: 0.2455 - val_loss: 1.8535 - val_sparse_categorical_accuracy: 0.2343\n",
      "Epoch 46/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8393 - sparse_categorical_accuracy: 0.2410 - val_loss: 1.8567 - val_sparse_categorical_accuracy: 0.2292\n",
      "Epoch 47/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8282 - sparse_categorical_accuracy: 0.2368 - val_loss: 1.8632 - val_sparse_categorical_accuracy: 0.2198\n",
      "Epoch 48/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8260 - sparse_categorical_accuracy: 0.2446 - val_loss: 1.8470 - val_sparse_categorical_accuracy: 0.2292\n",
      "Epoch 49/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8250 - sparse_categorical_accuracy: 0.2464 - val_loss: 1.8453 - val_sparse_categorical_accuracy: 0.2324\n",
      "Epoch 50/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8280 - sparse_categorical_accuracy: 0.2482 - val_loss: 1.8428 - val_sparse_categorical_accuracy: 0.2324\n",
      "Epoch 51/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8206 - sparse_categorical_accuracy: 0.2548 - val_loss: 1.8463 - val_sparse_categorical_accuracy: 0.2387\n",
      "Epoch 52/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8174 - sparse_categorical_accuracy: 0.2587 - val_loss: 1.8444 - val_sparse_categorical_accuracy: 0.2437\n",
      "Epoch 53/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.8157 - sparse_categorical_accuracy: 0.2608 - val_loss: 1.8431 - val_sparse_categorical_accuracy: 0.2292\n",
      "Epoch 54/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.8096 - sparse_categorical_accuracy: 0.2629 - val_loss: 1.8625 - val_sparse_categorical_accuracy: 0.2487\n",
      "Epoch 55/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8095 - sparse_categorical_accuracy: 0.2554 - val_loss: 1.8743 - val_sparse_categorical_accuracy: 0.2374\n",
      "Epoch 56/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8120 - sparse_categorical_accuracy: 0.2605 - val_loss: 1.8354 - val_sparse_categorical_accuracy: 0.2361\n",
      "Epoch 57/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8047 - sparse_categorical_accuracy: 0.2602 - val_loss: 1.8380 - val_sparse_categorical_accuracy: 0.2361\n",
      "Epoch 58/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8106 - sparse_categorical_accuracy: 0.2584 - val_loss: 1.8378 - val_sparse_categorical_accuracy: 0.2254\n",
      "Epoch 59/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8028 - sparse_categorical_accuracy: 0.2659 - val_loss: 1.8636 - val_sparse_categorical_accuracy: 0.2349\n",
      "Epoch 60/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8039 - sparse_categorical_accuracy: 0.2560 - val_loss: 1.8394 - val_sparse_categorical_accuracy: 0.2387\n",
      "Epoch 61/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.8030 - sparse_categorical_accuracy: 0.2518 - val_loss: 1.8399 - val_sparse_categorical_accuracy: 0.2223\n",
      "Epoch 62/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.8016 - sparse_categorical_accuracy: 0.2557 - val_loss: 1.8287 - val_sparse_categorical_accuracy: 0.2343\n",
      "Epoch 63/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7937 - sparse_categorical_accuracy: 0.2725 - val_loss: 1.8263 - val_sparse_categorical_accuracy: 0.2317\n",
      "Epoch 64/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7923 - sparse_categorical_accuracy: 0.2710 - val_loss: 1.8399 - val_sparse_categorical_accuracy: 0.2292\n",
      "Epoch 65/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.7903 - sparse_categorical_accuracy: 0.2722 - val_loss: 1.8296 - val_sparse_categorical_accuracy: 0.2267\n",
      "Epoch 66/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.7860 - sparse_categorical_accuracy: 0.2719 - val_loss: 1.8292 - val_sparse_categorical_accuracy: 0.2374\n",
      "Epoch 67/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7846 - sparse_categorical_accuracy: 0.2785 - val_loss: 1.8248 - val_sparse_categorical_accuracy: 0.2406\n",
      "Epoch 68/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7873 - sparse_categorical_accuracy: 0.2737 - val_loss: 1.8259 - val_sparse_categorical_accuracy: 0.2273\n",
      "Epoch 69/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.7823 - sparse_categorical_accuracy: 0.2770 - val_loss: 1.8351 - val_sparse_categorical_accuracy: 0.2198\n",
      "Epoch 70/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.7798 - sparse_categorical_accuracy: 0.2725 - val_loss: 1.8257 - val_sparse_categorical_accuracy: 0.2361\n",
      "Epoch 71/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7734 - sparse_categorical_accuracy: 0.2788 - val_loss: 1.8183 - val_sparse_categorical_accuracy: 0.2280\n",
      "Epoch 72/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7759 - sparse_categorical_accuracy: 0.2713 - val_loss: 1.8259 - val_sparse_categorical_accuracy: 0.2563\n",
      "Epoch 73/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7761 - sparse_categorical_accuracy: 0.2797 - val_loss: 1.8153 - val_sparse_categorical_accuracy: 0.2513\n",
      "Epoch 74/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7705 - sparse_categorical_accuracy: 0.2734 - val_loss: 1.8195 - val_sparse_categorical_accuracy: 0.2683\n",
      "Epoch 75/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7698 - sparse_categorical_accuracy: 0.2839 - val_loss: 1.8215 - val_sparse_categorical_accuracy: 0.2317\n",
      "Epoch 76/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7725 - sparse_categorical_accuracy: 0.2872 - val_loss: 1.8232 - val_sparse_categorical_accuracy: 0.2569\n",
      "Epoch 77/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7650 - sparse_categorical_accuracy: 0.2851 - val_loss: 1.8190 - val_sparse_categorical_accuracy: 0.2639\n",
      "Epoch 78/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7657 - sparse_categorical_accuracy: 0.2845 - val_loss: 1.8246 - val_sparse_categorical_accuracy: 0.2475\n",
      "Epoch 79/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7591 - sparse_categorical_accuracy: 0.2878 - val_loss: 1.8170 - val_sparse_categorical_accuracy: 0.2531\n",
      "Epoch 80/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7655 - sparse_categorical_accuracy: 0.2848 - val_loss: 1.8125 - val_sparse_categorical_accuracy: 0.2456\n",
      "Epoch 81/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7595 - sparse_categorical_accuracy: 0.2920 - val_loss: 1.8108 - val_sparse_categorical_accuracy: 0.2588\n",
      "Epoch 82/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7570 - sparse_categorical_accuracy: 0.2842 - val_loss: 1.8052 - val_sparse_categorical_accuracy: 0.2531\n",
      "Epoch 83/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7593 - sparse_categorical_accuracy: 0.2836 - val_loss: 1.8140 - val_sparse_categorical_accuracy: 0.2450\n",
      "Epoch 84/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7521 - sparse_categorical_accuracy: 0.2809 - val_loss: 1.8116 - val_sparse_categorical_accuracy: 0.2387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7506 - sparse_categorical_accuracy: 0.2962 - val_loss: 1.8046 - val_sparse_categorical_accuracy: 0.2645\n",
      "Epoch 86/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7532 - sparse_categorical_accuracy: 0.2860 - val_loss: 1.8124 - val_sparse_categorical_accuracy: 0.2651\n",
      "Epoch 87/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7459 - sparse_categorical_accuracy: 0.2950 - val_loss: 1.8144 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 88/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7447 - sparse_categorical_accuracy: 0.2989 - val_loss: 1.8128 - val_sparse_categorical_accuracy: 0.2607\n",
      "Epoch 89/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7441 - sparse_categorical_accuracy: 0.3001 - val_loss: 1.8135 - val_sparse_categorical_accuracy: 0.2702\n",
      "Epoch 90/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7472 - sparse_categorical_accuracy: 0.2998 - val_loss: 1.8028 - val_sparse_categorical_accuracy: 0.2727\n",
      "Epoch 91/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7438 - sparse_categorical_accuracy: 0.3007 - val_loss: 1.8021 - val_sparse_categorical_accuracy: 0.2550\n",
      "Epoch 92/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7383 - sparse_categorical_accuracy: 0.2995 - val_loss: 1.7892 - val_sparse_categorical_accuracy: 0.2645\n",
      "Epoch 93/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7357 - sparse_categorical_accuracy: 0.3028 - val_loss: 1.7988 - val_sparse_categorical_accuracy: 0.2487\n",
      "Epoch 94/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7307 - sparse_categorical_accuracy: 0.2980 - val_loss: 1.7932 - val_sparse_categorical_accuracy: 0.2613\n",
      "Epoch 95/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7252 - sparse_categorical_accuracy: 0.3091 - val_loss: 1.8022 - val_sparse_categorical_accuracy: 0.2557\n",
      "Epoch 96/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7304 - sparse_categorical_accuracy: 0.2986 - val_loss: 1.8026 - val_sparse_categorical_accuracy: 0.2670\n",
      "Epoch 97/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7214 - sparse_categorical_accuracy: 0.3049 - val_loss: 1.7997 - val_sparse_categorical_accuracy: 0.2739\n",
      "Epoch 98/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7243 - sparse_categorical_accuracy: 0.3076 - val_loss: 1.8018 - val_sparse_categorical_accuracy: 0.2557\n",
      "Epoch 99/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7255 - sparse_categorical_accuracy: 0.3109 - val_loss: 1.7903 - val_sparse_categorical_accuracy: 0.2664\n",
      "Epoch 100/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7218 - sparse_categorical_accuracy: 0.3061 - val_loss: 1.7894 - val_sparse_categorical_accuracy: 0.2802\n",
      "Epoch 101/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7169 - sparse_categorical_accuracy: 0.3022 - val_loss: 1.7896 - val_sparse_categorical_accuracy: 0.2607\n",
      "Epoch 102/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7233 - sparse_categorical_accuracy: 0.2986 - val_loss: 1.7897 - val_sparse_categorical_accuracy: 0.2840\n",
      "Epoch 103/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7229 - sparse_categorical_accuracy: 0.3115 - val_loss: 1.7840 - val_sparse_categorical_accuracy: 0.2865\n",
      "Epoch 104/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.7127 - sparse_categorical_accuracy: 0.3106 - val_loss: 1.7855 - val_sparse_categorical_accuracy: 0.2739\n",
      "Epoch 105/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7099 - sparse_categorical_accuracy: 0.3169 - val_loss: 1.7652 - val_sparse_categorical_accuracy: 0.2601\n",
      "Epoch 106/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7089 - sparse_categorical_accuracy: 0.3115 - val_loss: 1.7876 - val_sparse_categorical_accuracy: 0.2708\n",
      "Epoch 107/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7123 - sparse_categorical_accuracy: 0.3061 - val_loss: 1.7711 - val_sparse_categorical_accuracy: 0.2796\n",
      "Epoch 108/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7122 - sparse_categorical_accuracy: 0.3199 - val_loss: 1.7700 - val_sparse_categorical_accuracy: 0.2708\n",
      "Epoch 109/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7016 - sparse_categorical_accuracy: 0.3184 - val_loss: 1.7721 - val_sparse_categorical_accuracy: 0.2764\n",
      "Epoch 110/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6958 - sparse_categorical_accuracy: 0.3268 - val_loss: 1.7833 - val_sparse_categorical_accuracy: 0.2865\n",
      "Epoch 111/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6978 - sparse_categorical_accuracy: 0.3232 - val_loss: 1.7792 - val_sparse_categorical_accuracy: 0.2815\n",
      "Epoch 112/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7029 - sparse_categorical_accuracy: 0.3199 - val_loss: 1.7624 - val_sparse_categorical_accuracy: 0.2947\n",
      "Epoch 113/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7015 - sparse_categorical_accuracy: 0.3265 - val_loss: 1.7674 - val_sparse_categorical_accuracy: 0.2953\n",
      "Epoch 114/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.7011 - sparse_categorical_accuracy: 0.3178 - val_loss: 1.7650 - val_sparse_categorical_accuracy: 0.2897\n",
      "Epoch 115/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6998 - sparse_categorical_accuracy: 0.3202 - val_loss: 1.7711 - val_sparse_categorical_accuracy: 0.2897\n",
      "Epoch 116/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6889 - sparse_categorical_accuracy: 0.3130 - val_loss: 1.7718 - val_sparse_categorical_accuracy: 0.2764\n",
      "Epoch 117/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6878 - sparse_categorical_accuracy: 0.3196 - val_loss: 1.7630 - val_sparse_categorical_accuracy: 0.2890\n",
      "Epoch 118/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.6820 - sparse_categorical_accuracy: 0.3247 - val_loss: 1.7729 - val_sparse_categorical_accuracy: 0.2783\n",
      "Epoch 119/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.6913 - sparse_categorical_accuracy: 0.3265 - val_loss: 1.7853 - val_sparse_categorical_accuracy: 0.2928\n",
      "Epoch 120/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.6788 - sparse_categorical_accuracy: 0.3277 - val_loss: 1.7620 - val_sparse_categorical_accuracy: 0.2922\n",
      "Epoch 121/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.6777 - sparse_categorical_accuracy: 0.3193 - val_loss: 1.7564 - val_sparse_categorical_accuracy: 0.2909\n",
      "Epoch 122/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.6748 - sparse_categorical_accuracy: 0.3331 - val_loss: 1.7554 - val_sparse_categorical_accuracy: 0.2796\n",
      "Epoch 123/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.6867 - sparse_categorical_accuracy: 0.3202 - val_loss: 1.7554 - val_sparse_categorical_accuracy: 0.2834\n",
      "Epoch 124/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.6807 - sparse_categorical_accuracy: 0.3256 - val_loss: 1.7614 - val_sparse_categorical_accuracy: 0.3004\n",
      "Epoch 125/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6840 - sparse_categorical_accuracy: 0.3307 - val_loss: 1.7405 - val_sparse_categorical_accuracy: 0.2985\n",
      "Epoch 126/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6743 - sparse_categorical_accuracy: 0.3220 - val_loss: 1.7405 - val_sparse_categorical_accuracy: 0.2890\n",
      "Epoch 127/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6710 - sparse_categorical_accuracy: 0.3358 - val_loss: 1.7458 - val_sparse_categorical_accuracy: 0.2953\n",
      "Epoch 128/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6725 - sparse_categorical_accuracy: 0.3280 - val_loss: 1.7543 - val_sparse_categorical_accuracy: 0.2916\n",
      "Epoch 129/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6672 - sparse_categorical_accuracy: 0.3304 - val_loss: 1.7440 - val_sparse_categorical_accuracy: 0.3004\n",
      "Epoch 130/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6588 - sparse_categorical_accuracy: 0.3385 - val_loss: 1.7416 - val_sparse_categorical_accuracy: 0.2935\n",
      "Epoch 131/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6683 - sparse_categorical_accuracy: 0.3376 - val_loss: 1.7484 - val_sparse_categorical_accuracy: 0.3123\n",
      "Epoch 132/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.6532 - sparse_categorical_accuracy: 0.3499 - val_loss: 1.7548 - val_sparse_categorical_accuracy: 0.3060\n",
      "Epoch 133/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.6644 - sparse_categorical_accuracy: 0.3301 - val_loss: 1.7391 - val_sparse_categorical_accuracy: 0.3117\n",
      "Epoch 134/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.6550 - sparse_categorical_accuracy: 0.3418 - val_loss: 1.7511 - val_sparse_categorical_accuracy: 0.3042\n",
      "Epoch 135/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.6663 - sparse_categorical_accuracy: 0.3385 - val_loss: 1.7412 - val_sparse_categorical_accuracy: 0.3161\n",
      "Epoch 136/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.6579 - sparse_categorical_accuracy: 0.3403 - val_loss: 1.7468 - val_sparse_categorical_accuracy: 0.3054\n",
      "Epoch 137/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6443 - sparse_categorical_accuracy: 0.3403 - val_loss: 1.7352 - val_sparse_categorical_accuracy: 0.3136\n",
      "Epoch 138/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.6531 - sparse_categorical_accuracy: 0.3418 - val_loss: 1.7277 - val_sparse_categorical_accuracy: 0.3086\n",
      "Epoch 139/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.6510 - sparse_categorical_accuracy: 0.3355 - val_loss: 1.7346 - val_sparse_categorical_accuracy: 0.3149\n",
      "Epoch 140/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.6573 - sparse_categorical_accuracy: 0.3424 - val_loss: 1.7359 - val_sparse_categorical_accuracy: 0.3004\n",
      "Epoch 141/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.6579 - sparse_categorical_accuracy: 0.3415 - val_loss: 1.7313 - val_sparse_categorical_accuracy: 0.3142\n",
      "Epoch 142/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.6435 - sparse_categorical_accuracy: 0.3466 - val_loss: 1.7394 - val_sparse_categorical_accuracy: 0.3218\n",
      "Epoch 143/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.6495 - sparse_categorical_accuracy: 0.3451 - val_loss: 1.7347 - val_sparse_categorical_accuracy: 0.3168\n",
      "Epoch 144/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.6423 - sparse_categorical_accuracy: 0.3367 - val_loss: 1.7352 - val_sparse_categorical_accuracy: 0.3111\n",
      "Epoch 145/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.6417 - sparse_categorical_accuracy: 0.3484 - val_loss: 1.7323 - val_sparse_categorical_accuracy: 0.2960\n",
      "Epoch 146/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.6399 - sparse_categorical_accuracy: 0.3502 - val_loss: 1.7334 - val_sparse_categorical_accuracy: 0.2941\n",
      "Epoch 147/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.6233 - sparse_categorical_accuracy: 0.3526 - val_loss: 1.7234 - val_sparse_categorical_accuracy: 0.3060\n",
      "Epoch 148/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6236 - sparse_categorical_accuracy: 0.3589 - val_loss: 1.7350 - val_sparse_categorical_accuracy: 0.2991\n",
      "Epoch 149/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6396 - sparse_categorical_accuracy: 0.3445 - val_loss: 1.7285 - val_sparse_categorical_accuracy: 0.2935\n",
      "Epoch 150/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6400 - sparse_categorical_accuracy: 0.3544 - val_loss: 1.7304 - val_sparse_categorical_accuracy: 0.3161\n",
      "Epoch 151/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6378 - sparse_categorical_accuracy: 0.3616 - val_loss: 1.7344 - val_sparse_categorical_accuracy: 0.3035\n",
      "Epoch 152/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6210 - sparse_categorical_accuracy: 0.3580 - val_loss: 1.7329 - val_sparse_categorical_accuracy: 0.3067\n",
      "Epoch 153/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6380 - sparse_categorical_accuracy: 0.3451 - val_loss: 1.7155 - val_sparse_categorical_accuracy: 0.3029\n",
      "Epoch 154/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6246 - sparse_categorical_accuracy: 0.3568 - val_loss: 1.7289 - val_sparse_categorical_accuracy: 0.3149\n",
      "Epoch 155/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6203 - sparse_categorical_accuracy: 0.3568 - val_loss: 1.7140 - val_sparse_categorical_accuracy: 0.3205\n",
      "Epoch 156/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.6076 - sparse_categorical_accuracy: 0.3658 - val_loss: 1.7160 - val_sparse_categorical_accuracy: 0.3123\n",
      "Epoch 157/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6217 - sparse_categorical_accuracy: 0.3571 - val_loss: 1.7254 - val_sparse_categorical_accuracy: 0.3293\n",
      "Epoch 158/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6201 - sparse_categorical_accuracy: 0.3580 - val_loss: 1.7258 - val_sparse_categorical_accuracy: 0.3123\n",
      "Epoch 159/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6176 - sparse_categorical_accuracy: 0.3541 - val_loss: 1.7145 - val_sparse_categorical_accuracy: 0.3117\n",
      "Epoch 160/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6093 - sparse_categorical_accuracy: 0.3553 - val_loss: 1.7091 - val_sparse_categorical_accuracy: 0.3186\n",
      "Epoch 161/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6193 - sparse_categorical_accuracy: 0.3496 - val_loss: 1.7104 - val_sparse_categorical_accuracy: 0.3224\n",
      "Epoch 162/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6160 - sparse_categorical_accuracy: 0.3628 - val_loss: 1.7093 - val_sparse_categorical_accuracy: 0.3199\n",
      "Epoch 163/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6152 - sparse_categorical_accuracy: 0.3601 - val_loss: 1.7085 - val_sparse_categorical_accuracy: 0.3375\n",
      "Epoch 164/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5981 - sparse_categorical_accuracy: 0.3601 - val_loss: 1.7200 - val_sparse_categorical_accuracy: 0.3105\n",
      "Epoch 165/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6079 - sparse_categorical_accuracy: 0.3646 - val_loss: 1.6975 - val_sparse_categorical_accuracy: 0.3224\n",
      "Epoch 166/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6067 - sparse_categorical_accuracy: 0.3649 - val_loss: 1.7159 - val_sparse_categorical_accuracy: 0.3369\n",
      "Epoch 167/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6071 - sparse_categorical_accuracy: 0.3652 - val_loss: 1.7062 - val_sparse_categorical_accuracy: 0.3136\n",
      "Epoch 168/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6029 - sparse_categorical_accuracy: 0.3556 - val_loss: 1.6990 - val_sparse_categorical_accuracy: 0.3155\n",
      "Epoch 169/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5969 - sparse_categorical_accuracy: 0.3682 - val_loss: 1.6993 - val_sparse_categorical_accuracy: 0.3338\n",
      "Epoch 170/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5967 - sparse_categorical_accuracy: 0.3622 - val_loss: 1.6904 - val_sparse_categorical_accuracy: 0.3451\n",
      "Epoch 171/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5982 - sparse_categorical_accuracy: 0.3770 - val_loss: 1.7234 - val_sparse_categorical_accuracy: 0.3356\n",
      "Epoch 172/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5986 - sparse_categorical_accuracy: 0.3601 - val_loss: 1.7006 - val_sparse_categorical_accuracy: 0.3356\n",
      "Epoch 173/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5955 - sparse_categorical_accuracy: 0.3637 - val_loss: 1.7130 - val_sparse_categorical_accuracy: 0.3205\n",
      "Epoch 174/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5903 - sparse_categorical_accuracy: 0.3715 - val_loss: 1.6993 - val_sparse_categorical_accuracy: 0.3319\n",
      "Epoch 175/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5993 - sparse_categorical_accuracy: 0.3643 - val_loss: 1.6845 - val_sparse_categorical_accuracy: 0.3319\n",
      "Epoch 176/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.5743 - sparse_categorical_accuracy: 0.3755 - val_loss: 1.6829 - val_sparse_categorical_accuracy: 0.3262\n",
      "Epoch 177/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.6012 - sparse_categorical_accuracy: 0.3592 - val_loss: 1.6842 - val_sparse_categorical_accuracy: 0.3363\n",
      "Epoch 178/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5908 - sparse_categorical_accuracy: 0.3643 - val_loss: 1.6891 - val_sparse_categorical_accuracy: 0.3577\n",
      "Epoch 179/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5838 - sparse_categorical_accuracy: 0.3649 - val_loss: 1.7328 - val_sparse_categorical_accuracy: 0.3079\n",
      "Epoch 180/600\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 1.6021 - sparse_categorical_accuracy: 0.3619 - val_loss: 1.6942 - val_sparse_categorical_accuracy: 0.3356\n",
      "Epoch 181/600\n",
      "105/105 [==============================] - 2s 14ms/step - loss: 1.5790 - sparse_categorical_accuracy: 0.3676 - val_loss: 1.6798 - val_sparse_categorical_accuracy: 0.3445\n",
      "Epoch 182/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5821 - sparse_categorical_accuracy: 0.3670 - val_loss: 1.7081 - val_sparse_categorical_accuracy: 0.3073\n",
      "Epoch 183/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5726 - sparse_categorical_accuracy: 0.3767 - val_loss: 1.7074 - val_sparse_categorical_accuracy: 0.3350\n",
      "Epoch 184/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5801 - sparse_categorical_accuracy: 0.3703 - val_loss: 1.6795 - val_sparse_categorical_accuracy: 0.3331\n",
      "Epoch 185/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5915 - sparse_categorical_accuracy: 0.3685 - val_loss: 1.6870 - val_sparse_categorical_accuracy: 0.3331\n",
      "Epoch 186/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5741 - sparse_categorical_accuracy: 0.3688 - val_loss: 1.6925 - val_sparse_categorical_accuracy: 0.3394\n",
      "Epoch 187/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5708 - sparse_categorical_accuracy: 0.3752 - val_loss: 1.6790 - val_sparse_categorical_accuracy: 0.3375\n",
      "Epoch 188/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5592 - sparse_categorical_accuracy: 0.3788 - val_loss: 1.6881 - val_sparse_categorical_accuracy: 0.3526\n",
      "Epoch 189/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.5746 - sparse_categorical_accuracy: 0.3733 - val_loss: 1.6722 - val_sparse_categorical_accuracy: 0.3356\n",
      "Epoch 190/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5702 - sparse_categorical_accuracy: 0.3875 - val_loss: 1.6702 - val_sparse_categorical_accuracy: 0.3401\n",
      "Epoch 191/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.5529 - sparse_categorical_accuracy: 0.3911 - val_loss: 1.6763 - val_sparse_categorical_accuracy: 0.3508\n",
      "Epoch 192/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.5706 - sparse_categorical_accuracy: 0.3742 - val_loss: 1.6915 - val_sparse_categorical_accuracy: 0.3401\n",
      "Epoch 193/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.5600 - sparse_categorical_accuracy: 0.3776 - val_loss: 1.6899 - val_sparse_categorical_accuracy: 0.3287\n",
      "Epoch 194/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.5752 - sparse_categorical_accuracy: 0.3857 - val_loss: 1.6917 - val_sparse_categorical_accuracy: 0.3401\n",
      "Epoch 195/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.5511 - sparse_categorical_accuracy: 0.3800 - val_loss: 1.6843 - val_sparse_categorical_accuracy: 0.3363\n",
      "Epoch 196/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.5663 - sparse_categorical_accuracy: 0.3764 - val_loss: 1.7383 - val_sparse_categorical_accuracy: 0.3508\n",
      "Epoch 197/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5612 - sparse_categorical_accuracy: 0.3824 - val_loss: 1.6809 - val_sparse_categorical_accuracy: 0.3463\n",
      "Epoch 198/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5557 - sparse_categorical_accuracy: 0.3890 - val_loss: 1.6582 - val_sparse_categorical_accuracy: 0.3583\n",
      "Epoch 199/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.5456 - sparse_categorical_accuracy: 0.3875 - val_loss: 1.6954 - val_sparse_categorical_accuracy: 0.3476\n",
      "Epoch 200/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.5583 - sparse_categorical_accuracy: 0.3872 - val_loss: 1.6713 - val_sparse_categorical_accuracy: 0.3325\n",
      "Epoch 201/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5471 - sparse_categorical_accuracy: 0.3715 - val_loss: 1.6543 - val_sparse_categorical_accuracy: 0.3438\n",
      "Epoch 202/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5534 - sparse_categorical_accuracy: 0.3854 - val_loss: 1.6570 - val_sparse_categorical_accuracy: 0.3445\n",
      "Epoch 203/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5509 - sparse_categorical_accuracy: 0.3914 - val_loss: 1.6624 - val_sparse_categorical_accuracy: 0.3589\n",
      "Epoch 204/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5476 - sparse_categorical_accuracy: 0.3881 - val_loss: 1.6692 - val_sparse_categorical_accuracy: 0.3476\n",
      "Epoch 205/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5401 - sparse_categorical_accuracy: 0.3911 - val_loss: 1.6462 - val_sparse_categorical_accuracy: 0.3545\n",
      "Epoch 206/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5405 - sparse_categorical_accuracy: 0.3923 - val_loss: 1.6575 - val_sparse_categorical_accuracy: 0.3419\n",
      "Epoch 207/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.5538 - sparse_categorical_accuracy: 0.3872 - val_loss: 1.6513 - val_sparse_categorical_accuracy: 0.3463\n",
      "Epoch 208/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.5503 - sparse_categorical_accuracy: 0.3842 - val_loss: 1.6620 - val_sparse_categorical_accuracy: 0.3558\n",
      "Epoch 209/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.5379 - sparse_categorical_accuracy: 0.3998 - val_loss: 1.6522 - val_sparse_categorical_accuracy: 0.3545\n",
      "Epoch 210/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5403 - sparse_categorical_accuracy: 0.3815 - val_loss: 1.6532 - val_sparse_categorical_accuracy: 0.3426\n",
      "Epoch 211/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5313 - sparse_categorical_accuracy: 0.3974 - val_loss: 1.6568 - val_sparse_categorical_accuracy: 0.3577\n",
      "Epoch 212/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.5236 - sparse_categorical_accuracy: 0.3926 - val_loss: 1.6685 - val_sparse_categorical_accuracy: 0.3482\n",
      "Epoch 213/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.5349 - sparse_categorical_accuracy: 0.3932 - val_loss: 1.6421 - val_sparse_categorical_accuracy: 0.3627\n",
      "Epoch 214/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.5420 - sparse_categorical_accuracy: 0.3938 - val_loss: 1.6423 - val_sparse_categorical_accuracy: 0.3545\n",
      "Epoch 215/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.5284 - sparse_categorical_accuracy: 0.3926 - val_loss: 1.6654 - val_sparse_categorical_accuracy: 0.3602\n",
      "Epoch 216/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.5178 - sparse_categorical_accuracy: 0.4085 - val_loss: 1.6611 - val_sparse_categorical_accuracy: 0.3476\n",
      "Epoch 217/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 2s 16ms/step - loss: 1.5354 - sparse_categorical_accuracy: 0.3878 - val_loss: 1.6438 - val_sparse_categorical_accuracy: 0.3608\n",
      "Epoch 218/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5177 - sparse_categorical_accuracy: 0.3989 - val_loss: 1.6466 - val_sparse_categorical_accuracy: 0.3489\n",
      "Epoch 219/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5365 - sparse_categorical_accuracy: 0.3977 - val_loss: 1.6433 - val_sparse_categorical_accuracy: 0.3520\n",
      "Epoch 220/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5256 - sparse_categorical_accuracy: 0.4091 - val_loss: 1.6613 - val_sparse_categorical_accuracy: 0.3564\n",
      "Epoch 221/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5100 - sparse_categorical_accuracy: 0.3998 - val_loss: 1.6392 - val_sparse_categorical_accuracy: 0.3539\n",
      "Epoch 222/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5198 - sparse_categorical_accuracy: 0.3938 - val_loss: 1.6709 - val_sparse_categorical_accuracy: 0.3457\n",
      "Epoch 223/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5074 - sparse_categorical_accuracy: 0.4004 - val_loss: 1.6393 - val_sparse_categorical_accuracy: 0.3646\n",
      "Epoch 224/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5047 - sparse_categorical_accuracy: 0.4055 - val_loss: 1.6499 - val_sparse_categorical_accuracy: 0.3728\n",
      "Epoch 225/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.5145 - sparse_categorical_accuracy: 0.4016 - val_loss: 1.6355 - val_sparse_categorical_accuracy: 0.3684\n",
      "Epoch 226/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.5092 - sparse_categorical_accuracy: 0.3968 - val_loss: 1.6359 - val_sparse_categorical_accuracy: 0.3684\n",
      "Epoch 227/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.5177 - sparse_categorical_accuracy: 0.3998 - val_loss: 1.6316 - val_sparse_categorical_accuracy: 0.3489\n",
      "Epoch 228/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.5172 - sparse_categorical_accuracy: 0.4016 - val_loss: 1.6570 - val_sparse_categorical_accuracy: 0.3451\n",
      "Epoch 229/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5051 - sparse_categorical_accuracy: 0.4067 - val_loss: 1.6289 - val_sparse_categorical_accuracy: 0.3734\n",
      "Epoch 230/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5097 - sparse_categorical_accuracy: 0.4001 - val_loss: 1.6225 - val_sparse_categorical_accuracy: 0.3709\n",
      "Epoch 231/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5111 - sparse_categorical_accuracy: 0.4043 - val_loss: 1.6399 - val_sparse_categorical_accuracy: 0.3596\n",
      "Epoch 232/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.5083 - sparse_categorical_accuracy: 0.4073 - val_loss: 1.6278 - val_sparse_categorical_accuracy: 0.3810\n",
      "Epoch 233/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4954 - sparse_categorical_accuracy: 0.4118 - val_loss: 1.6405 - val_sparse_categorical_accuracy: 0.3690\n",
      "Epoch 234/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4950 - sparse_categorical_accuracy: 0.3998 - val_loss: 1.6461 - val_sparse_categorical_accuracy: 0.3583\n",
      "Epoch 235/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.5083 - sparse_categorical_accuracy: 0.3953 - val_loss: 1.6197 - val_sparse_categorical_accuracy: 0.3797\n",
      "Epoch 236/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.5021 - sparse_categorical_accuracy: 0.3989 - val_loss: 1.6336 - val_sparse_categorical_accuracy: 0.3665\n",
      "Epoch 237/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4943 - sparse_categorical_accuracy: 0.4097 - val_loss: 1.6201 - val_sparse_categorical_accuracy: 0.3583\n",
      "Epoch 238/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4968 - sparse_categorical_accuracy: 0.4130 - val_loss: 1.6373 - val_sparse_categorical_accuracy: 0.3627\n",
      "Epoch 239/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.5087 - sparse_categorical_accuracy: 0.4052 - val_loss: 1.6124 - val_sparse_categorical_accuracy: 0.3848\n",
      "Epoch 240/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4813 - sparse_categorical_accuracy: 0.4163 - val_loss: 1.6183 - val_sparse_categorical_accuracy: 0.3696\n",
      "Epoch 241/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4972 - sparse_categorical_accuracy: 0.4022 - val_loss: 1.6234 - val_sparse_categorical_accuracy: 0.3634\n",
      "Epoch 242/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4980 - sparse_categorical_accuracy: 0.4049 - val_loss: 1.6013 - val_sparse_categorical_accuracy: 0.3684\n",
      "Epoch 243/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4954 - sparse_categorical_accuracy: 0.4031 - val_loss: 1.6102 - val_sparse_categorical_accuracy: 0.3797\n",
      "Epoch 244/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4914 - sparse_categorical_accuracy: 0.4154 - val_loss: 1.6014 - val_sparse_categorical_accuracy: 0.3873\n",
      "Epoch 245/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4797 - sparse_categorical_accuracy: 0.4151 - val_loss: 1.6018 - val_sparse_categorical_accuracy: 0.3734\n",
      "Epoch 246/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4824 - sparse_categorical_accuracy: 0.4106 - val_loss: 1.5988 - val_sparse_categorical_accuracy: 0.3785\n",
      "Epoch 247/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.4816 - sparse_categorical_accuracy: 0.4100 - val_loss: 1.6059 - val_sparse_categorical_accuracy: 0.3741\n",
      "Epoch 248/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4761 - sparse_categorical_accuracy: 0.4205 - val_loss: 1.5968 - val_sparse_categorical_accuracy: 0.3791\n",
      "Epoch 249/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4786 - sparse_categorical_accuracy: 0.4127 - val_loss: 1.6121 - val_sparse_categorical_accuracy: 0.3816\n",
      "Epoch 250/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4743 - sparse_categorical_accuracy: 0.4238 - val_loss: 1.5934 - val_sparse_categorical_accuracy: 0.3766\n",
      "Epoch 251/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4762 - sparse_categorical_accuracy: 0.4145 - val_loss: 1.6142 - val_sparse_categorical_accuracy: 0.3734\n",
      "Epoch 252/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.4669 - sparse_categorical_accuracy: 0.4172 - val_loss: 1.6257 - val_sparse_categorical_accuracy: 0.3715\n",
      "Epoch 253/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4759 - sparse_categorical_accuracy: 0.4202 - val_loss: 1.6080 - val_sparse_categorical_accuracy: 0.3709\n",
      "Epoch 254/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4735 - sparse_categorical_accuracy: 0.4124 - val_loss: 1.5974 - val_sparse_categorical_accuracy: 0.3854\n",
      "Epoch 255/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4690 - sparse_categorical_accuracy: 0.4169 - val_loss: 1.6253 - val_sparse_categorical_accuracy: 0.3615\n",
      "Epoch 256/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4630 - sparse_categorical_accuracy: 0.4274 - val_loss: 1.6161 - val_sparse_categorical_accuracy: 0.3659\n",
      "Epoch 257/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4737 - sparse_categorical_accuracy: 0.4160 - val_loss: 1.5910 - val_sparse_categorical_accuracy: 0.3804\n",
      "Epoch 258/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4658 - sparse_categorical_accuracy: 0.4130 - val_loss: 1.6096 - val_sparse_categorical_accuracy: 0.3778\n",
      "Epoch 259/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4658 - sparse_categorical_accuracy: 0.4193 - val_loss: 1.5897 - val_sparse_categorical_accuracy: 0.3835\n",
      "Epoch 260/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4702 - sparse_categorical_accuracy: 0.4220 - val_loss: 1.5938 - val_sparse_categorical_accuracy: 0.3967\n",
      "Epoch 261/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4610 - sparse_categorical_accuracy: 0.4295 - val_loss: 1.5995 - val_sparse_categorical_accuracy: 0.3791\n",
      "Epoch 262/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4567 - sparse_categorical_accuracy: 0.4241 - val_loss: 1.5964 - val_sparse_categorical_accuracy: 0.3879\n",
      "Epoch 263/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4600 - sparse_categorical_accuracy: 0.4136 - val_loss: 1.5988 - val_sparse_categorical_accuracy: 0.3879\n",
      "Epoch 264/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4709 - sparse_categorical_accuracy: 0.4205 - val_loss: 1.6170 - val_sparse_categorical_accuracy: 0.3722\n",
      "Epoch 265/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4536 - sparse_categorical_accuracy: 0.4226 - val_loss: 1.5967 - val_sparse_categorical_accuracy: 0.3753\n",
      "Epoch 266/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4551 - sparse_categorical_accuracy: 0.4244 - val_loss: 1.5963 - val_sparse_categorical_accuracy: 0.3898\n",
      "Epoch 267/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4562 - sparse_categorical_accuracy: 0.4163 - val_loss: 1.5780 - val_sparse_categorical_accuracy: 0.3911\n",
      "Epoch 268/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4543 - sparse_categorical_accuracy: 0.4175 - val_loss: 1.5906 - val_sparse_categorical_accuracy: 0.3822\n",
      "Epoch 269/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4565 - sparse_categorical_accuracy: 0.4202 - val_loss: 1.5840 - val_sparse_categorical_accuracy: 0.3923\n",
      "Epoch 270/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4540 - sparse_categorical_accuracy: 0.4148 - val_loss: 1.5926 - val_sparse_categorical_accuracy: 0.3709\n",
      "Epoch 271/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4397 - sparse_categorical_accuracy: 0.4328 - val_loss: 1.5857 - val_sparse_categorical_accuracy: 0.3904\n",
      "Epoch 272/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4529 - sparse_categorical_accuracy: 0.4184 - val_loss: 1.5739 - val_sparse_categorical_accuracy: 0.3873\n",
      "Epoch 273/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4489 - sparse_categorical_accuracy: 0.4271 - val_loss: 1.5783 - val_sparse_categorical_accuracy: 0.3879\n",
      "Epoch 274/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4660 - sparse_categorical_accuracy: 0.4253 - val_loss: 1.5808 - val_sparse_categorical_accuracy: 0.3948\n",
      "Epoch 275/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4493 - sparse_categorical_accuracy: 0.4337 - val_loss: 1.5773 - val_sparse_categorical_accuracy: 0.3873\n",
      "Epoch 276/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4591 - sparse_categorical_accuracy: 0.4271 - val_loss: 1.5828 - val_sparse_categorical_accuracy: 0.3772\n",
      "Epoch 277/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4522 - sparse_categorical_accuracy: 0.4274 - val_loss: 1.6234 - val_sparse_categorical_accuracy: 0.3778\n",
      "Epoch 278/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4397 - sparse_categorical_accuracy: 0.4271 - val_loss: 1.5804 - val_sparse_categorical_accuracy: 0.3759\n",
      "Epoch 279/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4397 - sparse_categorical_accuracy: 0.4295 - val_loss: 1.5717 - val_sparse_categorical_accuracy: 0.3898\n",
      "Epoch 280/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.4369 - sparse_categorical_accuracy: 0.4259 - val_loss: 1.5853 - val_sparse_categorical_accuracy: 0.3873\n",
      "Epoch 281/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4398 - sparse_categorical_accuracy: 0.4409 - val_loss: 1.5638 - val_sparse_categorical_accuracy: 0.3892\n",
      "Epoch 282/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4413 - sparse_categorical_accuracy: 0.4418 - val_loss: 1.5855 - val_sparse_categorical_accuracy: 0.3785\n",
      "Epoch 283/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4425 - sparse_categorical_accuracy: 0.4277 - val_loss: 1.5864 - val_sparse_categorical_accuracy: 0.3829\n",
      "Epoch 284/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4308 - sparse_categorical_accuracy: 0.4361 - val_loss: 1.5719 - val_sparse_categorical_accuracy: 0.3810\n",
      "Epoch 285/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.4242 - sparse_categorical_accuracy: 0.4352 - val_loss: 1.5811 - val_sparse_categorical_accuracy: 0.3917\n",
      "Epoch 286/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.4208 - sparse_categorical_accuracy: 0.4364 - val_loss: 1.5818 - val_sparse_categorical_accuracy: 0.4043\n",
      "Epoch 287/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4346 - sparse_categorical_accuracy: 0.4379 - val_loss: 1.5687 - val_sparse_categorical_accuracy: 0.3923\n",
      "Epoch 288/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4195 - sparse_categorical_accuracy: 0.4385 - val_loss: 1.5655 - val_sparse_categorical_accuracy: 0.4024\n",
      "Epoch 289/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4205 - sparse_categorical_accuracy: 0.4463 - val_loss: 1.5485 - val_sparse_categorical_accuracy: 0.3992\n",
      "Epoch 290/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4217 - sparse_categorical_accuracy: 0.4370 - val_loss: 1.5607 - val_sparse_categorical_accuracy: 0.3942\n",
      "Epoch 291/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.4061 - sparse_categorical_accuracy: 0.4457 - val_loss: 1.5781 - val_sparse_categorical_accuracy: 0.3835\n",
      "Epoch 292/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4338 - sparse_categorical_accuracy: 0.4241 - val_loss: 1.5851 - val_sparse_categorical_accuracy: 0.3936\n",
      "Epoch 293/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4139 - sparse_categorical_accuracy: 0.4403 - val_loss: 1.5780 - val_sparse_categorical_accuracy: 0.4024\n",
      "Epoch 294/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.4229 - sparse_categorical_accuracy: 0.4376 - val_loss: 1.5521 - val_sparse_categorical_accuracy: 0.3986\n",
      "Epoch 295/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.4120 - sparse_categorical_accuracy: 0.4526 - val_loss: 1.5707 - val_sparse_categorical_accuracy: 0.3885\n",
      "Epoch 296/600\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 1.4071 - sparse_categorical_accuracy: 0.4436 - val_loss: 1.5398 - val_sparse_categorical_accuracy: 0.4150\n",
      "Epoch 297/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.4211 - sparse_categorical_accuracy: 0.4361 - val_loss: 1.5666 - val_sparse_categorical_accuracy: 0.3961\n",
      "Epoch 298/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.4112 - sparse_categorical_accuracy: 0.4382 - val_loss: 1.5563 - val_sparse_categorical_accuracy: 0.3917\n",
      "Epoch 299/600\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 1.4000 - sparse_categorical_accuracy: 0.4511 - val_loss: 1.5592 - val_sparse_categorical_accuracy: 0.4030\n",
      "Epoch 300/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.4103 - sparse_categorical_accuracy: 0.4382 - val_loss: 1.5829 - val_sparse_categorical_accuracy: 0.3885\n",
      "Epoch 301/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.4273 - sparse_categorical_accuracy: 0.4430 - val_loss: 1.5610 - val_sparse_categorical_accuracy: 0.4030\n",
      "Epoch 302/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.4106 - sparse_categorical_accuracy: 0.4376 - val_loss: 1.5702 - val_sparse_categorical_accuracy: 0.4018\n",
      "Epoch 303/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.4047 - sparse_categorical_accuracy: 0.4484 - val_loss: 1.5560 - val_sparse_categorical_accuracy: 0.4081\n",
      "Epoch 304/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.3982 - sparse_categorical_accuracy: 0.4478 - val_loss: 1.5447 - val_sparse_categorical_accuracy: 0.4049\n",
      "Epoch 305/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 2s 20ms/step - loss: 1.4106 - sparse_categorical_accuracy: 0.4478 - val_loss: 1.5624 - val_sparse_categorical_accuracy: 0.3980\n",
      "Epoch 306/600\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 1.4053 - sparse_categorical_accuracy: 0.4523 - val_loss: 1.5445 - val_sparse_categorical_accuracy: 0.3986\n",
      "Epoch 307/600\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 1.4059 - sparse_categorical_accuracy: 0.4499 - val_loss: 1.5344 - val_sparse_categorical_accuracy: 0.4118\n",
      "Epoch 308/600\n",
      "105/105 [==============================] - 2s 17ms/step - loss: 1.3925 - sparse_categorical_accuracy: 0.4511 - val_loss: 1.5481 - val_sparse_categorical_accuracy: 0.3942\n",
      "Epoch 309/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.4008 - sparse_categorical_accuracy: 0.4322 - val_loss: 1.5542 - val_sparse_categorical_accuracy: 0.4131\n",
      "Epoch 310/600\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 1.3938 - sparse_categorical_accuracy: 0.4556 - val_loss: 1.5319 - val_sparse_categorical_accuracy: 0.4081\n",
      "Epoch 311/600\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 1.4088 - sparse_categorical_accuracy: 0.4538 - val_loss: 1.5382 - val_sparse_categorical_accuracy: 0.4099\n",
      "Epoch 312/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.3828 - sparse_categorical_accuracy: 0.4565 - val_loss: 1.5298 - val_sparse_categorical_accuracy: 0.4030\n",
      "Epoch 313/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.3977 - sparse_categorical_accuracy: 0.4442 - val_loss: 1.5494 - val_sparse_categorical_accuracy: 0.3967\n",
      "Epoch 314/600\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 1.3995 - sparse_categorical_accuracy: 0.4466 - val_loss: 1.5434 - val_sparse_categorical_accuracy: 0.3911\n",
      "Epoch 315/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.3741 - sparse_categorical_accuracy: 0.4589 - val_loss: 1.5318 - val_sparse_categorical_accuracy: 0.4043\n",
      "Epoch 316/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.3949 - sparse_categorical_accuracy: 0.4517 - val_loss: 1.5356 - val_sparse_categorical_accuracy: 0.4062\n",
      "Epoch 317/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.3894 - sparse_categorical_accuracy: 0.4433 - val_loss: 1.5437 - val_sparse_categorical_accuracy: 0.4005\n",
      "Epoch 318/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3972 - sparse_categorical_accuracy: 0.4469 - val_loss: 1.5390 - val_sparse_categorical_accuracy: 0.3999\n",
      "Epoch 319/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.3868 - sparse_categorical_accuracy: 0.4502 - val_loss: 1.5299 - val_sparse_categorical_accuracy: 0.4081\n",
      "Epoch 320/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.3796 - sparse_categorical_accuracy: 0.4580 - val_loss: 1.5498 - val_sparse_categorical_accuracy: 0.3999\n",
      "Epoch 321/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.3999 - sparse_categorical_accuracy: 0.4421 - val_loss: 1.5231 - val_sparse_categorical_accuracy: 0.4037\n",
      "Epoch 322/600\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 1.3731 - sparse_categorical_accuracy: 0.4601 - val_loss: 1.5240 - val_sparse_categorical_accuracy: 0.4131\n",
      "Epoch 323/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.3820 - sparse_categorical_accuracy: 0.4490 - val_loss: 1.5304 - val_sparse_categorical_accuracy: 0.4099\n",
      "Epoch 324/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3774 - sparse_categorical_accuracy: 0.4586 - val_loss: 1.5238 - val_sparse_categorical_accuracy: 0.4188\n",
      "Epoch 325/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3864 - sparse_categorical_accuracy: 0.4484 - val_loss: 1.5299 - val_sparse_categorical_accuracy: 0.4263\n",
      "Epoch 326/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.3869 - sparse_categorical_accuracy: 0.4514 - val_loss: 1.5269 - val_sparse_categorical_accuracy: 0.4219\n",
      "Epoch 327/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.3697 - sparse_categorical_accuracy: 0.4502 - val_loss: 1.5344 - val_sparse_categorical_accuracy: 0.4074\n",
      "Epoch 328/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3763 - sparse_categorical_accuracy: 0.4556 - val_loss: 1.5288 - val_sparse_categorical_accuracy: 0.4087\n",
      "Epoch 329/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.3799 - sparse_categorical_accuracy: 0.4613 - val_loss: 1.5344 - val_sparse_categorical_accuracy: 0.4087\n",
      "Epoch 330/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.3667 - sparse_categorical_accuracy: 0.4520 - val_loss: 1.5301 - val_sparse_categorical_accuracy: 0.4118\n",
      "Epoch 331/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.3738 - sparse_categorical_accuracy: 0.4562 - val_loss: 1.5432 - val_sparse_categorical_accuracy: 0.4024\n",
      "Epoch 332/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3789 - sparse_categorical_accuracy: 0.4595 - val_loss: 1.5360 - val_sparse_categorical_accuracy: 0.4156\n",
      "Epoch 333/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.3684 - sparse_categorical_accuracy: 0.4637 - val_loss: 1.5430 - val_sparse_categorical_accuracy: 0.4099\n",
      "Epoch 334/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.3833 - sparse_categorical_accuracy: 0.4592 - val_loss: 1.5501 - val_sparse_categorical_accuracy: 0.4257\n",
      "Epoch 335/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.3780 - sparse_categorical_accuracy: 0.4523 - val_loss: 1.5366 - val_sparse_categorical_accuracy: 0.4150\n",
      "Epoch 336/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.3610 - sparse_categorical_accuracy: 0.4697 - val_loss: 1.5296 - val_sparse_categorical_accuracy: 0.4118\n",
      "Epoch 337/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3752 - sparse_categorical_accuracy: 0.4580 - val_loss: 1.5246 - val_sparse_categorical_accuracy: 0.4213\n",
      "Epoch 338/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3635 - sparse_categorical_accuracy: 0.4562 - val_loss: 1.5259 - val_sparse_categorical_accuracy: 0.4093\n",
      "Epoch 339/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3571 - sparse_categorical_accuracy: 0.4637 - val_loss: 1.5139 - val_sparse_categorical_accuracy: 0.4244\n",
      "Epoch 340/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3559 - sparse_categorical_accuracy: 0.4643 - val_loss: 1.5166 - val_sparse_categorical_accuracy: 0.4213\n",
      "Epoch 341/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3705 - sparse_categorical_accuracy: 0.4532 - val_loss: 1.5300 - val_sparse_categorical_accuracy: 0.4156\n",
      "Epoch 342/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3390 - sparse_categorical_accuracy: 0.4697 - val_loss: 1.5138 - val_sparse_categorical_accuracy: 0.4238\n",
      "Epoch 343/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.3669 - sparse_categorical_accuracy: 0.4535 - val_loss: 1.5159 - val_sparse_categorical_accuracy: 0.4288\n",
      "Epoch 344/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3525 - sparse_categorical_accuracy: 0.4691 - val_loss: 1.5148 - val_sparse_categorical_accuracy: 0.4181\n",
      "Epoch 345/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3417 - sparse_categorical_accuracy: 0.4571 - val_loss: 1.4934 - val_sparse_categorical_accuracy: 0.4213\n",
      "Epoch 346/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3537 - sparse_categorical_accuracy: 0.4628 - val_loss: 1.5275 - val_sparse_categorical_accuracy: 0.4238\n",
      "Epoch 347/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.3515 - sparse_categorical_accuracy: 0.4643 - val_loss: 1.5187 - val_sparse_categorical_accuracy: 0.4194\n",
      "Epoch 348/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3580 - sparse_categorical_accuracy: 0.4658 - val_loss: 1.5158 - val_sparse_categorical_accuracy: 0.4125\n",
      "Epoch 349/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3431 - sparse_categorical_accuracy: 0.4652 - val_loss: 1.5278 - val_sparse_categorical_accuracy: 0.4320\n",
      "Epoch 350/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3404 - sparse_categorical_accuracy: 0.4673 - val_loss: 1.5261 - val_sparse_categorical_accuracy: 0.4188\n",
      "Epoch 351/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3442 - sparse_categorical_accuracy: 0.4607 - val_loss: 1.5314 - val_sparse_categorical_accuracy: 0.4175\n",
      "Epoch 352/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3537 - sparse_categorical_accuracy: 0.4595 - val_loss: 1.5072 - val_sparse_categorical_accuracy: 0.4099\n",
      "Epoch 353/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3345 - sparse_categorical_accuracy: 0.4682 - val_loss: 1.5148 - val_sparse_categorical_accuracy: 0.4169\n",
      "Epoch 354/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3416 - sparse_categorical_accuracy: 0.4625 - val_loss: 1.5321 - val_sparse_categorical_accuracy: 0.4288\n",
      "Epoch 355/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3433 - sparse_categorical_accuracy: 0.4679 - val_loss: 1.5353 - val_sparse_categorical_accuracy: 0.4150\n",
      "Epoch 356/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3538 - sparse_categorical_accuracy: 0.4709 - val_loss: 1.5177 - val_sparse_categorical_accuracy: 0.4288\n",
      "Epoch 357/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.3337 - sparse_categorical_accuracy: 0.4718 - val_loss: 1.5440 - val_sparse_categorical_accuracy: 0.4232\n",
      "Epoch 358/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3484 - sparse_categorical_accuracy: 0.4820 - val_loss: 1.5268 - val_sparse_categorical_accuracy: 0.4244\n",
      "Epoch 359/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3398 - sparse_categorical_accuracy: 0.4646 - val_loss: 1.4919 - val_sparse_categorical_accuracy: 0.4339\n",
      "Epoch 360/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3353 - sparse_categorical_accuracy: 0.4682 - val_loss: 1.5071 - val_sparse_categorical_accuracy: 0.4276\n",
      "Epoch 361/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3404 - sparse_categorical_accuracy: 0.4667 - val_loss: 1.4912 - val_sparse_categorical_accuracy: 0.4288\n",
      "Epoch 362/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3400 - sparse_categorical_accuracy: 0.4712 - val_loss: 1.5183 - val_sparse_categorical_accuracy: 0.4232\n",
      "Epoch 363/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3300 - sparse_categorical_accuracy: 0.4691 - val_loss: 1.5252 - val_sparse_categorical_accuracy: 0.4112\n",
      "Epoch 364/600\n",
      "105/105 [==============================] - 2s 15ms/step - loss: 1.3372 - sparse_categorical_accuracy: 0.4676 - val_loss: 1.5022 - val_sparse_categorical_accuracy: 0.4194\n",
      "Epoch 365/600\n",
      "105/105 [==============================] - 2s 16ms/step - loss: 1.3299 - sparse_categorical_accuracy: 0.4679 - val_loss: 1.5081 - val_sparse_categorical_accuracy: 0.4219\n",
      "Epoch 366/600\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 1.3322 - sparse_categorical_accuracy: 0.4772 - val_loss: 1.5216 - val_sparse_categorical_accuracy: 0.4169\n",
      "Epoch 367/600\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 1.3237 - sparse_categorical_accuracy: 0.4700 - val_loss: 1.5159 - val_sparse_categorical_accuracy: 0.4301\n",
      "Epoch 368/600\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 1.3116 - sparse_categorical_accuracy: 0.4823 - val_loss: 1.4945 - val_sparse_categorical_accuracy: 0.4465\n",
      "Epoch 369/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.3315 - sparse_categorical_accuracy: 0.4805 - val_loss: 1.4905 - val_sparse_categorical_accuracy: 0.4251\n",
      "Epoch 370/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3249 - sparse_categorical_accuracy: 0.4607 - val_loss: 1.5247 - val_sparse_categorical_accuracy: 0.4225\n",
      "Epoch 371/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3425 - sparse_categorical_accuracy: 0.4748 - val_loss: 1.5288 - val_sparse_categorical_accuracy: 0.4314\n",
      "Epoch 372/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3222 - sparse_categorical_accuracy: 0.4787 - val_loss: 1.4916 - val_sparse_categorical_accuracy: 0.4225\n",
      "Epoch 373/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3346 - sparse_categorical_accuracy: 0.4751 - val_loss: 1.5164 - val_sparse_categorical_accuracy: 0.4213\n",
      "Epoch 374/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.3210 - sparse_categorical_accuracy: 0.4724 - val_loss: 1.4981 - val_sparse_categorical_accuracy: 0.4257\n",
      "Epoch 375/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3301 - sparse_categorical_accuracy: 0.4727 - val_loss: 1.5251 - val_sparse_categorical_accuracy: 0.4301\n",
      "Epoch 376/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3064 - sparse_categorical_accuracy: 0.4736 - val_loss: 1.5017 - val_sparse_categorical_accuracy: 0.4427\n",
      "Epoch 377/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3264 - sparse_categorical_accuracy: 0.4790 - val_loss: 1.5079 - val_sparse_categorical_accuracy: 0.4377\n",
      "Epoch 378/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.3121 - sparse_categorical_accuracy: 0.4853 - val_loss: 1.5453 - val_sparse_categorical_accuracy: 0.4068\n",
      "Epoch 379/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3174 - sparse_categorical_accuracy: 0.4742 - val_loss: 1.5310 - val_sparse_categorical_accuracy: 0.4194\n",
      "Epoch 380/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2960 - sparse_categorical_accuracy: 0.4877 - val_loss: 1.5365 - val_sparse_categorical_accuracy: 0.4244\n",
      "Epoch 381/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3211 - sparse_categorical_accuracy: 0.4781 - val_loss: 1.5093 - val_sparse_categorical_accuracy: 0.4402\n",
      "Epoch 382/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3069 - sparse_categorical_accuracy: 0.4871 - val_loss: 1.4956 - val_sparse_categorical_accuracy: 0.4427\n",
      "Epoch 383/600\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 1.2951 - sparse_categorical_accuracy: 0.4841 - val_loss: 1.5111 - val_sparse_categorical_accuracy: 0.4251\n",
      "Epoch 384/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3261 - sparse_categorical_accuracy: 0.4754 - val_loss: 1.5006 - val_sparse_categorical_accuracy: 0.4288\n",
      "Epoch 385/600\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 1.3116 - sparse_categorical_accuracy: 0.4835 - val_loss: 1.5183 - val_sparse_categorical_accuracy: 0.4219\n",
      "Epoch 386/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3082 - sparse_categorical_accuracy: 0.4829 - val_loss: 1.4860 - val_sparse_categorical_accuracy: 0.4270\n",
      "Epoch 387/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.3163 - sparse_categorical_accuracy: 0.4751 - val_loss: 1.5085 - val_sparse_categorical_accuracy: 0.4282\n",
      "Epoch 388/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3056 - sparse_categorical_accuracy: 0.4901 - val_loss: 1.4964 - val_sparse_categorical_accuracy: 0.4276\n",
      "Epoch 389/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3007 - sparse_categorical_accuracy: 0.4880 - val_loss: 1.4776 - val_sparse_categorical_accuracy: 0.4377\n",
      "Epoch 390/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.3084 - sparse_categorical_accuracy: 0.4883 - val_loss: 1.5016 - val_sparse_categorical_accuracy: 0.4257\n",
      "Epoch 391/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2978 - sparse_categorical_accuracy: 0.4883 - val_loss: 1.5019 - val_sparse_categorical_accuracy: 0.4351\n",
      "Epoch 392/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3056 - sparse_categorical_accuracy: 0.4934 - val_loss: 1.4869 - val_sparse_categorical_accuracy: 0.4301\n",
      "Epoch 393/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 2s 20ms/step - loss: 1.3107 - sparse_categorical_accuracy: 0.4916 - val_loss: 1.4709 - val_sparse_categorical_accuracy: 0.4326\n",
      "Epoch 394/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3080 - sparse_categorical_accuracy: 0.4874 - val_loss: 1.4755 - val_sparse_categorical_accuracy: 0.4332\n",
      "Epoch 395/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2947 - sparse_categorical_accuracy: 0.4829 - val_loss: 1.4742 - val_sparse_categorical_accuracy: 0.4288\n",
      "Epoch 396/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2789 - sparse_categorical_accuracy: 0.4976 - val_loss: 1.4860 - val_sparse_categorical_accuracy: 0.4225\n",
      "Epoch 397/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.3087 - sparse_categorical_accuracy: 0.4925 - val_loss: 1.4753 - val_sparse_categorical_accuracy: 0.4433\n",
      "Epoch 398/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3041 - sparse_categorical_accuracy: 0.4868 - val_loss: 1.4842 - val_sparse_categorical_accuracy: 0.4364\n",
      "Epoch 399/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2944 - sparse_categorical_accuracy: 0.4850 - val_loss: 1.4814 - val_sparse_categorical_accuracy: 0.4244\n",
      "Epoch 400/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3058 - sparse_categorical_accuracy: 0.4826 - val_loss: 1.4723 - val_sparse_categorical_accuracy: 0.4446\n",
      "Epoch 401/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2931 - sparse_categorical_accuracy: 0.4898 - val_loss: 1.4657 - val_sparse_categorical_accuracy: 0.4263\n",
      "Epoch 402/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2819 - sparse_categorical_accuracy: 0.4970 - val_loss: 1.4949 - val_sparse_categorical_accuracy: 0.4232\n",
      "Epoch 403/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2841 - sparse_categorical_accuracy: 0.4880 - val_loss: 1.5020 - val_sparse_categorical_accuracy: 0.4263\n",
      "Epoch 404/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2841 - sparse_categorical_accuracy: 0.4904 - val_loss: 1.4809 - val_sparse_categorical_accuracy: 0.4377\n",
      "Epoch 405/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2687 - sparse_categorical_accuracy: 0.4937 - val_loss: 1.4881 - val_sparse_categorical_accuracy: 0.4458\n",
      "Epoch 406/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2874 - sparse_categorical_accuracy: 0.4859 - val_loss: 1.4624 - val_sparse_categorical_accuracy: 0.4440\n",
      "Epoch 407/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2915 - sparse_categorical_accuracy: 0.4805 - val_loss: 1.5002 - val_sparse_categorical_accuracy: 0.4207\n",
      "Epoch 408/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.3023 - sparse_categorical_accuracy: 0.4805 - val_loss: 1.4938 - val_sparse_categorical_accuracy: 0.4395\n",
      "Epoch 409/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2861 - sparse_categorical_accuracy: 0.4904 - val_loss: 1.4721 - val_sparse_categorical_accuracy: 0.4408\n",
      "Epoch 410/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2985 - sparse_categorical_accuracy: 0.4961 - val_loss: 1.4664 - val_sparse_categorical_accuracy: 0.4364\n",
      "Epoch 411/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2737 - sparse_categorical_accuracy: 0.4901 - val_loss: 1.4596 - val_sparse_categorical_accuracy: 0.4427\n",
      "Epoch 412/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2656 - sparse_categorical_accuracy: 0.5087 - val_loss: 1.4567 - val_sparse_categorical_accuracy: 0.4446\n",
      "Epoch 413/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2909 - sparse_categorical_accuracy: 0.4925 - val_loss: 1.4641 - val_sparse_categorical_accuracy: 0.4433\n",
      "Epoch 414/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2815 - sparse_categorical_accuracy: 0.4964 - val_loss: 1.4740 - val_sparse_categorical_accuracy: 0.4314\n",
      "Epoch 415/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2859 - sparse_categorical_accuracy: 0.4970 - val_loss: 1.4786 - val_sparse_categorical_accuracy: 0.4377\n",
      "Epoch 416/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2807 - sparse_categorical_accuracy: 0.4856 - val_loss: 1.4484 - val_sparse_categorical_accuracy: 0.4433\n",
      "Epoch 417/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2741 - sparse_categorical_accuracy: 0.5033 - val_loss: 1.4609 - val_sparse_categorical_accuracy: 0.4377\n",
      "Epoch 418/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2797 - sparse_categorical_accuracy: 0.4877 - val_loss: 1.4511 - val_sparse_categorical_accuracy: 0.4490\n",
      "Epoch 419/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2876 - sparse_categorical_accuracy: 0.4964 - val_loss: 1.4732 - val_sparse_categorical_accuracy: 0.4351\n",
      "Epoch 420/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2846 - sparse_categorical_accuracy: 0.4856 - val_loss: 1.4714 - val_sparse_categorical_accuracy: 0.4433\n",
      "Epoch 421/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2766 - sparse_categorical_accuracy: 0.4805 - val_loss: 1.4802 - val_sparse_categorical_accuracy: 0.4446\n",
      "Epoch 422/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2838 - sparse_categorical_accuracy: 0.4889 - val_loss: 1.4911 - val_sparse_categorical_accuracy: 0.4408\n",
      "Epoch 423/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2712 - sparse_categorical_accuracy: 0.4943 - val_loss: 1.4777 - val_sparse_categorical_accuracy: 0.4484\n",
      "Epoch 424/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2619 - sparse_categorical_accuracy: 0.5069 - val_loss: 1.4779 - val_sparse_categorical_accuracy: 0.4389\n",
      "Epoch 425/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2802 - sparse_categorical_accuracy: 0.4898 - val_loss: 1.4653 - val_sparse_categorical_accuracy: 0.4465\n",
      "Epoch 426/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2572 - sparse_categorical_accuracy: 0.5000 - val_loss: 1.5164 - val_sparse_categorical_accuracy: 0.4377\n",
      "Epoch 427/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2735 - sparse_categorical_accuracy: 0.4952 - val_loss: 1.4807 - val_sparse_categorical_accuracy: 0.4440\n",
      "Epoch 428/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2610 - sparse_categorical_accuracy: 0.5033 - val_loss: 1.4705 - val_sparse_categorical_accuracy: 0.4458\n",
      "Epoch 429/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2746 - sparse_categorical_accuracy: 0.4862 - val_loss: 1.4928 - val_sparse_categorical_accuracy: 0.4465\n",
      "Epoch 430/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2761 - sparse_categorical_accuracy: 0.4853 - val_loss: 1.4679 - val_sparse_categorical_accuracy: 0.4484\n",
      "Epoch 431/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2601 - sparse_categorical_accuracy: 0.5075 - val_loss: 1.4524 - val_sparse_categorical_accuracy: 0.4433\n",
      "Epoch 432/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2867 - sparse_categorical_accuracy: 0.4811 - val_loss: 1.4607 - val_sparse_categorical_accuracy: 0.4515\n",
      "Epoch 433/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2631 - sparse_categorical_accuracy: 0.4904 - val_loss: 1.4556 - val_sparse_categorical_accuracy: 0.4465\n",
      "Epoch 434/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2715 - sparse_categorical_accuracy: 0.5006 - val_loss: 1.4708 - val_sparse_categorical_accuracy: 0.4465\n",
      "Epoch 435/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2510 - sparse_categorical_accuracy: 0.5042 - val_loss: 1.4691 - val_sparse_categorical_accuracy: 0.4503\n",
      "Epoch 436/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2694 - sparse_categorical_accuracy: 0.5057 - val_loss: 1.4915 - val_sparse_categorical_accuracy: 0.4395\n",
      "Epoch 437/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 2s 21ms/step - loss: 1.2761 - sparse_categorical_accuracy: 0.4889 - val_loss: 1.4885 - val_sparse_categorical_accuracy: 0.4490\n",
      "Epoch 438/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2718 - sparse_categorical_accuracy: 0.4838 - val_loss: 1.4657 - val_sparse_categorical_accuracy: 0.4490\n",
      "Epoch 439/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.2450 - sparse_categorical_accuracy: 0.5192 - val_loss: 1.4681 - val_sparse_categorical_accuracy: 0.4465\n",
      "Epoch 440/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2701 - sparse_categorical_accuracy: 0.4976 - val_loss: 1.4492 - val_sparse_categorical_accuracy: 0.4521\n",
      "Epoch 441/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2481 - sparse_categorical_accuracy: 0.5012 - val_loss: 1.4633 - val_sparse_categorical_accuracy: 0.4458\n",
      "Epoch 442/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2671 - sparse_categorical_accuracy: 0.4973 - val_loss: 1.4412 - val_sparse_categorical_accuracy: 0.4534\n",
      "Epoch 443/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2571 - sparse_categorical_accuracy: 0.4850 - val_loss: 1.4573 - val_sparse_categorical_accuracy: 0.4446\n",
      "Epoch 444/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2753 - sparse_categorical_accuracy: 0.5009 - val_loss: 1.4623 - val_sparse_categorical_accuracy: 0.4553\n",
      "Epoch 445/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2566 - sparse_categorical_accuracy: 0.4952 - val_loss: 1.4639 - val_sparse_categorical_accuracy: 0.4490\n",
      "Epoch 446/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2520 - sparse_categorical_accuracy: 0.4964 - val_loss: 1.4734 - val_sparse_categorical_accuracy: 0.4408\n",
      "Epoch 447/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2476 - sparse_categorical_accuracy: 0.5060 - val_loss: 1.4567 - val_sparse_categorical_accuracy: 0.4553\n",
      "Epoch 448/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2606 - sparse_categorical_accuracy: 0.5021 - val_loss: 1.4661 - val_sparse_categorical_accuracy: 0.4534\n",
      "Epoch 449/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.2517 - sparse_categorical_accuracy: 0.4952 - val_loss: 1.4468 - val_sparse_categorical_accuracy: 0.4395\n",
      "Epoch 450/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2469 - sparse_categorical_accuracy: 0.5141 - val_loss: 1.4565 - val_sparse_categorical_accuracy: 0.4458\n",
      "Epoch 451/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2464 - sparse_categorical_accuracy: 0.5015 - val_loss: 1.4582 - val_sparse_categorical_accuracy: 0.4553\n",
      "Epoch 452/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2484 - sparse_categorical_accuracy: 0.5072 - val_loss: 1.4930 - val_sparse_categorical_accuracy: 0.4389\n",
      "Epoch 453/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2345 - sparse_categorical_accuracy: 0.5075 - val_loss: 1.4793 - val_sparse_categorical_accuracy: 0.4547\n",
      "Epoch 454/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2509 - sparse_categorical_accuracy: 0.5036 - val_loss: 1.4607 - val_sparse_categorical_accuracy: 0.4584\n",
      "Epoch 455/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2502 - sparse_categorical_accuracy: 0.5093 - val_loss: 1.4427 - val_sparse_categorical_accuracy: 0.4540\n",
      "Epoch 456/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.2525 - sparse_categorical_accuracy: 0.5072 - val_loss: 1.4571 - val_sparse_categorical_accuracy: 0.4610\n",
      "Epoch 457/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2405 - sparse_categorical_accuracy: 0.5120 - val_loss: 1.4622 - val_sparse_categorical_accuracy: 0.4427\n",
      "Epoch 458/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2393 - sparse_categorical_accuracy: 0.5195 - val_loss: 1.4553 - val_sparse_categorical_accuracy: 0.4578\n",
      "Epoch 459/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2432 - sparse_categorical_accuracy: 0.5078 - val_loss: 1.4531 - val_sparse_categorical_accuracy: 0.4559\n",
      "Epoch 460/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2411 - sparse_categorical_accuracy: 0.5141 - val_loss: 1.4487 - val_sparse_categorical_accuracy: 0.4578\n",
      "Epoch 461/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2332 - sparse_categorical_accuracy: 0.5177 - val_loss: 1.4512 - val_sparse_categorical_accuracy: 0.4679\n",
      "Epoch 462/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.2287 - sparse_categorical_accuracy: 0.5102 - val_loss: 1.4442 - val_sparse_categorical_accuracy: 0.4591\n",
      "Epoch 463/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2469 - sparse_categorical_accuracy: 0.5159 - val_loss: 1.4778 - val_sparse_categorical_accuracy: 0.4534\n",
      "Epoch 464/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2557 - sparse_categorical_accuracy: 0.5033 - val_loss: 1.4519 - val_sparse_categorical_accuracy: 0.4471\n",
      "Epoch 465/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2441 - sparse_categorical_accuracy: 0.5084 - val_loss: 1.4454 - val_sparse_categorical_accuracy: 0.4591\n",
      "Epoch 466/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2347 - sparse_categorical_accuracy: 0.5027 - val_loss: 1.4771 - val_sparse_categorical_accuracy: 0.4427\n",
      "Epoch 467/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2267 - sparse_categorical_accuracy: 0.5111 - val_loss: 1.4467 - val_sparse_categorical_accuracy: 0.4597\n",
      "Epoch 468/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2327 - sparse_categorical_accuracy: 0.5210 - val_loss: 1.4444 - val_sparse_categorical_accuracy: 0.4610\n",
      "Epoch 469/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.2362 - sparse_categorical_accuracy: 0.5021 - val_loss: 1.4510 - val_sparse_categorical_accuracy: 0.4603\n",
      "Epoch 470/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2289 - sparse_categorical_accuracy: 0.5156 - val_loss: 1.4825 - val_sparse_categorical_accuracy: 0.4572\n",
      "Epoch 471/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2329 - sparse_categorical_accuracy: 0.5234 - val_loss: 1.4555 - val_sparse_categorical_accuracy: 0.4465\n",
      "Epoch 472/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2396 - sparse_categorical_accuracy: 0.5090 - val_loss: 1.4599 - val_sparse_categorical_accuracy: 0.4427\n",
      "Epoch 473/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2324 - sparse_categorical_accuracy: 0.5060 - val_loss: 1.4298 - val_sparse_categorical_accuracy: 0.4673\n",
      "Epoch 474/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2284 - sparse_categorical_accuracy: 0.5159 - val_loss: 1.4710 - val_sparse_categorical_accuracy: 0.4427\n",
      "Epoch 475/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2265 - sparse_categorical_accuracy: 0.5132 - val_loss: 1.4562 - val_sparse_categorical_accuracy: 0.4427\n",
      "Epoch 476/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2389 - sparse_categorical_accuracy: 0.5066 - val_loss: 1.4529 - val_sparse_categorical_accuracy: 0.4509\n",
      "Epoch 477/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2202 - sparse_categorical_accuracy: 0.5159 - val_loss: 1.4573 - val_sparse_categorical_accuracy: 0.4540\n",
      "Epoch 478/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2353 - sparse_categorical_accuracy: 0.5102 - val_loss: 1.4421 - val_sparse_categorical_accuracy: 0.4547\n",
      "Epoch 479/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1922 - sparse_categorical_accuracy: 0.5255 - val_loss: 1.4438 - val_sparse_categorical_accuracy: 0.4679\n",
      "Epoch 480/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2197 - sparse_categorical_accuracy: 0.5078 - val_loss: 1.4671 - val_sparse_categorical_accuracy: 0.4440\n",
      "Epoch 481/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 2s 21ms/step - loss: 1.2213 - sparse_categorical_accuracy: 0.5147 - val_loss: 1.4377 - val_sparse_categorical_accuracy: 0.4471\n",
      "Epoch 482/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2169 - sparse_categorical_accuracy: 0.5186 - val_loss: 1.4444 - val_sparse_categorical_accuracy: 0.4591\n",
      "Epoch 483/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2239 - sparse_categorical_accuracy: 0.5210 - val_loss: 1.4322 - val_sparse_categorical_accuracy: 0.4635\n",
      "Epoch 484/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2290 - sparse_categorical_accuracy: 0.5180 - val_loss: 1.4598 - val_sparse_categorical_accuracy: 0.4515\n",
      "Epoch 485/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2123 - sparse_categorical_accuracy: 0.5141 - val_loss: 1.4151 - val_sparse_categorical_accuracy: 0.4446\n",
      "Epoch 486/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2271 - sparse_categorical_accuracy: 0.5183 - val_loss: 1.4594 - val_sparse_categorical_accuracy: 0.4572\n",
      "Epoch 487/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2238 - sparse_categorical_accuracy: 0.5129 - val_loss: 1.4662 - val_sparse_categorical_accuracy: 0.4521\n",
      "Epoch 488/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2288 - sparse_categorical_accuracy: 0.5024 - val_loss: 1.4471 - val_sparse_categorical_accuracy: 0.4704\n",
      "Epoch 489/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2207 - sparse_categorical_accuracy: 0.5183 - val_loss: 1.4397 - val_sparse_categorical_accuracy: 0.4521\n",
      "Epoch 490/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2173 - sparse_categorical_accuracy: 0.5117 - val_loss: 1.4438 - val_sparse_categorical_accuracy: 0.4572\n",
      "Epoch 491/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2034 - sparse_categorical_accuracy: 0.5234 - val_loss: 1.4371 - val_sparse_categorical_accuracy: 0.4717\n",
      "Epoch 492/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2208 - sparse_categorical_accuracy: 0.5141 - val_loss: 1.4336 - val_sparse_categorical_accuracy: 0.4710\n",
      "Epoch 493/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2238 - sparse_categorical_accuracy: 0.5105 - val_loss: 1.4561 - val_sparse_categorical_accuracy: 0.4603\n",
      "Epoch 494/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2024 - sparse_categorical_accuracy: 0.5192 - val_loss: 1.4624 - val_sparse_categorical_accuracy: 0.4503\n",
      "Epoch 495/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2348 - sparse_categorical_accuracy: 0.5087 - val_loss: 1.4567 - val_sparse_categorical_accuracy: 0.4616\n",
      "Epoch 496/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2073 - sparse_categorical_accuracy: 0.5243 - val_loss: 1.4369 - val_sparse_categorical_accuracy: 0.4597\n",
      "Epoch 497/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2219 - sparse_categorical_accuracy: 0.5063 - val_loss: 1.4329 - val_sparse_categorical_accuracy: 0.4440\n",
      "Epoch 498/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2227 - sparse_categorical_accuracy: 0.5237 - val_loss: 1.4313 - val_sparse_categorical_accuracy: 0.4597\n",
      "Epoch 499/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2245 - sparse_categorical_accuracy: 0.5075 - val_loss: 1.4793 - val_sparse_categorical_accuracy: 0.4528\n",
      "Epoch 500/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2106 - sparse_categorical_accuracy: 0.5237 - val_loss: 1.4591 - val_sparse_categorical_accuracy: 0.4641\n",
      "Epoch 501/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2210 - sparse_categorical_accuracy: 0.5054 - val_loss: 1.4440 - val_sparse_categorical_accuracy: 0.4534\n",
      "Epoch 502/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2159 - sparse_categorical_accuracy: 0.5135 - val_loss: 1.4244 - val_sparse_categorical_accuracy: 0.4503\n",
      "Epoch 503/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2065 - sparse_categorical_accuracy: 0.5072 - val_loss: 1.4313 - val_sparse_categorical_accuracy: 0.4503\n",
      "Epoch 504/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.1910 - sparse_categorical_accuracy: 0.5273 - val_loss: 1.4441 - val_sparse_categorical_accuracy: 0.4440\n",
      "Epoch 505/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2107 - sparse_categorical_accuracy: 0.5207 - val_loss: 1.4452 - val_sparse_categorical_accuracy: 0.4635\n",
      "Epoch 506/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2034 - sparse_categorical_accuracy: 0.5168 - val_loss: 1.4229 - val_sparse_categorical_accuracy: 0.4647\n",
      "Epoch 507/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2045 - sparse_categorical_accuracy: 0.5159 - val_loss: 1.4292 - val_sparse_categorical_accuracy: 0.4528\n",
      "Epoch 508/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2068 - sparse_categorical_accuracy: 0.5195 - val_loss: 1.4215 - val_sparse_categorical_accuracy: 0.4540\n",
      "Epoch 509/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2121 - sparse_categorical_accuracy: 0.5210 - val_loss: 1.4245 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 510/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2246 - sparse_categorical_accuracy: 0.5063 - val_loss: 1.4463 - val_sparse_categorical_accuracy: 0.4471\n",
      "Epoch 511/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2071 - sparse_categorical_accuracy: 0.5174 - val_loss: 1.4230 - val_sparse_categorical_accuracy: 0.4603\n",
      "Epoch 512/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2072 - sparse_categorical_accuracy: 0.5195 - val_loss: 1.4352 - val_sparse_categorical_accuracy: 0.4679\n",
      "Epoch 513/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2158 - sparse_categorical_accuracy: 0.5099 - val_loss: 1.4178 - val_sparse_categorical_accuracy: 0.4698\n",
      "Epoch 514/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.2154 - sparse_categorical_accuracy: 0.5165 - val_loss: 1.4367 - val_sparse_categorical_accuracy: 0.4717\n",
      "Epoch 515/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1988 - sparse_categorical_accuracy: 0.5189 - val_loss: 1.4433 - val_sparse_categorical_accuracy: 0.4666\n",
      "Epoch 516/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1855 - sparse_categorical_accuracy: 0.5291 - val_loss: 1.4425 - val_sparse_categorical_accuracy: 0.4559\n",
      "Epoch 517/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.2063 - sparse_categorical_accuracy: 0.5204 - val_loss: 1.4721 - val_sparse_categorical_accuracy: 0.4628\n",
      "Epoch 518/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2035 - sparse_categorical_accuracy: 0.5153 - val_loss: 1.4531 - val_sparse_categorical_accuracy: 0.4540\n",
      "Epoch 519/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1842 - sparse_categorical_accuracy: 0.5285 - val_loss: 1.4510 - val_sparse_categorical_accuracy: 0.4597\n",
      "Epoch 520/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1905 - sparse_categorical_accuracy: 0.5312 - val_loss: 1.4400 - val_sparse_categorical_accuracy: 0.4641\n",
      "Epoch 521/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.1877 - sparse_categorical_accuracy: 0.5306 - val_loss: 1.4378 - val_sparse_categorical_accuracy: 0.4679\n",
      "Epoch 522/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1871 - sparse_categorical_accuracy: 0.5324 - val_loss: 1.4410 - val_sparse_categorical_accuracy: 0.4471\n",
      "Epoch 523/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1878 - sparse_categorical_accuracy: 0.5243 - val_loss: 1.4333 - val_sparse_categorical_accuracy: 0.4553\n",
      "Epoch 524/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.1970 - sparse_categorical_accuracy: 0.5171 - val_loss: 1.4571 - val_sparse_categorical_accuracy: 0.4685\n",
      "Epoch 525/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 2s 19ms/step - loss: 1.2110 - sparse_categorical_accuracy: 0.5204 - val_loss: 1.4579 - val_sparse_categorical_accuracy: 0.4534\n",
      "Epoch 526/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2000 - sparse_categorical_accuracy: 0.5177 - val_loss: 1.4253 - val_sparse_categorical_accuracy: 0.4830\n",
      "Epoch 527/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2028 - sparse_categorical_accuracy: 0.5255 - val_loss: 1.4192 - val_sparse_categorical_accuracy: 0.4685\n",
      "Epoch 528/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.2095 - sparse_categorical_accuracy: 0.5198 - val_loss: 1.4338 - val_sparse_categorical_accuracy: 0.4553\n",
      "Epoch 529/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.1923 - sparse_categorical_accuracy: 0.5219 - val_loss: 1.4280 - val_sparse_categorical_accuracy: 0.4641\n",
      "Epoch 530/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1975 - sparse_categorical_accuracy: 0.5102 - val_loss: 1.4337 - val_sparse_categorical_accuracy: 0.4578\n",
      "Epoch 531/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1998 - sparse_categorical_accuracy: 0.5219 - val_loss: 1.4310 - val_sparse_categorical_accuracy: 0.4547\n",
      "Epoch 532/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1905 - sparse_categorical_accuracy: 0.5249 - val_loss: 1.4335 - val_sparse_categorical_accuracy: 0.4704\n",
      "Epoch 533/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1791 - sparse_categorical_accuracy: 0.5240 - val_loss: 1.4216 - val_sparse_categorical_accuracy: 0.4654\n",
      "Epoch 534/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1882 - sparse_categorical_accuracy: 0.5195 - val_loss: 1.4413 - val_sparse_categorical_accuracy: 0.4710\n",
      "Epoch 535/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1909 - sparse_categorical_accuracy: 0.5147 - val_loss: 1.4390 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 536/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1893 - sparse_categorical_accuracy: 0.5231 - val_loss: 1.4241 - val_sparse_categorical_accuracy: 0.4698\n",
      "Epoch 537/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1965 - sparse_categorical_accuracy: 0.5150 - val_loss: 1.4283 - val_sparse_categorical_accuracy: 0.4767\n",
      "Epoch 538/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1827 - sparse_categorical_accuracy: 0.5285 - val_loss: 1.4193 - val_sparse_categorical_accuracy: 0.4666\n",
      "Epoch 539/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1795 - sparse_categorical_accuracy: 0.5312 - val_loss: 1.4381 - val_sparse_categorical_accuracy: 0.4647\n",
      "Epoch 540/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1725 - sparse_categorical_accuracy: 0.5369 - val_loss: 1.4108 - val_sparse_categorical_accuracy: 0.4761\n",
      "Epoch 541/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.1871 - sparse_categorical_accuracy: 0.5297 - val_loss: 1.4347 - val_sparse_categorical_accuracy: 0.4635\n",
      "Epoch 542/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1751 - sparse_categorical_accuracy: 0.5279 - val_loss: 1.4337 - val_sparse_categorical_accuracy: 0.4704\n",
      "Epoch 543/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1664 - sparse_categorical_accuracy: 0.5384 - val_loss: 1.4164 - val_sparse_categorical_accuracy: 0.4673\n",
      "Epoch 544/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1626 - sparse_categorical_accuracy: 0.5285 - val_loss: 1.4163 - val_sparse_categorical_accuracy: 0.4641\n",
      "Epoch 545/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1964 - sparse_categorical_accuracy: 0.5276 - val_loss: 1.4262 - val_sparse_categorical_accuracy: 0.4685\n",
      "Epoch 546/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.1761 - sparse_categorical_accuracy: 0.5354 - val_loss: 1.4198 - val_sparse_categorical_accuracy: 0.4635\n",
      "Epoch 547/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1772 - sparse_categorical_accuracy: 0.5300 - val_loss: 1.4394 - val_sparse_categorical_accuracy: 0.4679\n",
      "Epoch 548/600\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 1.1742 - sparse_categorical_accuracy: 0.5318 - val_loss: 1.4265 - val_sparse_categorical_accuracy: 0.4616\n",
      "Epoch 549/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.1857 - sparse_categorical_accuracy: 0.5297 - val_loss: 1.4359 - val_sparse_categorical_accuracy: 0.4616\n",
      "Epoch 550/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.1771 - sparse_categorical_accuracy: 0.5336 - val_loss: 1.4196 - val_sparse_categorical_accuracy: 0.4723\n",
      "Epoch 551/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.1786 - sparse_categorical_accuracy: 0.5306 - val_loss: 1.4204 - val_sparse_categorical_accuracy: 0.4584\n",
      "Epoch 552/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1775 - sparse_categorical_accuracy: 0.5309 - val_loss: 1.4284 - val_sparse_categorical_accuracy: 0.4647\n",
      "Epoch 553/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.1833 - sparse_categorical_accuracy: 0.5252 - val_loss: 1.4357 - val_sparse_categorical_accuracy: 0.4540\n",
      "Epoch 554/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.1577 - sparse_categorical_accuracy: 0.5414 - val_loss: 1.4340 - val_sparse_categorical_accuracy: 0.4622\n",
      "Epoch 555/600\n",
      "105/105 [==============================] - 2s 18ms/step - loss: 1.1812 - sparse_categorical_accuracy: 0.5324 - val_loss: 1.4203 - val_sparse_categorical_accuracy: 0.4717\n",
      "Epoch 556/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1770 - sparse_categorical_accuracy: 0.5327 - val_loss: 1.4432 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 557/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1776 - sparse_categorical_accuracy: 0.5279 - val_loss: 1.4273 - val_sparse_categorical_accuracy: 0.4673\n",
      "Epoch 558/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1860 - sparse_categorical_accuracy: 0.5327 - val_loss: 1.4449 - val_sparse_categorical_accuracy: 0.4698\n",
      "Epoch 559/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1761 - sparse_categorical_accuracy: 0.5318 - val_loss: 1.4221 - val_sparse_categorical_accuracy: 0.4654\n",
      "Epoch 560/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1714 - sparse_categorical_accuracy: 0.5318 - val_loss: 1.4198 - val_sparse_categorical_accuracy: 0.4647\n",
      "Epoch 561/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1797 - sparse_categorical_accuracy: 0.5249 - val_loss: 1.4175 - val_sparse_categorical_accuracy: 0.4786\n",
      "Epoch 562/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1785 - sparse_categorical_accuracy: 0.5447 - val_loss: 1.4199 - val_sparse_categorical_accuracy: 0.4798\n",
      "Epoch 563/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.1725 - sparse_categorical_accuracy: 0.5369 - val_loss: 1.4395 - val_sparse_categorical_accuracy: 0.4597\n",
      "Epoch 564/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.1544 - sparse_categorical_accuracy: 0.5456 - val_loss: 1.4139 - val_sparse_categorical_accuracy: 0.4792\n",
      "Epoch 565/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1649 - sparse_categorical_accuracy: 0.5315 - val_loss: 1.4392 - val_sparse_categorical_accuracy: 0.4616\n",
      "Epoch 566/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1709 - sparse_categorical_accuracy: 0.5261 - val_loss: 1.4308 - val_sparse_categorical_accuracy: 0.4698\n",
      "Epoch 567/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1744 - sparse_categorical_accuracy: 0.5336 - val_loss: 1.4041 - val_sparse_categorical_accuracy: 0.4830\n",
      "Epoch 568/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.1741 - sparse_categorical_accuracy: 0.5327 - val_loss: 1.4181 - val_sparse_categorical_accuracy: 0.4798\n",
      "Epoch 569/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1737 - sparse_categorical_accuracy: 0.5306 - val_loss: 1.4298 - val_sparse_categorical_accuracy: 0.4691\n",
      "Epoch 570/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1705 - sparse_categorical_accuracy: 0.5324 - val_loss: 1.4086 - val_sparse_categorical_accuracy: 0.4798\n",
      "Epoch 571/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1563 - sparse_categorical_accuracy: 0.5390 - val_loss: 1.4135 - val_sparse_categorical_accuracy: 0.4647\n",
      "Epoch 572/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1681 - sparse_categorical_accuracy: 0.5375 - val_loss: 1.4328 - val_sparse_categorical_accuracy: 0.4610\n",
      "Epoch 573/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.1861 - sparse_categorical_accuracy: 0.5315 - val_loss: 1.4557 - val_sparse_categorical_accuracy: 0.4673\n",
      "Epoch 574/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1665 - sparse_categorical_accuracy: 0.5291 - val_loss: 1.4091 - val_sparse_categorical_accuracy: 0.4723\n",
      "Epoch 575/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1766 - sparse_categorical_accuracy: 0.5261 - val_loss: 1.4381 - val_sparse_categorical_accuracy: 0.4616\n",
      "Epoch 576/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1668 - sparse_categorical_accuracy: 0.5354 - val_loss: 1.4282 - val_sparse_categorical_accuracy: 0.4704\n",
      "Epoch 577/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1584 - sparse_categorical_accuracy: 0.5387 - val_loss: 1.4141 - val_sparse_categorical_accuracy: 0.4729\n",
      "Epoch 578/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1667 - sparse_categorical_accuracy: 0.5246 - val_loss: 1.4533 - val_sparse_categorical_accuracy: 0.4597\n",
      "Epoch 579/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1776 - sparse_categorical_accuracy: 0.5216 - val_loss: 1.4465 - val_sparse_categorical_accuracy: 0.4654\n",
      "Epoch 580/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1619 - sparse_categorical_accuracy: 0.5447 - val_loss: 1.4163 - val_sparse_categorical_accuracy: 0.4761\n",
      "Epoch 581/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.1500 - sparse_categorical_accuracy: 0.5441 - val_loss: 1.4221 - val_sparse_categorical_accuracy: 0.4767\n",
      "Epoch 582/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1636 - sparse_categorical_accuracy: 0.5366 - val_loss: 1.4326 - val_sparse_categorical_accuracy: 0.4666\n",
      "Epoch 583/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1468 - sparse_categorical_accuracy: 0.5441 - val_loss: 1.4147 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 584/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1587 - sparse_categorical_accuracy: 0.5345 - val_loss: 1.4219 - val_sparse_categorical_accuracy: 0.4824\n",
      "Epoch 585/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1525 - sparse_categorical_accuracy: 0.5384 - val_loss: 1.4420 - val_sparse_categorical_accuracy: 0.4635\n",
      "Epoch 586/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1417 - sparse_categorical_accuracy: 0.5507 - val_loss: 1.4091 - val_sparse_categorical_accuracy: 0.4685\n",
      "Epoch 587/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1574 - sparse_categorical_accuracy: 0.5309 - val_loss: 1.4193 - val_sparse_categorical_accuracy: 0.4572\n",
      "Epoch 588/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.1598 - sparse_categorical_accuracy: 0.5423 - val_loss: 1.4117 - val_sparse_categorical_accuracy: 0.4748\n",
      "Epoch 589/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1514 - sparse_categorical_accuracy: 0.5387 - val_loss: 1.4122 - val_sparse_categorical_accuracy: 0.4654\n",
      "Epoch 590/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1459 - sparse_categorical_accuracy: 0.5432 - val_loss: 1.4096 - val_sparse_categorical_accuracy: 0.4805\n",
      "Epoch 591/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1364 - sparse_categorical_accuracy: 0.5492 - val_loss: 1.4098 - val_sparse_categorical_accuracy: 0.4647\n",
      "Epoch 592/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.1639 - sparse_categorical_accuracy: 0.5459 - val_loss: 1.3956 - val_sparse_categorical_accuracy: 0.4673\n",
      "Epoch 593/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1598 - sparse_categorical_accuracy: 0.5294 - val_loss: 1.4026 - val_sparse_categorical_accuracy: 0.4780\n",
      "Epoch 594/600\n",
      "105/105 [==============================] - 2s 19ms/step - loss: 1.1518 - sparse_categorical_accuracy: 0.5336 - val_loss: 1.3989 - val_sparse_categorical_accuracy: 0.4761\n",
      "Epoch 595/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1537 - sparse_categorical_accuracy: 0.5396 - val_loss: 1.4155 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 596/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1529 - sparse_categorical_accuracy: 0.5438 - val_loss: 1.4092 - val_sparse_categorical_accuracy: 0.4767\n",
      "Epoch 597/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.1614 - sparse_categorical_accuracy: 0.5279 - val_loss: 1.4235 - val_sparse_categorical_accuracy: 0.4679\n",
      "Epoch 598/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1497 - sparse_categorical_accuracy: 0.5432 - val_loss: 1.4061 - val_sparse_categorical_accuracy: 0.4704\n",
      "Epoch 599/600\n",
      "105/105 [==============================] - 2s 20ms/step - loss: 1.1400 - sparse_categorical_accuracy: 0.5414 - val_loss: 1.4247 - val_sparse_categorical_accuracy: 0.4723\n",
      "Epoch 600/600\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 1.1396 - sparse_categorical_accuracy: 0.5474 - val_loss: 1.4172 - val_sparse_categorical_accuracy: 0.4729\n",
      "Accuracy of the model on test set: 47.292%\n",
      "Accuracy of the model on validation set: 48.787%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "np.random.seed = 123\n",
    "\n",
    "y = Data_train.Emotion\n",
    "X = pd.DataFrame(Data_train.drop(['Emotion','User'], axis = 1))\n",
    "\n",
    "#y_val = Data_val.Emotion\n",
    "#X_val = pd.DataFrame(Data_val.drop(['Emotion', 'User'], axis = 1))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 123)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 123)\n",
    "\n",
    "\n",
    "#Trying adam optimizer\n",
    "model = initModelGRU(X.shape[1], 7, 'softmax') \n",
    "\n",
    "#model = initModelBasic(X.shape[1], 7)\n",
    "model.compile(\n",
    "    optimizer= 'adam',\n",
    "    loss='sparse_categorical_crossentropy', # sparse because using integer labels for emotions (not OHE)\n",
    "    metrics=[ 'sparse_categorical_accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    #validation_split = 0.3,\n",
    "    #validation_data = (X_val, y_val),\n",
    "    validation_data = (X_test, y_test),\n",
    "    epochs=600,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_sparse_categorical_accuracy',\n",
    "            patience=100,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Result on test data\n",
    "model_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(\"Accuracy of the model on test set: {:.3f}%\".format(model_acc * 100))\n",
    "\n",
    "#Result on val data\n",
    "model_acc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "print(\"Accuracy of the model on validation set: {:.3f}%\".format(model_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f77d41c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.03511801957397812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on test set: 18.408%\n",
      "Accuracy of the model on validation set: 18.538%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([1737])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "#model.save('8_features_train_test_16.983')\n",
    "#test 60.691  val 16.983\n",
    "#model = load_model('8_features_train_test') #val 19%!\n",
    "\n",
    "acc =tf.keras.metrics.sparse_categorical_accuracy(y_val, model.predict(X_val))\n",
    "acc.numpy()\n",
    "print(\"acc: \", accuracy_score(y_val, acc))\n",
    "\n",
    "\n",
    "model_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(\"Accuracy of the model on test set: {:.3f}%\".format(model_acc * 100))\n",
    "\n",
    "\n",
    "\n",
    "# Plot the accuracy curve for training\n",
    "#plt.plot(history.history['val_accuracy'], color='r', label=\"Accuracy\")\n",
    "\n",
    "plt.title(\"Validation accuracy\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "model_acc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "print(\"Accuracy of the model on validation set: {:.3f}%\".format(model_acc * 100))\n",
    "\n",
    "acc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f2f7d63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 9)]               0         \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (None, 9, 1)             0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 9, 256)            198912    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 16135     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 215,047\n",
      "Trainable params: 215,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "38/38 [==============================] - 4s 47ms/step - loss: 1.9661 - accuracy: 0.1556 - val_loss: 1.9222 - val_accuracy: 0.1762\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.9319 - accuracy: 0.1835 - val_loss: 1.9217 - val_accuracy: 0.1820\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.9220 - accuracy: 0.1811 - val_loss: 1.9028 - val_accuracy: 0.2107\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.9161 - accuracy: 0.1942 - val_loss: 1.9073 - val_accuracy: 0.2165\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.9197 - accuracy: 0.1778 - val_loss: 1.9098 - val_accuracy: 0.2241\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.9153 - accuracy: 0.2074 - val_loss: 1.8978 - val_accuracy: 0.1935\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.9063 - accuracy: 0.1959 - val_loss: 1.8900 - val_accuracy: 0.2414\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.9046 - accuracy: 0.2008 - val_loss: 1.8857 - val_accuracy: 0.2280\n",
      "Epoch 9/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8964 - accuracy: 0.2115 - val_loss: 1.8606 - val_accuracy: 0.2682\n",
      "Epoch 10/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8970 - accuracy: 0.2049 - val_loss: 1.8765 - val_accuracy: 0.2222\n",
      "Epoch 11/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8959 - accuracy: 0.2025 - val_loss: 1.8642 - val_accuracy: 0.2759\n",
      "Epoch 12/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.8876 - accuracy: 0.2354 - val_loss: 1.8639 - val_accuracy: 0.2395\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.8827 - accuracy: 0.2280 - val_loss: 1.8542 - val_accuracy: 0.2510\n",
      "Epoch 14/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8719 - accuracy: 0.2255 - val_loss: 1.8634 - val_accuracy: 0.2490\n",
      "Epoch 15/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8747 - accuracy: 0.2337 - val_loss: 1.8859 - val_accuracy: 0.2126\n",
      "Epoch 16/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8710 - accuracy: 0.2494 - val_loss: 1.8212 - val_accuracy: 0.2682\n",
      "Epoch 17/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8537 - accuracy: 0.2502 - val_loss: 1.8272 - val_accuracy: 0.2414\n",
      "Epoch 18/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.8570 - accuracy: 0.2519 - val_loss: 1.8242 - val_accuracy: 0.2625\n",
      "Epoch 19/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8554 - accuracy: 0.2510 - val_loss: 1.8168 - val_accuracy: 0.3161\n",
      "Epoch 20/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8521 - accuracy: 0.2494 - val_loss: 1.8458 - val_accuracy: 0.2816\n",
      "Epoch 21/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.8397 - accuracy: 0.2486 - val_loss: 1.8150 - val_accuracy: 0.2778\n",
      "Epoch 22/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8284 - accuracy: 0.2724 - val_loss: 1.8165 - val_accuracy: 0.2931\n",
      "Epoch 23/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8334 - accuracy: 0.2576 - val_loss: 1.8035 - val_accuracy: 0.2816\n",
      "Epoch 24/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8292 - accuracy: 0.2626 - val_loss: 1.8061 - val_accuracy: 0.2720\n",
      "Epoch 25/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8171 - accuracy: 0.2642 - val_loss: 1.7945 - val_accuracy: 0.3027\n",
      "Epoch 26/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8026 - accuracy: 0.2840 - val_loss: 1.7890 - val_accuracy: 0.2701\n",
      "Epoch 27/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.7913 - accuracy: 0.2955 - val_loss: 1.7922 - val_accuracy: 0.2989\n",
      "Epoch 28/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.7942 - accuracy: 0.2856 - val_loss: 1.7721 - val_accuracy: 0.2778\n",
      "Epoch 29/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7994 - accuracy: 0.2733 - val_loss: 1.8004 - val_accuracy: 0.3046\n",
      "Epoch 30/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7787 - accuracy: 0.2922 - val_loss: 1.7713 - val_accuracy: 0.2950\n",
      "Epoch 31/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7845 - accuracy: 0.2765 - val_loss: 1.7789 - val_accuracy: 0.3372\n",
      "Epoch 32/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.7715 - accuracy: 0.2914 - val_loss: 1.7928 - val_accuracy: 0.2739\n",
      "Epoch 33/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7793 - accuracy: 0.2782 - val_loss: 1.7694 - val_accuracy: 0.2931\n",
      "Epoch 34/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7575 - accuracy: 0.3111 - val_loss: 1.7505 - val_accuracy: 0.2874\n",
      "Epoch 35/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7412 - accuracy: 0.2947 - val_loss: 1.7608 - val_accuracy: 0.3142\n",
      "Epoch 36/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7309 - accuracy: 0.3062 - val_loss: 1.7236 - val_accuracy: 0.2912\n",
      "Epoch 37/1000\n",
      "38/38 [==============================] - 1s 40ms/step - loss: 1.7269 - accuracy: 0.3062 - val_loss: 1.7549 - val_accuracy: 0.2893\n",
      "Epoch 38/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.7238 - accuracy: 0.3045 - val_loss: 1.7565 - val_accuracy: 0.2893\n",
      "Epoch 39/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.7044 - accuracy: 0.3095 - val_loss: 1.7531 - val_accuracy: 0.2605\n",
      "Epoch 40/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.7036 - accuracy: 0.3226 - val_loss: 1.7157 - val_accuracy: 0.3276\n",
      "Epoch 41/1000\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 1.6841 - accuracy: 0.3144 - val_loss: 1.6986 - val_accuracy: 0.3142\n",
      "Epoch 42/1000\n",
      "38/38 [==============================] - 2s 48ms/step - loss: 1.6689 - accuracy: 0.3300 - val_loss: 1.7188 - val_accuracy: 0.3276\n",
      "Epoch 43/1000\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 1.6689 - accuracy: 0.3185 - val_loss: 1.6751 - val_accuracy: 0.3525\n",
      "Epoch 44/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.6648 - accuracy: 0.3267 - val_loss: 1.6855 - val_accuracy: 0.3257\n",
      "Epoch 45/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.6372 - accuracy: 0.3366 - val_loss: 1.6817 - val_accuracy: 0.3276\n",
      "Epoch 46/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.6425 - accuracy: 0.3267 - val_loss: 1.6552 - val_accuracy: 0.3640\n",
      "Epoch 47/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.6398 - accuracy: 0.3317 - val_loss: 1.6644 - val_accuracy: 0.3391\n",
      "Epoch 48/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.6132 - accuracy: 0.3481 - val_loss: 1.6434 - val_accuracy: 0.3716\n",
      "Epoch 49/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.5937 - accuracy: 0.3597 - val_loss: 1.6387 - val_accuracy: 0.3391\n",
      "Epoch 50/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.5942 - accuracy: 0.3457 - val_loss: 1.6051 - val_accuracy: 0.3525\n",
      "Epoch 51/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.5897 - accuracy: 0.3449 - val_loss: 1.6380 - val_accuracy: 0.3429\n",
      "Epoch 52/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.5639 - accuracy: 0.3728 - val_loss: 1.5930 - val_accuracy: 0.3544\n",
      "Epoch 53/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.5433 - accuracy: 0.3720 - val_loss: 1.6207 - val_accuracy: 0.3640\n",
      "Epoch 54/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5675 - accuracy: 0.3663 - val_loss: 1.6187 - val_accuracy: 0.3602\n",
      "Epoch 55/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5494 - accuracy: 0.3770 - val_loss: 1.5902 - val_accuracy: 0.3755\n",
      "Epoch 56/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.5262 - accuracy: 0.3712 - val_loss: 1.5532 - val_accuracy: 0.3640\n",
      "Epoch 57/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5206 - accuracy: 0.3761 - val_loss: 1.5460 - val_accuracy: 0.4023\n",
      "Epoch 58/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5175 - accuracy: 0.4016 - val_loss: 1.5668 - val_accuracy: 0.3602\n",
      "Epoch 59/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5154 - accuracy: 0.3860 - val_loss: 1.5388 - val_accuracy: 0.3774\n",
      "Epoch 60/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5000 - accuracy: 0.3893 - val_loss: 1.5381 - val_accuracy: 0.3774\n",
      "Epoch 61/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4843 - accuracy: 0.4123 - val_loss: 1.5952 - val_accuracy: 0.3238\n",
      "Epoch 62/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4773 - accuracy: 0.3959 - val_loss: 1.5598 - val_accuracy: 0.3448\n",
      "Epoch 63/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4781 - accuracy: 0.4074 - val_loss: 1.4844 - val_accuracy: 0.4272\n",
      "Epoch 64/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4428 - accuracy: 0.3992 - val_loss: 1.5117 - val_accuracy: 0.4368\n",
      "Epoch 65/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4390 - accuracy: 0.3926 - val_loss: 1.5630 - val_accuracy: 0.3927\n",
      "Epoch 66/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4525 - accuracy: 0.3951 - val_loss: 1.5329 - val_accuracy: 0.3621\n",
      "Epoch 67/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4327 - accuracy: 0.4288 - val_loss: 1.5145 - val_accuracy: 0.3870\n",
      "Epoch 68/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4532 - accuracy: 0.3934 - val_loss: 1.4805 - val_accuracy: 0.4330\n",
      "Epoch 69/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4135 - accuracy: 0.4313 - val_loss: 1.4607 - val_accuracy: 0.4253\n",
      "Epoch 70/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4071 - accuracy: 0.4214 - val_loss: 1.5036 - val_accuracy: 0.4042\n",
      "Epoch 71/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4097 - accuracy: 0.4239 - val_loss: 1.4817 - val_accuracy: 0.4119\n",
      "Epoch 72/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4084 - accuracy: 0.4091 - val_loss: 1.5304 - val_accuracy: 0.3870\n",
      "Epoch 73/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.3759 - accuracy: 0.4535 - val_loss: 1.4497 - val_accuracy: 0.4138\n",
      "Epoch 74/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3731 - accuracy: 0.4362 - val_loss: 1.4643 - val_accuracy: 0.4330\n",
      "Epoch 75/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3753 - accuracy: 0.4576 - val_loss: 1.4655 - val_accuracy: 0.4368\n",
      "Epoch 76/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3693 - accuracy: 0.4502 - val_loss: 1.4518 - val_accuracy: 0.4425\n",
      "Epoch 77/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3566 - accuracy: 0.4436 - val_loss: 1.4169 - val_accuracy: 0.4176\n",
      "Epoch 78/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.3651 - accuracy: 0.4387 - val_loss: 1.4515 - val_accuracy: 0.4004\n",
      "Epoch 79/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.3593 - accuracy: 0.4543 - val_loss: 1.4112 - val_accuracy: 0.4579\n",
      "Epoch 80/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.3385 - accuracy: 0.4543 - val_loss: 1.4286 - val_accuracy: 0.4502\n",
      "Epoch 81/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3449 - accuracy: 0.4568 - val_loss: 1.4086 - val_accuracy: 0.4272\n",
      "Epoch 82/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3381 - accuracy: 0.4601 - val_loss: 1.4298 - val_accuracy: 0.4540\n",
      "Epoch 83/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.3181 - accuracy: 0.4708 - val_loss: 1.3983 - val_accuracy: 0.4655\n",
      "Epoch 84/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.3264 - accuracy: 0.4658 - val_loss: 1.4243 - val_accuracy: 0.4004\n",
      "Epoch 85/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.3292 - accuracy: 0.4543 - val_loss: 1.4357 - val_accuracy: 0.4310\n",
      "Epoch 86/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.2780 - accuracy: 0.4872 - val_loss: 1.3853 - val_accuracy: 0.4406\n",
      "Epoch 87/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2921 - accuracy: 0.4675 - val_loss: 1.4128 - val_accuracy: 0.4272\n",
      "Epoch 88/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2789 - accuracy: 0.4765 - val_loss: 1.4092 - val_accuracy: 0.4444\n",
      "Epoch 89/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.2640 - accuracy: 0.4947 - val_loss: 1.3904 - val_accuracy: 0.4732\n",
      "Epoch 90/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2964 - accuracy: 0.4642 - val_loss: 1.4073 - val_accuracy: 0.4655\n",
      "Epoch 91/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2739 - accuracy: 0.4782 - val_loss: 1.3893 - val_accuracy: 0.4425\n",
      "Epoch 92/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.2584 - accuracy: 0.4930 - val_loss: 1.4007 - val_accuracy: 0.4444\n",
      "Epoch 93/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2714 - accuracy: 0.4848 - val_loss: 1.3558 - val_accuracy: 0.4847\n",
      "Epoch 94/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2566 - accuracy: 0.4938 - val_loss: 1.3715 - val_accuracy: 0.4713\n",
      "Epoch 95/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.2834 - accuracy: 0.4757 - val_loss: 1.3602 - val_accuracy: 0.4770\n",
      "Epoch 96/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.2656 - accuracy: 0.4864 - val_loss: 1.3667 - val_accuracy: 0.4713\n",
      "Epoch 97/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.2624 - accuracy: 0.4905 - val_loss: 1.3592 - val_accuracy: 0.4483\n",
      "Epoch 98/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.2294 - accuracy: 0.4996 - val_loss: 1.3742 - val_accuracy: 0.4464\n",
      "Epoch 99/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.2351 - accuracy: 0.4971 - val_loss: 1.3108 - val_accuracy: 0.4962\n",
      "Epoch 100/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2187 - accuracy: 0.5045 - val_loss: 1.2828 - val_accuracy: 0.5172\n",
      "Epoch 101/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.2010 - accuracy: 0.5021 - val_loss: 1.3359 - val_accuracy: 0.4483\n",
      "Epoch 102/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2150 - accuracy: 0.5029 - val_loss: 1.3436 - val_accuracy: 0.4674\n",
      "Epoch 103/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.2199 - accuracy: 0.5226 - val_loss: 1.3288 - val_accuracy: 0.4981\n",
      "Epoch 104/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.2127 - accuracy: 0.5103 - val_loss: 1.3377 - val_accuracy: 0.4866\n",
      "Epoch 105/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.1954 - accuracy: 0.5119 - val_loss: 1.3275 - val_accuracy: 0.4713\n",
      "Epoch 106/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.1776 - accuracy: 0.5226 - val_loss: 1.3134 - val_accuracy: 0.5057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2008 - accuracy: 0.5053 - val_loss: 1.3129 - val_accuracy: 0.4866\n",
      "Epoch 108/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1968 - accuracy: 0.5251 - val_loss: 1.2973 - val_accuracy: 0.4789\n",
      "Epoch 109/1000\n",
      "38/38 [==============================] - 2s 57ms/step - loss: 1.1777 - accuracy: 0.5136 - val_loss: 1.3076 - val_accuracy: 0.5077\n",
      "Epoch 110/1000\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.1519 - accuracy: 0.5284 - val_loss: 1.3027 - val_accuracy: 0.5077\n",
      "Epoch 111/1000\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 1.1545 - accuracy: 0.5333 - val_loss: 1.3478 - val_accuracy: 0.5096\n",
      "Epoch 112/1000\n",
      "38/38 [==============================] - 3s 92ms/step - loss: 1.1566 - accuracy: 0.5202 - val_loss: 1.3114 - val_accuracy: 0.4981\n",
      "Epoch 113/1000\n",
      "38/38 [==============================] - 3s 84ms/step - loss: 1.1667 - accuracy: 0.5284 - val_loss: 1.2720 - val_accuracy: 0.5268\n",
      "Epoch 114/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.1552 - accuracy: 0.5350 - val_loss: 1.2924 - val_accuracy: 0.5268\n",
      "Epoch 115/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.1688 - accuracy: 0.5202 - val_loss: 1.2600 - val_accuracy: 0.5230\n",
      "Epoch 116/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1511 - accuracy: 0.5235 - val_loss: 1.2568 - val_accuracy: 0.5249\n",
      "Epoch 117/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1509 - accuracy: 0.5465 - val_loss: 1.2540 - val_accuracy: 0.5172\n",
      "Epoch 118/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1255 - accuracy: 0.5440 - val_loss: 1.3337 - val_accuracy: 0.5038\n",
      "Epoch 119/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.1638 - accuracy: 0.5243 - val_loss: 1.2599 - val_accuracy: 0.5192\n",
      "Epoch 120/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1287 - accuracy: 0.5440 - val_loss: 1.3064 - val_accuracy: 0.4904\n",
      "Epoch 121/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.1218 - accuracy: 0.5374 - val_loss: 1.2939 - val_accuracy: 0.4904\n",
      "Epoch 122/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.1298 - accuracy: 0.5391 - val_loss: 1.3516 - val_accuracy: 0.5000\n",
      "Epoch 123/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1211 - accuracy: 0.5547 - val_loss: 1.2625 - val_accuracy: 0.5268\n",
      "Epoch 124/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0960 - accuracy: 0.5613 - val_loss: 1.3190 - val_accuracy: 0.4904\n",
      "Epoch 125/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1141 - accuracy: 0.5547 - val_loss: 1.2439 - val_accuracy: 0.5441\n",
      "Epoch 126/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1070 - accuracy: 0.5440 - val_loss: 1.2560 - val_accuracy: 0.5192\n",
      "Epoch 127/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1127 - accuracy: 0.5424 - val_loss: 1.3472 - val_accuracy: 0.4962\n",
      "Epoch 128/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1242 - accuracy: 0.5597 - val_loss: 1.2408 - val_accuracy: 0.5460\n",
      "Epoch 129/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.0925 - accuracy: 0.5646 - val_loss: 1.3133 - val_accuracy: 0.5000\n",
      "Epoch 130/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1287 - accuracy: 0.5399 - val_loss: 1.2655 - val_accuracy: 0.5077\n",
      "Epoch 131/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.1264 - accuracy: 0.5284 - val_loss: 1.2549 - val_accuracy: 0.5498\n",
      "Epoch 132/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.1118 - accuracy: 0.5490 - val_loss: 1.2450 - val_accuracy: 0.5498\n",
      "Epoch 133/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.0891 - accuracy: 0.5588 - val_loss: 1.3179 - val_accuracy: 0.5153\n",
      "Epoch 134/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0706 - accuracy: 0.5539 - val_loss: 1.2552 - val_accuracy: 0.5402\n",
      "Epoch 135/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1007 - accuracy: 0.5547 - val_loss: 1.2381 - val_accuracy: 0.5268\n",
      "Epoch 136/1000\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 1.1005 - accuracy: 0.5473 - val_loss: 1.2956 - val_accuracy: 0.4828\n",
      "Epoch 137/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.0820 - accuracy: 0.5350 - val_loss: 1.2561 - val_accuracy: 0.5287\n",
      "Epoch 138/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0846 - accuracy: 0.5317 - val_loss: 1.2588 - val_accuracy: 0.5517\n",
      "Epoch 139/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.0544 - accuracy: 0.5770 - val_loss: 1.2545 - val_accuracy: 0.5211\n",
      "Epoch 140/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.0725 - accuracy: 0.5737 - val_loss: 1.2638 - val_accuracy: 0.5134\n",
      "Epoch 141/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0633 - accuracy: 0.5580 - val_loss: 1.2467 - val_accuracy: 0.5307\n",
      "Epoch 142/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0681 - accuracy: 0.5588 - val_loss: 1.2845 - val_accuracy: 0.5211\n",
      "Epoch 143/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.0552 - accuracy: 0.5506 - val_loss: 1.2927 - val_accuracy: 0.5230\n",
      "Epoch 144/1000\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 1.0753 - accuracy: 0.5490 - val_loss: 1.2338 - val_accuracy: 0.5479\n",
      "Epoch 145/1000\n",
      "38/38 [==============================] - 2s 43ms/step - loss: 1.0703 - accuracy: 0.5564 - val_loss: 1.2353 - val_accuracy: 0.5230\n",
      "Epoch 146/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.0432 - accuracy: 0.5687 - val_loss: 1.2340 - val_accuracy: 0.5460\n",
      "Epoch 147/1000\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 1.0201 - accuracy: 0.5638 - val_loss: 1.2059 - val_accuracy: 0.5364\n",
      "Epoch 148/1000\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 1.0312 - accuracy: 0.5794 - val_loss: 1.2329 - val_accuracy: 0.5326\n",
      "Epoch 149/1000\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 1.0429 - accuracy: 0.5794 - val_loss: 1.2605 - val_accuracy: 0.5307\n",
      "Epoch 150/1000\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 1.0575 - accuracy: 0.5605 - val_loss: 1.2892 - val_accuracy: 0.5230\n",
      "Epoch 151/1000\n",
      "38/38 [==============================] - 3s 82ms/step - loss: 1.0228 - accuracy: 0.5868 - val_loss: 1.2095 - val_accuracy: 0.5517\n",
      "Epoch 152/1000\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 1.0542 - accuracy: 0.5712 - val_loss: 1.2583 - val_accuracy: 0.5211\n",
      "Epoch 153/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.0466 - accuracy: 0.5621 - val_loss: 1.2808 - val_accuracy: 0.5268\n",
      "Epoch 154/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.0291 - accuracy: 0.5753 - val_loss: 1.2825 - val_accuracy: 0.5192\n",
      "Epoch 155/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0197 - accuracy: 0.5745 - val_loss: 1.2422 - val_accuracy: 0.5402\n",
      "Epoch 156/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0166 - accuracy: 0.5663 - val_loss: 1.2389 - val_accuracy: 0.5670\n",
      "Epoch 157/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.0266 - accuracy: 0.5770 - val_loss: 1.2478 - val_accuracy: 0.5172\n",
      "Epoch 158/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0267 - accuracy: 0.5613 - val_loss: 1.2382 - val_accuracy: 0.5460\n",
      "Epoch 159/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0198 - accuracy: 0.5737 - val_loss: 1.2647 - val_accuracy: 0.5287\n",
      "Epoch 160/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0273 - accuracy: 0.5802 - val_loss: 1.2397 - val_accuracy: 0.5345\n",
      "Epoch 161/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0164 - accuracy: 0.5819 - val_loss: 1.2616 - val_accuracy: 0.5268\n",
      "Epoch 162/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9815 - accuracy: 0.5951 - val_loss: 1.2715 - val_accuracy: 0.5479\n",
      "Epoch 163/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9969 - accuracy: 0.5753 - val_loss: 1.2420 - val_accuracy: 0.5556\n",
      "Epoch 164/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0304 - accuracy: 0.5728 - val_loss: 1.2265 - val_accuracy: 0.5441\n",
      "Epoch 165/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.0132 - accuracy: 0.5844 - val_loss: 1.2195 - val_accuracy: 0.5862\n",
      "Epoch 166/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0023 - accuracy: 0.5802 - val_loss: 1.2264 - val_accuracy: 0.5536\n",
      "Epoch 167/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.0126 - accuracy: 0.5737 - val_loss: 1.2459 - val_accuracy: 0.5077\n",
      "Epoch 168/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9591 - accuracy: 0.5926 - val_loss: 1.2415 - val_accuracy: 0.5517\n",
      "Epoch 169/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9744 - accuracy: 0.5893 - val_loss: 1.2400 - val_accuracy: 0.5556\n",
      "Epoch 170/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9802 - accuracy: 0.5901 - val_loss: 1.2125 - val_accuracy: 0.5651\n",
      "Epoch 171/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9986 - accuracy: 0.5860 - val_loss: 1.2370 - val_accuracy: 0.5728\n",
      "Epoch 172/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9966 - accuracy: 0.5695 - val_loss: 1.2548 - val_accuracy: 0.5479\n",
      "Epoch 173/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.0015 - accuracy: 0.5720 - val_loss: 1.2497 - val_accuracy: 0.5556\n",
      "Epoch 174/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.9670 - accuracy: 0.5877 - val_loss: 1.2200 - val_accuracy: 0.5613\n",
      "Epoch 175/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9572 - accuracy: 0.6099 - val_loss: 1.2546 - val_accuracy: 0.5613\n",
      "Epoch 176/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9871 - accuracy: 0.5827 - val_loss: 1.2441 - val_accuracy: 0.5536\n",
      "Epoch 177/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9680 - accuracy: 0.5959 - val_loss: 1.2285 - val_accuracy: 0.5785\n",
      "Epoch 178/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9736 - accuracy: 0.6049 - val_loss: 1.2644 - val_accuracy: 0.5613\n",
      "Epoch 179/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9641 - accuracy: 0.6016 - val_loss: 1.3206 - val_accuracy: 0.5498\n",
      "Epoch 180/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9605 - accuracy: 0.6091 - val_loss: 1.2341 - val_accuracy: 0.5747\n",
      "Epoch 181/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9496 - accuracy: 0.6033 - val_loss: 1.2518 - val_accuracy: 0.5747\n",
      "Epoch 182/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.9524 - accuracy: 0.6148 - val_loss: 1.2432 - val_accuracy: 0.5441\n",
      "Epoch 183/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.9716 - accuracy: 0.5835 - val_loss: 1.2157 - val_accuracy: 0.5651\n",
      "Epoch 184/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9385 - accuracy: 0.6156 - val_loss: 1.2059 - val_accuracy: 0.5785\n",
      "Epoch 185/1000\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.9583 - accuracy: 0.6140 - val_loss: 1.1834 - val_accuracy: 0.5728\n",
      "Epoch 186/1000\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 0.9726 - accuracy: 0.5918 - val_loss: 1.1975 - val_accuracy: 0.5709\n",
      "Epoch 187/1000\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.9400 - accuracy: 0.5909 - val_loss: 1.2023 - val_accuracy: 0.5613\n",
      "Epoch 188/1000\n",
      "38/38 [==============================] - 3s 83ms/step - loss: 0.9652 - accuracy: 0.5992 - val_loss: 1.2433 - val_accuracy: 0.5632\n",
      "Epoch 189/1000\n",
      "38/38 [==============================] - 4s 93ms/step - loss: 0.9928 - accuracy: 0.5852 - val_loss: 1.2802 - val_accuracy: 0.5383\n",
      "Epoch 190/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9612 - accuracy: 0.5819 - val_loss: 1.1950 - val_accuracy: 0.5766\n",
      "Epoch 191/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9697 - accuracy: 0.5901 - val_loss: 1.2398 - val_accuracy: 0.5441\n",
      "Epoch 192/1000\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.9453 - accuracy: 0.6033 - val_loss: 1.2272 - val_accuracy: 0.5709\n",
      "Epoch 193/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9606 - accuracy: 0.6173 - val_loss: 1.2493 - val_accuracy: 0.5805\n",
      "Epoch 194/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9383 - accuracy: 0.6049 - val_loss: 1.1945 - val_accuracy: 0.5632\n",
      "Epoch 195/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.9598 - accuracy: 0.5959 - val_loss: 1.2030 - val_accuracy: 0.5843\n",
      "Epoch 196/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.9407 - accuracy: 0.6049 - val_loss: 1.2183 - val_accuracy: 0.5900\n",
      "Epoch 197/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.9099 - accuracy: 0.6165 - val_loss: 1.1710 - val_accuracy: 0.5958\n",
      "Epoch 198/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9545 - accuracy: 0.6058 - val_loss: 1.2426 - val_accuracy: 0.5498\n",
      "Epoch 199/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.9410 - accuracy: 0.5959 - val_loss: 1.2218 - val_accuracy: 0.5556\n",
      "Epoch 200/1000\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.9250 - accuracy: 0.6058 - val_loss: 1.2301 - val_accuracy: 0.5651\n",
      "Epoch 201/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9173 - accuracy: 0.6247 - val_loss: 1.2187 - val_accuracy: 0.5843\n",
      "Epoch 202/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9334 - accuracy: 0.6099 - val_loss: 1.2843 - val_accuracy: 0.5421\n",
      "Epoch 203/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9277 - accuracy: 0.6140 - val_loss: 1.2395 - val_accuracy: 0.5613\n",
      "Epoch 204/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9284 - accuracy: 0.6082 - val_loss: 1.1955 - val_accuracy: 0.5728\n",
      "Epoch 205/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.9155 - accuracy: 0.6189 - val_loss: 1.2985 - val_accuracy: 0.5383\n",
      "Epoch 206/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9458 - accuracy: 0.6058 - val_loss: 1.1895 - val_accuracy: 0.5785\n",
      "Epoch 207/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8789 - accuracy: 0.6362 - val_loss: 1.1923 - val_accuracy: 0.5900\n",
      "Epoch 208/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9195 - accuracy: 0.6132 - val_loss: 1.2108 - val_accuracy: 0.5594\n",
      "Epoch 209/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9222 - accuracy: 0.6189 - val_loss: 1.2136 - val_accuracy: 0.5747\n",
      "Epoch 210/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8959 - accuracy: 0.6255 - val_loss: 1.1964 - val_accuracy: 0.5824\n",
      "Epoch 211/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9292 - accuracy: 0.6016 - val_loss: 1.1987 - val_accuracy: 0.5575\n",
      "Epoch 212/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9126 - accuracy: 0.6025 - val_loss: 1.2278 - val_accuracy: 0.5709\n",
      "Epoch 213/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9079 - accuracy: 0.6370 - val_loss: 1.2206 - val_accuracy: 0.5747\n",
      "Epoch 214/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8949 - accuracy: 0.6091 - val_loss: 1.1984 - val_accuracy: 0.5766\n",
      "Epoch 215/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8658 - accuracy: 0.6403 - val_loss: 1.2174 - val_accuracy: 0.5805\n",
      "Epoch 216/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8831 - accuracy: 0.6239 - val_loss: 1.2579 - val_accuracy: 0.5402\n",
      "Epoch 217/1000\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.9174 - accuracy: 0.6272 - val_loss: 1.2453 - val_accuracy: 0.5824\n",
      "Epoch 218/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9270 - accuracy: 0.6041 - val_loss: 1.2090 - val_accuracy: 0.5632\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8975 - accuracy: 0.6255 - val_loss: 1.1933 - val_accuracy: 0.6054\n",
      "Epoch 220/1000\n",
      "38/38 [==============================] - 2s 47ms/step - loss: 0.8827 - accuracy: 0.6362 - val_loss: 1.2186 - val_accuracy: 0.5747\n",
      "Epoch 221/1000\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 0.8770 - accuracy: 0.6370 - val_loss: 1.2194 - val_accuracy: 0.5690\n",
      "Epoch 222/1000\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 0.8879 - accuracy: 0.6354 - val_loss: 1.2194 - val_accuracy: 0.5977\n",
      "Epoch 223/1000\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 0.8923 - accuracy: 0.6387 - val_loss: 1.2297 - val_accuracy: 0.5728\n",
      "Epoch 224/1000\n",
      "38/38 [==============================] - 3s 79ms/step - loss: 0.8979 - accuracy: 0.6272 - val_loss: 1.2010 - val_accuracy: 0.5690\n",
      "Epoch 225/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8750 - accuracy: 0.6263 - val_loss: 1.2033 - val_accuracy: 0.5958\n",
      "Epoch 226/1000\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 0.8973 - accuracy: 0.6156 - val_loss: 1.1807 - val_accuracy: 0.5881\n",
      "Epoch 227/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.8932 - accuracy: 0.6156 - val_loss: 1.2052 - val_accuracy: 0.6034\n",
      "Epoch 228/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8771 - accuracy: 0.6346 - val_loss: 1.2351 - val_accuracy: 0.5843\n",
      "Epoch 229/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9087 - accuracy: 0.6239 - val_loss: 1.1978 - val_accuracy: 0.5594\n",
      "Epoch 230/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8660 - accuracy: 0.6280 - val_loss: 1.2104 - val_accuracy: 0.5805\n",
      "Epoch 231/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8682 - accuracy: 0.6247 - val_loss: 1.1774 - val_accuracy: 0.5881\n",
      "Epoch 232/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8650 - accuracy: 0.6362 - val_loss: 1.1920 - val_accuracy: 0.6130\n",
      "Epoch 233/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9083 - accuracy: 0.6313 - val_loss: 1.2133 - val_accuracy: 0.5785\n",
      "Epoch 234/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8709 - accuracy: 0.6181 - val_loss: 1.1856 - val_accuracy: 0.5824\n",
      "Epoch 235/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9061 - accuracy: 0.6033 - val_loss: 1.2361 - val_accuracy: 0.5843\n",
      "Epoch 236/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8646 - accuracy: 0.6370 - val_loss: 1.2156 - val_accuracy: 0.5556\n",
      "Epoch 237/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8579 - accuracy: 0.6321 - val_loss: 1.1983 - val_accuracy: 0.5824\n",
      "Epoch 238/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8866 - accuracy: 0.6280 - val_loss: 1.2180 - val_accuracy: 0.5690\n",
      "Epoch 239/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8685 - accuracy: 0.6354 - val_loss: 1.2503 - val_accuracy: 0.5575\n",
      "Epoch 240/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8477 - accuracy: 0.6436 - val_loss: 1.1771 - val_accuracy: 0.6092\n",
      "Epoch 241/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8720 - accuracy: 0.6247 - val_loss: 1.2104 - val_accuracy: 0.5670\n",
      "Epoch 242/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8717 - accuracy: 0.6420 - val_loss: 1.1836 - val_accuracy: 0.6245\n",
      "Epoch 243/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8613 - accuracy: 0.6288 - val_loss: 1.2509 - val_accuracy: 0.5920\n",
      "Epoch 244/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8667 - accuracy: 0.6370 - val_loss: 1.2103 - val_accuracy: 0.5785\n",
      "Epoch 245/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8409 - accuracy: 0.6494 - val_loss: 1.2403 - val_accuracy: 0.5651\n",
      "Epoch 246/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8555 - accuracy: 0.6477 - val_loss: 1.2451 - val_accuracy: 0.6034\n",
      "Epoch 247/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8745 - accuracy: 0.6247 - val_loss: 1.2194 - val_accuracy: 0.5785\n",
      "Epoch 248/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8323 - accuracy: 0.6362 - val_loss: 1.2419 - val_accuracy: 0.6034\n",
      "Epoch 249/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8488 - accuracy: 0.6379 - val_loss: 1.2185 - val_accuracy: 0.5900\n",
      "Epoch 250/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.8748 - accuracy: 0.6305 - val_loss: 1.1968 - val_accuracy: 0.6015\n",
      "Epoch 251/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8556 - accuracy: 0.6329 - val_loss: 1.1659 - val_accuracy: 0.6054\n",
      "Epoch 252/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8362 - accuracy: 0.6576 - val_loss: 1.1999 - val_accuracy: 0.6054\n",
      "Epoch 253/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8444 - accuracy: 0.6403 - val_loss: 1.1905 - val_accuracy: 0.5996\n",
      "Epoch 254/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8179 - accuracy: 0.6494 - val_loss: 1.2465 - val_accuracy: 0.5958\n",
      "Epoch 255/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8491 - accuracy: 0.6510 - val_loss: 1.2265 - val_accuracy: 0.5843\n",
      "Epoch 256/1000\n",
      "38/38 [==============================] - 3s 80ms/step - loss: 0.9059 - accuracy: 0.6305 - val_loss: 1.1837 - val_accuracy: 0.5977\n",
      "Epoch 257/1000\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.8496 - accuracy: 0.6412 - val_loss: 1.1859 - val_accuracy: 0.5881\n",
      "Epoch 258/1000\n",
      "38/38 [==============================] - 4s 95ms/step - loss: 0.8367 - accuracy: 0.6379 - val_loss: 1.2009 - val_accuracy: 0.6130\n",
      "Epoch 259/1000\n",
      "38/38 [==============================] - 4s 97ms/step - loss: 0.8341 - accuracy: 0.6461 - val_loss: 1.2062 - val_accuracy: 0.5805\n",
      "Epoch 260/1000\n",
      "38/38 [==============================] - 3s 79ms/step - loss: 0.8519 - accuracy: 0.6379 - val_loss: 1.2824 - val_accuracy: 0.5690\n",
      "Epoch 261/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8310 - accuracy: 0.6568 - val_loss: 1.2163 - val_accuracy: 0.5805\n",
      "Epoch 262/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8705 - accuracy: 0.6346 - val_loss: 1.2696 - val_accuracy: 0.5747\n",
      "Epoch 263/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8795 - accuracy: 0.6214 - val_loss: 1.2437 - val_accuracy: 0.5900\n",
      "Epoch 264/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8289 - accuracy: 0.6494 - val_loss: 1.2222 - val_accuracy: 0.5920\n",
      "Epoch 265/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8548 - accuracy: 0.6494 - val_loss: 1.2161 - val_accuracy: 0.5939\n",
      "Epoch 266/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8381 - accuracy: 0.6486 - val_loss: 1.1846 - val_accuracy: 0.6149\n",
      "Epoch 267/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8122 - accuracy: 0.6609 - val_loss: 1.2365 - val_accuracy: 0.6092\n",
      "Epoch 268/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8396 - accuracy: 0.6395 - val_loss: 1.2846 - val_accuracy: 0.6073\n",
      "Epoch 269/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8182 - accuracy: 0.6560 - val_loss: 1.2851 - val_accuracy: 0.6015\n",
      "Epoch 270/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8192 - accuracy: 0.6535 - val_loss: 1.2270 - val_accuracy: 0.5900\n",
      "Epoch 271/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8289 - accuracy: 0.6420 - val_loss: 1.2611 - val_accuracy: 0.6226\n",
      "Epoch 272/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8135 - accuracy: 0.6601 - val_loss: 1.2795 - val_accuracy: 0.5766\n",
      "Epoch 273/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8595 - accuracy: 0.6395 - val_loss: 1.2891 - val_accuracy: 0.5805\n",
      "Epoch 274/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8147 - accuracy: 0.6724 - val_loss: 1.2620 - val_accuracy: 0.6111\n",
      "Epoch 275/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8085 - accuracy: 0.6519 - val_loss: 1.2263 - val_accuracy: 0.6015\n",
      "Epoch 276/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8309 - accuracy: 0.6494 - val_loss: 1.2252 - val_accuracy: 0.5920\n",
      "Epoch 277/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8286 - accuracy: 0.6403 - val_loss: 1.2703 - val_accuracy: 0.5632\n",
      "Epoch 278/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8438 - accuracy: 0.6362 - val_loss: 1.2111 - val_accuracy: 0.6073\n",
      "Epoch 279/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8163 - accuracy: 0.6576 - val_loss: 1.2538 - val_accuracy: 0.6015\n",
      "Epoch 280/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.8339 - accuracy: 0.6560 - val_loss: 1.2512 - val_accuracy: 0.5939\n",
      "Epoch 281/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8290 - accuracy: 0.6477 - val_loss: 1.2405 - val_accuracy: 0.5881\n",
      "Epoch 282/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8358 - accuracy: 0.6510 - val_loss: 1.2704 - val_accuracy: 0.5651\n",
      "Epoch 283/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8177 - accuracy: 0.6519 - val_loss: 1.2122 - val_accuracy: 0.5958\n",
      "Epoch 284/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.8122 - accuracy: 0.6510 - val_loss: 1.2605 - val_accuracy: 0.5747\n",
      "Epoch 285/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8199 - accuracy: 0.6486 - val_loss: 1.2512 - val_accuracy: 0.6149\n",
      "Epoch 286/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8105 - accuracy: 0.6576 - val_loss: 1.2188 - val_accuracy: 0.6245\n",
      "Epoch 287/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7880 - accuracy: 0.6626 - val_loss: 1.3096 - val_accuracy: 0.5843\n",
      "Epoch 288/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8253 - accuracy: 0.6576 - val_loss: 1.2674 - val_accuracy: 0.6188\n",
      "Epoch 289/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.7991 - accuracy: 0.6568 - val_loss: 1.2404 - val_accuracy: 0.6054\n",
      "Epoch 290/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7936 - accuracy: 0.6634 - val_loss: 1.2423 - val_accuracy: 0.6130\n",
      "Epoch 291/1000\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.7945 - accuracy: 0.6543 - val_loss: 1.2750 - val_accuracy: 0.6034\n",
      "Epoch 292/1000\n",
      "38/38 [==============================] - 4s 118ms/step - loss: 0.8217 - accuracy: 0.6461 - val_loss: 1.2304 - val_accuracy: 0.6092\n",
      "Epoch 293/1000\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 0.8030 - accuracy: 0.6617 - val_loss: 1.2410 - val_accuracy: 0.6111\n",
      "Epoch 294/1000\n",
      "38/38 [==============================] - 4s 95ms/step - loss: 0.8204 - accuracy: 0.6576 - val_loss: 1.2987 - val_accuracy: 0.5709\n",
      "Epoch 295/1000\n",
      "38/38 [==============================] - 2s 47ms/step - loss: 0.8318 - accuracy: 0.6362 - val_loss: 1.2765 - val_accuracy: 0.5766\n",
      "Epoch 296/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.8267 - accuracy: 0.6420 - val_loss: 1.2606 - val_accuracy: 0.6015\n",
      "Epoch 297/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8095 - accuracy: 0.6617 - val_loss: 1.2833 - val_accuracy: 0.5900\n",
      "Epoch 298/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8045 - accuracy: 0.6667 - val_loss: 1.2069 - val_accuracy: 0.6398\n",
      "Epoch 299/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8091 - accuracy: 0.6444 - val_loss: 1.2112 - val_accuracy: 0.6034\n",
      "Epoch 300/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8028 - accuracy: 0.6626 - val_loss: 1.2234 - val_accuracy: 0.6111\n",
      "Epoch 301/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.7981 - accuracy: 0.6749 - val_loss: 1.2077 - val_accuracy: 0.6207\n",
      "Epoch 302/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7891 - accuracy: 0.6626 - val_loss: 1.2448 - val_accuracy: 0.5881\n",
      "Epoch 303/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7988 - accuracy: 0.6543 - val_loss: 1.2783 - val_accuracy: 0.5996\n",
      "Epoch 304/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.7971 - accuracy: 0.6527 - val_loss: 1.2485 - val_accuracy: 0.6264\n",
      "Epoch 305/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7934 - accuracy: 0.6650 - val_loss: 1.2263 - val_accuracy: 0.6149\n",
      "Epoch 306/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7813 - accuracy: 0.6716 - val_loss: 1.3060 - val_accuracy: 0.5939\n",
      "Epoch 307/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.8110 - accuracy: 0.6617 - val_loss: 1.2526 - val_accuracy: 0.5996\n",
      "Epoch 308/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7887 - accuracy: 0.6658 - val_loss: 1.2693 - val_accuracy: 0.5881\n",
      "Epoch 309/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7991 - accuracy: 0.6749 - val_loss: 1.2614 - val_accuracy: 0.6073\n",
      "Epoch 310/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7716 - accuracy: 0.6733 - val_loss: 1.2964 - val_accuracy: 0.5920\n",
      "Epoch 311/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8059 - accuracy: 0.6576 - val_loss: 1.2691 - val_accuracy: 0.5766\n",
      "Epoch 312/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.8201 - accuracy: 0.6337 - val_loss: 1.2712 - val_accuracy: 0.5977\n",
      "Epoch 313/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.7745 - accuracy: 0.6675 - val_loss: 1.2468 - val_accuracy: 0.6073\n",
      "Epoch 314/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7899 - accuracy: 0.6551 - val_loss: 1.2350 - val_accuracy: 0.6207\n",
      "Epoch 315/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.8136 - accuracy: 0.6494 - val_loss: 1.3031 - val_accuracy: 0.5881\n",
      "Epoch 316/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7614 - accuracy: 0.6848 - val_loss: 1.2412 - val_accuracy: 0.6360\n",
      "Epoch 317/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8030 - accuracy: 0.6510 - val_loss: 1.2350 - val_accuracy: 0.6073\n",
      "Epoch 318/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7831 - accuracy: 0.6576 - val_loss: 1.2431 - val_accuracy: 0.6073\n",
      "Epoch 319/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7870 - accuracy: 0.6700 - val_loss: 1.2667 - val_accuracy: 0.6054\n",
      "Epoch 320/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7764 - accuracy: 0.6700 - val_loss: 1.2237 - val_accuracy: 0.6092\n",
      "Epoch 321/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7716 - accuracy: 0.6642 - val_loss: 1.2303 - val_accuracy: 0.6073\n",
      "Epoch 322/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7716 - accuracy: 0.6642 - val_loss: 1.3363 - val_accuracy: 0.5881\n",
      "Epoch 323/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7783 - accuracy: 0.6601 - val_loss: 1.2119 - val_accuracy: 0.6130\n",
      "Epoch 324/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7872 - accuracy: 0.6675 - val_loss: 1.2256 - val_accuracy: 0.6130\n",
      "Epoch 325/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7774 - accuracy: 0.6765 - val_loss: 1.3077 - val_accuracy: 0.5594\n",
      "Epoch 326/1000\n",
      "38/38 [==============================] - 2s 48ms/step - loss: 0.7710 - accuracy: 0.6749 - val_loss: 1.2657 - val_accuracy: 0.6169\n",
      "Epoch 327/1000\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.7575 - accuracy: 0.6749 - val_loss: 1.2670 - val_accuracy: 0.6245\n",
      "Epoch 328/1000\n",
      "38/38 [==============================] - 4s 100ms/step - loss: 0.7873 - accuracy: 0.6609 - val_loss: 1.3344 - val_accuracy: 0.6054\n",
      "Epoch 329/1000\n",
      "38/38 [==============================] - 3s 86ms/step - loss: 0.7985 - accuracy: 0.6733 - val_loss: 1.2898 - val_accuracy: 0.5996\n",
      "Epoch 330/1000\n",
      "38/38 [==============================] - 4s 97ms/step - loss: 0.7795 - accuracy: 0.6798 - val_loss: 1.2858 - val_accuracy: 0.5996\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 2s 57ms/step - loss: 0.7569 - accuracy: 0.6741 - val_loss: 1.2542 - val_accuracy: 0.6456\n",
      "Epoch 332/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7976 - accuracy: 0.6650 - val_loss: 1.2216 - val_accuracy: 0.6245\n",
      "Epoch 333/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7627 - accuracy: 0.6642 - val_loss: 1.2549 - val_accuracy: 0.5977\n",
      "Epoch 334/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7383 - accuracy: 0.6724 - val_loss: 1.2573 - val_accuracy: 0.6226\n",
      "Epoch 335/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7911 - accuracy: 0.6560 - val_loss: 1.3300 - val_accuracy: 0.5728\n",
      "Epoch 336/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7552 - accuracy: 0.6683 - val_loss: 1.2894 - val_accuracy: 0.6111\n",
      "Epoch 337/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7837 - accuracy: 0.6708 - val_loss: 1.3041 - val_accuracy: 0.5958\n",
      "Epoch 338/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7804 - accuracy: 0.6650 - val_loss: 1.2878 - val_accuracy: 0.5824\n",
      "Epoch 339/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.7608 - accuracy: 0.6774 - val_loss: 1.2711 - val_accuracy: 0.5862\n",
      "Epoch 340/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7631 - accuracy: 0.6733 - val_loss: 1.2505 - val_accuracy: 0.6226\n",
      "Epoch 341/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7487 - accuracy: 0.6675 - val_loss: 1.2879 - val_accuracy: 0.5900\n",
      "Epoch 342/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7629 - accuracy: 0.6782 - val_loss: 1.2361 - val_accuracy: 0.6073\n",
      "Epoch 343/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7788 - accuracy: 0.6658 - val_loss: 1.2899 - val_accuracy: 0.6149\n",
      "Epoch 344/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7675 - accuracy: 0.6634 - val_loss: 1.2440 - val_accuracy: 0.5843\n",
      "Epoch 345/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7846 - accuracy: 0.6601 - val_loss: 1.2380 - val_accuracy: 0.5862\n",
      "Epoch 346/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7747 - accuracy: 0.6584 - val_loss: 1.2826 - val_accuracy: 0.6149\n",
      "Epoch 347/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7888 - accuracy: 0.6634 - val_loss: 1.2206 - val_accuracy: 0.6379\n",
      "Epoch 348/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7307 - accuracy: 0.6897 - val_loss: 1.2334 - val_accuracy: 0.6456\n",
      "Epoch 349/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7458 - accuracy: 0.6782 - val_loss: 1.2157 - val_accuracy: 0.6130\n",
      "Epoch 350/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7320 - accuracy: 0.6979 - val_loss: 1.3067 - val_accuracy: 0.5651\n",
      "Epoch 351/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7757 - accuracy: 0.6807 - val_loss: 1.2217 - val_accuracy: 0.6379\n",
      "Validation Accuracy: 60.536%\n"
     ]
    }
   ],
   "source": [
    "# # Training on validation data (Experimental)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# y_val = Data_val.Emotion\n",
    "# X_val = pd.DataFrame(Data_val.drop(['Emotion', 'User'], axis = 1))\n",
    "\n",
    "# X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(X_val, y_val, test_size = 0.3, random_state = 123)\n",
    "\n",
    "\n",
    "# #Trying adam optimizer\n",
    "# modelVal = initModelGRU(X.shape[1], 7, 'softmax')\n",
    "# modelVal.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# historyVal = modelVal.fit(\n",
    "#     X_train_val,\n",
    "#     y_train_val,\n",
    "#     validation_data = (X_test_val, y_test_val),\n",
    "#     epochs=1000,\n",
    "#     callbacks=[\n",
    "#         tf.keras.callbacks.EarlyStopping(\n",
    "#             monitor='val_loss',\n",
    "#             patience=100,\n",
    "#             restore_best_weights=True\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# #Result of adam optimizer on validation data\n",
    "# model_acc = modelVal.evaluate(X_test_val, y_test_val, verbose=0)[1]\n",
    "# print(\"Validation Accuracy: {:.3f}%\".format(model_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2cd3b7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Plot the accuracy curve for validation set\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(historyVal.history['val_accuracy'], color='r', label=\"Accuracy\")\n",
    "\n",
    "# plt.title(\"Val accuracy\")\n",
    "# plt.xlabel(\"Number of Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b225588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict = model.predict(X_test)[0]\n",
    "# predict = [np.argmax(pre) for pre in predict]\n",
    "# print(predict)\n",
    "# y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e5e15a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
