{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8778ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.signal import medfilt\n",
    "from scipy.signal import wiener\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "genders = ['male', 'female']\n",
    "labels = ['Happy', 'Surprise', 'Disgust', 'Angry', 'Fear', 'Sad', 'Neutral'] # 0-6, 7 classes\n",
    "\n",
    "def preprocess_data(dataPath, train):\n",
    "    if train:\n",
    "        path = os.path.join(dataPath, 'train')\n",
    "        output_dir = os.path.join(dataPath, 'train.csv')\n",
    "    else:\n",
    "        path = os.path.join(dataPath, 'val')\n",
    "        output_dir = os.path.join(dataPath, 'val.csv')\n",
    "    folders = glob.glob(os.path.join(path, '*'))\n",
    "    folders.sort()\n",
    "\n",
    "    with open(output_dir, 'a+') as csv_output_file:\n",
    "        fieldnames = ['User', 'Person_min', 'Max', 'Min', 'Mean', 'Var', 'Mean Abs Diff', 'Mean Abs Second Diff', 'Emotion', 'Gender', 'Age'] # The features extracted\n",
    "        writer = csv.DictWriter(csv_output_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for dir in folders:\n",
    "            with open(os.path.join(dir, 'EDA.csv')) as csv_file:\n",
    "                csv_reader = csv.reader(csv_file)\n",
    "                line_count = 0\n",
    "                data = [] # all data for one person\n",
    "                time_stamp = [] # time stamp for each item\n",
    "\n",
    "                for row in csv_reader:\n",
    "                    if line_count == 0:\n",
    "                        start_time = float(row[0])\n",
    "                    elif line_count == 1:\n",
    "                        freq = float(row[0])\n",
    "                    elif line_count>2 :\n",
    "                        data.append(float(row[0]))\n",
    "                        time_stamp.append(start_time + float((line_count-2)/freq))\n",
    "                    line_count += 1\n",
    "\n",
    "                #person_Max = max(data)\n",
    "                #person_Min = min(data)\n",
    "                data = (data - np.average(data)) / (np.std(data)) # standartization filter\n",
    "                #data = (np.array(data) - float(person_Min)) / (float(person_Max) - float(person_Min)) # normalised data for each person\n",
    "                #data = medfilt(data, 11) # median filter; can be substituted by your preprocessing methods\n",
    "                #data = wiener(data)\n",
    "                #data = savgol_filter(data, 11, 5)\n",
    "                person_Max = max(data)\n",
    "                person_Min = min(data)\n",
    "                \n",
    "            \n",
    "                log = open(os.path.join(dir, 'log.txt'), 'r')\n",
    "                log_count = 0\n",
    "                for line in log:\n",
    "                    if log_count == 0:\n",
    "                        user = line.split(';')[0].split(':')[-1]\n",
    "                        age = line.split(';')[1].split(':')[-1]\n",
    "                        gender = line.split(';')[2].split(':')[-1]\n",
    "                        gender = genders.index(gender.lower())\n",
    "                        log_count += 1\n",
    "                    elif log_count == 1:\n",
    "                        log_count += 1\n",
    "                    else:\n",
    "                        st = float(line.split(';')[1]) # start time of each video\n",
    "                        et = float(line.split(';')[3]) # end time of each video\n",
    "                        video_name = line.split(';')[2]\n",
    "                        if \"_\" in video_name:\n",
    "                            emotion_label = line.split(';')[2].split('.')[0][:-10] # emotion label of each video\n",
    "                        else:\n",
    "                            emotion_label = line.split(';')[2].split('.')[0][:-9]  # emotion label of each video\n",
    "                        emotion_label = labels.index(emotion_label)\n",
    "\n",
    "                        index = np.where(np.logical_and((np.array(time_stamp) >= st), (np.array(time_stamp) <= et)))\n",
    "                        data_list = data[index[0]]\n",
    "                        if len(data_list)== 0:\n",
    "                            break\n",
    "                        diff_list = [data_list[k+1]-data_list[k] for k in range(len(data_list)-1)]\n",
    "                        abs_diff_list = abs(np.array(diff_list))\n",
    "                        second_diff_list = [diff_list[k + 1] - diff_list[k] for k in range(len(diff_list) - 1)]\n",
    "                        abs_second_diff_list = abs(np.array(second_diff_list))\n",
    "                        writer.writerow({'User': user, 'Person_min': person_Min,  'Max': max(data_list), 'Min': min(data_list), 'Mean': np.mean(data_list), 'Var': np.var(data_list), 'Mean Abs Diff': np.mean(abs_diff_list), 'Mean Abs Second Diff': np.mean(abs_second_diff_list),'Emotion': emotion_label, 'Gender': gender, 'Age': age})\n",
    "                log.close()\n",
    "        csv_file.close()\n",
    "    csv_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8285489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and reading dat\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "os.remove('train.csv')\n",
    "preprocess_data('', train=1)\n",
    "os.remove('val.csv')\n",
    "preprocess_data('', train=0)\n",
    "\n",
    "\n",
    "Data_train = pd.read_csv(\"train.csv\", sep = \",\")\n",
    "Data_train = shuffle(Data_train)\n",
    "#Data_train[Data_train.User == \"Person_25\"].head(10)\n",
    "#Data_train.head(20)\n",
    "\n",
    "Data_val = pd.read_csv(\"val.csv\")\n",
    "Data_val = shuffle(Data_val)\n",
    "#Data_val[Data_val.User == \"Person_25\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca097b4",
   "metadata": {},
   "source": [
    "# Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22e78213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import seaborn as sns\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(16, 10))\n",
    "# plt.plot(np.arange(0, 1000, 1), Data_train.Mean.iloc[:1000], scaley = 100)\n",
    "# plt.title(\"Mean variations\")\n",
    "# plt.legend([\"y = mean common variation\"])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9f27eba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #Max\tMin\tMean\tVar\tMean Abs Diff\tMean Abs Second Diff\tEmotion\n",
    "\n",
    "# sns.set(rc = {'figure.figsize':(16, 10)})\n",
    "# sns.set_theme(style=\"darkgrid\")\n",
    "# sns.scatterplot(data = Data_train, x = \"Mean\", y = Data_train.index, hue = \"Emotion\", palette = \"tab10\", x_bins= 150)\n",
    "# #sns.lineplot(data = Data_train.iloc[:1500], x = Data_train.Mean.iloc[:1500], y = np.arange(0, 1500, 1), hue = \"Emotion\", palette = \"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81e60458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a21b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data_train.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a95ae",
   "metadata": {},
   "source": [
    "####  Data is distributed normally. No NaN values. Sad and happy emotions have more samples than others -> might have to equalize value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7072b73",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08962cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def initModelGRU(shape, outputUnits, outputActivation) -> tf.keras.Model:\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    inputs = tf.keras.Input(shape = (shape))\n",
    "    expand = tf.expand_dims(inputs, axis = 2)\n",
    "                                                            #dropout better than L reg\n",
    "    gru1 = tf.keras.layers.GRU(128, return_sequences = True, recurrent_dropout = 0.25, activation = 'relu')(expand) \n",
    "    gru2 = tf.keras.layers.GRU(64, return_sequences = True, recurrent_dropout = 0.25, activation = 'relu')(gru1)\n",
    "    flatten = tf.keras.layers.Flatten()(gru2)  \n",
    "                                                        #use softmax for prob distribution!\n",
    "    outputs = tf.keras.layers.Dense(outputUnits, activation = outputActivation)(flatten)    \n",
    "    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9176b7a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 9)]               0         \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (None, 9, 1)             0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 9, 128)            50304     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 9, 64)             37248     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 4039      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,591\n",
      "Trainable params: 91,591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/600\n",
      "73/73 [==============================] - 7s 33ms/step - loss: 1.9281 - accuracy: 0.1991 - val_loss: 1.9163 - val_accuracy: 0.2122\n",
      "Epoch 2/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.9090 - accuracy: 0.2004 - val_loss: 1.9152 - val_accuracy: 0.1785\n",
      "Epoch 3/600\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 1.8981 - accuracy: 0.1961 - val_loss: 1.9021 - val_accuracy: 0.1929\n",
      "Epoch 4/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.8906 - accuracy: 0.2030 - val_loss: 1.8947 - val_accuracy: 0.2195\n",
      "Epoch 5/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.8840 - accuracy: 0.2061 - val_loss: 1.8903 - val_accuracy: 0.2130\n",
      "Epoch 6/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.8796 - accuracy: 0.2221 - val_loss: 1.8963 - val_accuracy: 0.2034\n",
      "Epoch 7/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.8714 - accuracy: 0.2260 - val_loss: 1.8891 - val_accuracy: 0.2219\n",
      "Epoch 8/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.8661 - accuracy: 0.2273 - val_loss: 1.8795 - val_accuracy: 0.2186\n",
      "Epoch 9/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.8618 - accuracy: 0.2342 - val_loss: 1.8897 - val_accuracy: 0.2074\n",
      "Epoch 10/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.8625 - accuracy: 0.2286 - val_loss: 1.8684 - val_accuracy: 0.2492\n",
      "Epoch 11/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.8550 - accuracy: 0.2320 - val_loss: 1.8786 - val_accuracy: 0.2195\n",
      "Epoch 12/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.8468 - accuracy: 0.2294 - val_loss: 1.8583 - val_accuracy: 0.2460\n",
      "Epoch 13/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.8386 - accuracy: 0.2420 - val_loss: 1.8969 - val_accuracy: 0.2299\n",
      "Epoch 14/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.8492 - accuracy: 0.2333 - val_loss: 1.8554 - val_accuracy: 0.2355\n",
      "Epoch 15/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.8371 - accuracy: 0.2472 - val_loss: 1.8583 - val_accuracy: 0.2500\n",
      "Epoch 16/600\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 1.8352 - accuracy: 0.2390 - val_loss: 1.8490 - val_accuracy: 0.2572\n",
      "Epoch 17/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.8248 - accuracy: 0.2532 - val_loss: 1.8479 - val_accuracy: 0.2516\n",
      "Epoch 18/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.8141 - accuracy: 0.2420 - val_loss: 1.8473 - val_accuracy: 0.2524\n",
      "Epoch 19/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.8135 - accuracy: 0.2645 - val_loss: 1.8401 - val_accuracy: 0.2781\n",
      "Epoch 20/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.8044 - accuracy: 0.2554 - val_loss: 1.8393 - val_accuracy: 0.2580\n",
      "Epoch 21/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.8046 - accuracy: 0.2654 - val_loss: 1.8239 - val_accuracy: 0.2532\n",
      "Epoch 22/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.7950 - accuracy: 0.2623 - val_loss: 1.8325 - val_accuracy: 0.2693\n",
      "Epoch 23/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.7856 - accuracy: 0.2654 - val_loss: 1.8304 - val_accuracy: 0.2596\n",
      "Epoch 24/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.7882 - accuracy: 0.2671 - val_loss: 1.8309 - val_accuracy: 0.2460\n",
      "Epoch 25/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.7831 - accuracy: 0.2597 - val_loss: 1.8153 - val_accuracy: 0.2709\n",
      "Epoch 26/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.7791 - accuracy: 0.2766 - val_loss: 1.7995 - val_accuracy: 0.2966\n",
      "Epoch 27/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.7599 - accuracy: 0.2883 - val_loss: 1.8087 - val_accuracy: 0.2814\n",
      "Epoch 28/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.7669 - accuracy: 0.2818 - val_loss: 1.7984 - val_accuracy: 0.2701\n",
      "Epoch 29/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.7587 - accuracy: 0.2900 - val_loss: 1.8001 - val_accuracy: 0.2733\n",
      "Epoch 30/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.7625 - accuracy: 0.2939 - val_loss: 1.7819 - val_accuracy: 0.2733\n",
      "Epoch 31/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.7435 - accuracy: 0.2814 - val_loss: 1.7961 - val_accuracy: 0.2878\n",
      "Epoch 32/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.7407 - accuracy: 0.2913 - val_loss: 1.7787 - val_accuracy: 0.2862\n",
      "Epoch 33/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.7224 - accuracy: 0.3013 - val_loss: 1.7790 - val_accuracy: 0.2749\n",
      "Epoch 34/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.7248 - accuracy: 0.3030 - val_loss: 1.7847 - val_accuracy: 0.2717\n",
      "Epoch 35/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.7153 - accuracy: 0.3065 - val_loss: 1.7637 - val_accuracy: 0.2942\n",
      "Epoch 36/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.7050 - accuracy: 0.3117 - val_loss: 1.7484 - val_accuracy: 0.3183\n",
      "Epoch 37/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.7068 - accuracy: 0.3165 - val_loss: 1.7645 - val_accuracy: 0.2773\n",
      "Epoch 38/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.6942 - accuracy: 0.3333 - val_loss: 1.7406 - val_accuracy: 0.3191\n",
      "Epoch 39/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.6967 - accuracy: 0.3147 - val_loss: 1.7196 - val_accuracy: 0.3240\n",
      "Epoch 40/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.6670 - accuracy: 0.3251 - val_loss: 1.7364 - val_accuracy: 0.3183\n",
      "Epoch 41/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.6782 - accuracy: 0.3273 - val_loss: 1.7244 - val_accuracy: 0.3304\n",
      "Epoch 42/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.6613 - accuracy: 0.3450 - val_loss: 1.7112 - val_accuracy: 0.3256\n",
      "Epoch 43/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.6524 - accuracy: 0.3385 - val_loss: 1.7192 - val_accuracy: 0.3167\n",
      "Epoch 44/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.6528 - accuracy: 0.3481 - val_loss: 1.7116 - val_accuracy: 0.3441\n",
      "Epoch 45/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.6502 - accuracy: 0.3589 - val_loss: 1.6876 - val_accuracy: 0.3392\n",
      "Epoch 46/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.6460 - accuracy: 0.3463 - val_loss: 1.6849 - val_accuracy: 0.3617\n",
      "Epoch 47/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.6385 - accuracy: 0.3554 - val_loss: 1.6758 - val_accuracy: 0.3489\n",
      "Epoch 48/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.6131 - accuracy: 0.3537 - val_loss: 1.6873 - val_accuracy: 0.3505\n",
      "Epoch 49/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.6194 - accuracy: 0.3693 - val_loss: 1.6559 - val_accuracy: 0.3537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/600\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 1.6031 - accuracy: 0.3662 - val_loss: 1.6720 - val_accuracy: 0.3328\n",
      "Epoch 51/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.6164 - accuracy: 0.3684 - val_loss: 1.6528 - val_accuracy: 0.3521\n",
      "Epoch 52/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.6017 - accuracy: 0.3688 - val_loss: 1.6508 - val_accuracy: 0.3818\n",
      "Epoch 53/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.5855 - accuracy: 0.3775 - val_loss: 1.6481 - val_accuracy: 0.3754\n",
      "Epoch 54/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.5672 - accuracy: 0.3926 - val_loss: 1.6480 - val_accuracy: 0.3762\n",
      "Epoch 55/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.5695 - accuracy: 0.3844 - val_loss: 1.6596 - val_accuracy: 0.3682\n",
      "Epoch 56/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.5706 - accuracy: 0.3810 - val_loss: 1.6438 - val_accuracy: 0.3850\n",
      "Epoch 57/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.5490 - accuracy: 0.3974 - val_loss: 1.6179 - val_accuracy: 0.3899\n",
      "Epoch 58/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.5388 - accuracy: 0.4113 - val_loss: 1.6481 - val_accuracy: 0.3842\n",
      "Epoch 59/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.5502 - accuracy: 0.3857 - val_loss: 1.6278 - val_accuracy: 0.3826\n",
      "Epoch 60/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.5201 - accuracy: 0.4087 - val_loss: 1.6068 - val_accuracy: 0.3899\n",
      "Epoch 61/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.5322 - accuracy: 0.3987 - val_loss: 1.6251 - val_accuracy: 0.3674\n",
      "Epoch 62/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.5048 - accuracy: 0.4095 - val_loss: 1.5695 - val_accuracy: 0.4035\n",
      "Epoch 63/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.5161 - accuracy: 0.4130 - val_loss: 1.6005 - val_accuracy: 0.3939\n",
      "Epoch 64/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.4945 - accuracy: 0.4126 - val_loss: 1.5891 - val_accuracy: 0.3770\n",
      "Epoch 65/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.4914 - accuracy: 0.4255 - val_loss: 1.5764 - val_accuracy: 0.4084\n",
      "Epoch 66/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.4903 - accuracy: 0.4203 - val_loss: 1.5702 - val_accuracy: 0.3931\n",
      "Epoch 67/600\n",
      "73/73 [==============================] - 3s 39ms/step - loss: 1.4757 - accuracy: 0.4260 - val_loss: 1.5593 - val_accuracy: 0.4116\n",
      "Epoch 68/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 1.4737 - accuracy: 0.4173 - val_loss: 1.5499 - val_accuracy: 0.4011\n",
      "Epoch 69/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 1.4605 - accuracy: 0.4303 - val_loss: 1.5503 - val_accuracy: 0.3987\n",
      "Epoch 70/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 1.4504 - accuracy: 0.4446 - val_loss: 1.5516 - val_accuracy: 0.4068\n",
      "Epoch 71/600\n",
      "73/73 [==============================] - 3s 39ms/step - loss: 1.4359 - accuracy: 0.4481 - val_loss: 1.5441 - val_accuracy: 0.4011\n",
      "Epoch 72/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.4403 - accuracy: 0.4364 - val_loss: 1.5007 - val_accuracy: 0.4317\n",
      "Epoch 73/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.4270 - accuracy: 0.4359 - val_loss: 1.5153 - val_accuracy: 0.4333\n",
      "Epoch 74/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.4339 - accuracy: 0.4390 - val_loss: 1.4990 - val_accuracy: 0.4301\n",
      "Epoch 75/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.4204 - accuracy: 0.4459 - val_loss: 1.5102 - val_accuracy: 0.4059\n",
      "Epoch 76/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.4030 - accuracy: 0.4511 - val_loss: 1.4986 - val_accuracy: 0.4293\n",
      "Epoch 77/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3984 - accuracy: 0.4619 - val_loss: 1.4888 - val_accuracy: 0.4252\n",
      "Epoch 78/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.4203 - accuracy: 0.4468 - val_loss: 1.4584 - val_accuracy: 0.4405\n",
      "Epoch 79/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3880 - accuracy: 0.4558 - val_loss: 1.4812 - val_accuracy: 0.4365\n",
      "Epoch 80/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3882 - accuracy: 0.4563 - val_loss: 1.4770 - val_accuracy: 0.4429\n",
      "Epoch 81/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3860 - accuracy: 0.4693 - val_loss: 1.4847 - val_accuracy: 0.4301\n",
      "Epoch 82/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3652 - accuracy: 0.4649 - val_loss: 1.4789 - val_accuracy: 0.4413\n",
      "Epoch 83/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3565 - accuracy: 0.4701 - val_loss: 1.5185 - val_accuracy: 0.4349\n",
      "Epoch 84/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3799 - accuracy: 0.4494 - val_loss: 1.5188 - val_accuracy: 0.4349\n",
      "Epoch 85/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3554 - accuracy: 0.4745 - val_loss: 1.4947 - val_accuracy: 0.4365\n",
      "Epoch 86/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3769 - accuracy: 0.4580 - val_loss: 1.4491 - val_accuracy: 0.4365\n",
      "Epoch 87/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3261 - accuracy: 0.4879 - val_loss: 1.4759 - val_accuracy: 0.4429\n",
      "Epoch 88/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3260 - accuracy: 0.4801 - val_loss: 1.4435 - val_accuracy: 0.4526\n",
      "Epoch 89/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3344 - accuracy: 0.4675 - val_loss: 1.4387 - val_accuracy: 0.4526\n",
      "Epoch 90/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3217 - accuracy: 0.4797 - val_loss: 1.4688 - val_accuracy: 0.4413\n",
      "Epoch 91/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3256 - accuracy: 0.4900 - val_loss: 1.4304 - val_accuracy: 0.4526\n",
      "Epoch 92/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3229 - accuracy: 0.4792 - val_loss: 1.4440 - val_accuracy: 0.4357\n",
      "Epoch 93/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3028 - accuracy: 0.4861 - val_loss: 1.4025 - val_accuracy: 0.4783\n",
      "Epoch 94/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.2986 - accuracy: 0.4970 - val_loss: 1.4188 - val_accuracy: 0.4622\n",
      "Epoch 95/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3100 - accuracy: 0.4922 - val_loss: 1.4541 - val_accuracy: 0.4260\n",
      "Epoch 96/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.3176 - accuracy: 0.4810 - val_loss: 1.4279 - val_accuracy: 0.4638\n",
      "Epoch 97/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.2940 - accuracy: 0.4874 - val_loss: 1.3919 - val_accuracy: 0.4735\n",
      "Epoch 98/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.2833 - accuracy: 0.4978 - val_loss: 1.3819 - val_accuracy: 0.4887\n",
      "Epoch 99/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.2790 - accuracy: 0.5056 - val_loss: 1.3930 - val_accuracy: 0.4879\n",
      "Epoch 100/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.2920 - accuracy: 0.4926 - val_loss: 1.4007 - val_accuracy: 0.4775\n",
      "Epoch 101/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.2641 - accuracy: 0.5182 - val_loss: 1.3992 - val_accuracy: 0.4703\n",
      "Epoch 102/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.2553 - accuracy: 0.5126 - val_loss: 1.3919 - val_accuracy: 0.4662\n",
      "Epoch 103/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.2815 - accuracy: 0.5026 - val_loss: 1.3711 - val_accuracy: 0.4807\n",
      "Epoch 104/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.2474 - accuracy: 0.5100 - val_loss: 1.3746 - val_accuracy: 0.4759\n",
      "Epoch 105/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.2436 - accuracy: 0.5126 - val_loss: 1.3665 - val_accuracy: 0.4879\n",
      "Epoch 106/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.2482 - accuracy: 0.5078 - val_loss: 1.3591 - val_accuracy: 0.4895\n",
      "Epoch 107/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 2s 24ms/step - loss: 1.2363 - accuracy: 0.5225 - val_loss: 1.3930 - val_accuracy: 0.4727\n",
      "Epoch 108/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.2485 - accuracy: 0.5173 - val_loss: 1.3760 - val_accuracy: 0.4791\n",
      "Epoch 109/600\n",
      "73/73 [==============================] - 4s 51ms/step - loss: 1.2488 - accuracy: 0.5000 - val_loss: 1.3500 - val_accuracy: 0.5064\n",
      "Epoch 110/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 1.2445 - accuracy: 0.5056 - val_loss: 1.3472 - val_accuracy: 0.4895\n",
      "Epoch 111/600\n",
      "73/73 [==============================] - 4s 54ms/step - loss: 1.2245 - accuracy: 0.5147 - val_loss: 1.3607 - val_accuracy: 0.4944\n",
      "Epoch 112/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 1.2156 - accuracy: 0.5281 - val_loss: 1.3430 - val_accuracy: 0.4968\n",
      "Epoch 113/600\n",
      "73/73 [==============================] - 2s 28ms/step - loss: 1.2136 - accuracy: 0.5182 - val_loss: 1.3356 - val_accuracy: 0.5000\n",
      "Epoch 114/600\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 1.2131 - accuracy: 0.5238 - val_loss: 1.3753 - val_accuracy: 0.4823\n",
      "Epoch 115/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.2271 - accuracy: 0.5195 - val_loss: 1.3443 - val_accuracy: 0.5000\n",
      "Epoch 116/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.2039 - accuracy: 0.5416 - val_loss: 1.3065 - val_accuracy: 0.5113\n",
      "Epoch 117/600\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 1.2083 - accuracy: 0.5255 - val_loss: 1.3074 - val_accuracy: 0.5080\n",
      "Epoch 118/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1910 - accuracy: 0.5286 - val_loss: 1.3240 - val_accuracy: 0.5161\n",
      "Epoch 119/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1899 - accuracy: 0.5238 - val_loss: 1.3171 - val_accuracy: 0.4920\n",
      "Epoch 120/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1966 - accuracy: 0.5238 - val_loss: 1.3306 - val_accuracy: 0.5088\n",
      "Epoch 121/600\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 1.1902 - accuracy: 0.5403 - val_loss: 1.3115 - val_accuracy: 0.5209\n",
      "Epoch 122/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1911 - accuracy: 0.5368 - val_loss: 1.3164 - val_accuracy: 0.4775\n",
      "Epoch 123/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1819 - accuracy: 0.5320 - val_loss: 1.3208 - val_accuracy: 0.4936\n",
      "Epoch 124/600\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 1.1671 - accuracy: 0.5390 - val_loss: 1.3194 - val_accuracy: 0.4944\n",
      "Epoch 125/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1875 - accuracy: 0.5281 - val_loss: 1.3009 - val_accuracy: 0.5217\n",
      "Epoch 126/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1507 - accuracy: 0.5528 - val_loss: 1.3021 - val_accuracy: 0.5048\n",
      "Epoch 127/600\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 1.1543 - accuracy: 0.5398 - val_loss: 1.2954 - val_accuracy: 0.5121\n",
      "Epoch 128/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1583 - accuracy: 0.5424 - val_loss: 1.3564 - val_accuracy: 0.4791\n",
      "Epoch 129/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1728 - accuracy: 0.5277 - val_loss: 1.3327 - val_accuracy: 0.4920\n",
      "Epoch 130/600\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 1.1530 - accuracy: 0.5450 - val_loss: 1.2831 - val_accuracy: 0.5249\n",
      "Epoch 131/600\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 1.1492 - accuracy: 0.5398 - val_loss: 1.3392 - val_accuracy: 0.4960\n",
      "Epoch 132/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1406 - accuracy: 0.5506 - val_loss: 1.3083 - val_accuracy: 0.5056\n",
      "Epoch 133/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1376 - accuracy: 0.5498 - val_loss: 1.3115 - val_accuracy: 0.5129\n",
      "Epoch 134/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1340 - accuracy: 0.5511 - val_loss: 1.2841 - val_accuracy: 0.5297\n",
      "Epoch 135/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1437 - accuracy: 0.5407 - val_loss: 1.2924 - val_accuracy: 0.5265\n",
      "Epoch 136/600\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 1.1306 - accuracy: 0.5494 - val_loss: 1.2703 - val_accuracy: 0.5072\n",
      "Epoch 137/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1576 - accuracy: 0.5411 - val_loss: 1.2714 - val_accuracy: 0.5434\n",
      "Epoch 138/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1418 - accuracy: 0.5450 - val_loss: 1.2813 - val_accuracy: 0.5281\n",
      "Epoch 139/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1108 - accuracy: 0.5580 - val_loss: 1.2740 - val_accuracy: 0.5314\n",
      "Epoch 140/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1050 - accuracy: 0.5571 - val_loss: 1.2725 - val_accuracy: 0.5314\n",
      "Epoch 141/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0933 - accuracy: 0.5671 - val_loss: 1.2873 - val_accuracy: 0.5217\n",
      "Epoch 142/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0971 - accuracy: 0.5662 - val_loss: 1.2721 - val_accuracy: 0.5193\n",
      "Epoch 143/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0856 - accuracy: 0.5688 - val_loss: 1.2675 - val_accuracy: 0.5322\n",
      "Epoch 144/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0839 - accuracy: 0.5693 - val_loss: 1.2817 - val_accuracy: 0.5241\n",
      "Epoch 145/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1044 - accuracy: 0.5550 - val_loss: 1.2656 - val_accuracy: 0.5362\n",
      "Epoch 146/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.1014 - accuracy: 0.5545 - val_loss: 1.2765 - val_accuracy: 0.5193\n",
      "Epoch 147/600\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 1.1082 - accuracy: 0.5632 - val_loss: 1.3174 - val_accuracy: 0.5056\n",
      "Epoch 148/600\n",
      "73/73 [==============================] - 2s 28ms/step - loss: 1.1028 - accuracy: 0.5623 - val_loss: 1.2759 - val_accuracy: 0.5322\n",
      "Epoch 149/600\n",
      "73/73 [==============================] - 4s 54ms/step - loss: 1.0868 - accuracy: 0.5701 - val_loss: 1.2767 - val_accuracy: 0.5169\n",
      "Epoch 150/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 1.1061 - accuracy: 0.5641 - val_loss: 1.2585 - val_accuracy: 0.5434\n",
      "Epoch 151/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 1.0937 - accuracy: 0.5723 - val_loss: 1.2565 - val_accuracy: 0.5346\n",
      "Epoch 152/600\n",
      "73/73 [==============================] - 4s 51ms/step - loss: 1.0683 - accuracy: 0.5697 - val_loss: 1.2600 - val_accuracy: 0.5354\n",
      "Epoch 153/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0946 - accuracy: 0.5693 - val_loss: 1.2734 - val_accuracy: 0.5257\n",
      "Epoch 154/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0854 - accuracy: 0.5736 - val_loss: 1.2608 - val_accuracy: 0.5193\n",
      "Epoch 155/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0680 - accuracy: 0.5753 - val_loss: 1.2469 - val_accuracy: 0.5330\n",
      "Epoch 156/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0523 - accuracy: 0.5818 - val_loss: 1.2707 - val_accuracy: 0.5281\n",
      "Epoch 157/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0702 - accuracy: 0.5723 - val_loss: 1.2502 - val_accuracy: 0.5225\n",
      "Epoch 158/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0803 - accuracy: 0.5693 - val_loss: 1.2642 - val_accuracy: 0.5370\n",
      "Epoch 159/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0476 - accuracy: 0.5801 - val_loss: 1.2355 - val_accuracy: 0.5386\n",
      "Epoch 160/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0938 - accuracy: 0.5619 - val_loss: 1.2438 - val_accuracy: 0.5450\n",
      "Epoch 161/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0665 - accuracy: 0.5745 - val_loss: 1.2775 - val_accuracy: 0.5289\n",
      "Epoch 162/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0594 - accuracy: 0.5788 - val_loss: 1.2593 - val_accuracy: 0.5330\n",
      "Epoch 163/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0558 - accuracy: 0.5619 - val_loss: 1.2522 - val_accuracy: 0.5482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0537 - accuracy: 0.5732 - val_loss: 1.2499 - val_accuracy: 0.5418\n",
      "Epoch 165/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0229 - accuracy: 0.5939 - val_loss: 1.2486 - val_accuracy: 0.5378\n",
      "Epoch 166/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0595 - accuracy: 0.5658 - val_loss: 1.2524 - val_accuracy: 0.5241\n",
      "Epoch 167/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0395 - accuracy: 0.5771 - val_loss: 1.2423 - val_accuracy: 0.5498\n",
      "Epoch 168/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0344 - accuracy: 0.5935 - val_loss: 1.2365 - val_accuracy: 0.5523\n",
      "Epoch 169/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0254 - accuracy: 0.5853 - val_loss: 1.2746 - val_accuracy: 0.5297\n",
      "Epoch 170/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0415 - accuracy: 0.5788 - val_loss: 1.2345 - val_accuracy: 0.5611\n",
      "Epoch 171/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0394 - accuracy: 0.5853 - val_loss: 1.2371 - val_accuracy: 0.5362\n",
      "Epoch 172/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0361 - accuracy: 0.5740 - val_loss: 1.2468 - val_accuracy: 0.5442\n",
      "Epoch 173/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0161 - accuracy: 0.5935 - val_loss: 1.2442 - val_accuracy: 0.5402\n",
      "Epoch 174/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0299 - accuracy: 0.5818 - val_loss: 1.2672 - val_accuracy: 0.5426\n",
      "Epoch 175/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0200 - accuracy: 0.5814 - val_loss: 1.2167 - val_accuracy: 0.5514\n",
      "Epoch 176/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0209 - accuracy: 0.5944 - val_loss: 1.2866 - val_accuracy: 0.5257\n",
      "Epoch 177/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0377 - accuracy: 0.5840 - val_loss: 1.2578 - val_accuracy: 0.5265\n",
      "Epoch 178/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0067 - accuracy: 0.6043 - val_loss: 1.2248 - val_accuracy: 0.5450\n",
      "Epoch 179/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0176 - accuracy: 0.5991 - val_loss: 1.3121 - val_accuracy: 0.5000\n",
      "Epoch 180/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9996 - accuracy: 0.5983 - val_loss: 1.2557 - val_accuracy: 0.5474\n",
      "Epoch 181/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0116 - accuracy: 0.5961 - val_loss: 1.2361 - val_accuracy: 0.5442\n",
      "Epoch 182/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0048 - accuracy: 0.5900 - val_loss: 1.2335 - val_accuracy: 0.5273\n",
      "Epoch 183/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0048 - accuracy: 0.5961 - val_loss: 1.2404 - val_accuracy: 0.5506\n",
      "Epoch 184/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0305 - accuracy: 0.5978 - val_loss: 1.2489 - val_accuracy: 0.5458\n",
      "Epoch 185/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0036 - accuracy: 0.5952 - val_loss: 1.2434 - val_accuracy: 0.5498\n",
      "Epoch 186/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0167 - accuracy: 0.5827 - val_loss: 1.2328 - val_accuracy: 0.5450\n",
      "Epoch 187/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9985 - accuracy: 0.6100 - val_loss: 1.2243 - val_accuracy: 0.5474\n",
      "Epoch 188/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9661 - accuracy: 0.6104 - val_loss: 1.2248 - val_accuracy: 0.5474\n",
      "Epoch 189/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 0.9864 - accuracy: 0.6013 - val_loss: 1.2618 - val_accuracy: 0.5531\n",
      "Epoch 190/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 0.9867 - accuracy: 0.6009 - val_loss: 1.2231 - val_accuracy: 0.5539\n",
      "Epoch 191/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 0.9848 - accuracy: 0.6087 - val_loss: 1.2336 - val_accuracy: 0.5531\n",
      "Epoch 192/600\n",
      "73/73 [==============================] - 4s 54ms/step - loss: 0.9812 - accuracy: 0.6026 - val_loss: 1.2146 - val_accuracy: 0.5474\n",
      "Epoch 193/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9894 - accuracy: 0.6078 - val_loss: 1.2258 - val_accuracy: 0.5523\n",
      "Epoch 194/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 1.0069 - accuracy: 0.6100 - val_loss: 1.2569 - val_accuracy: 0.5442\n",
      "Epoch 195/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9952 - accuracy: 0.5965 - val_loss: 1.2346 - val_accuracy: 0.5514\n",
      "Epoch 196/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9825 - accuracy: 0.6048 - val_loss: 1.2269 - val_accuracy: 0.5450\n",
      "Epoch 197/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9830 - accuracy: 0.6026 - val_loss: 1.2052 - val_accuracy: 0.5466\n",
      "Epoch 198/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9825 - accuracy: 0.6026 - val_loss: 1.2151 - val_accuracy: 0.5563\n",
      "Epoch 199/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9875 - accuracy: 0.6017 - val_loss: 1.2313 - val_accuracy: 0.5378\n",
      "Epoch 200/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9835 - accuracy: 0.6065 - val_loss: 1.2220 - val_accuracy: 0.5442\n",
      "Epoch 201/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9896 - accuracy: 0.5974 - val_loss: 1.2360 - val_accuracy: 0.5346\n",
      "Epoch 202/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9717 - accuracy: 0.6130 - val_loss: 1.2259 - val_accuracy: 0.5402\n",
      "Epoch 203/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9614 - accuracy: 0.6104 - val_loss: 1.2125 - val_accuracy: 0.5394\n",
      "Epoch 204/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9661 - accuracy: 0.6221 - val_loss: 1.2178 - val_accuracy: 0.5370\n",
      "Epoch 205/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9734 - accuracy: 0.6087 - val_loss: 1.2187 - val_accuracy: 0.5563\n",
      "Epoch 206/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9675 - accuracy: 0.5961 - val_loss: 1.2261 - val_accuracy: 0.5450\n",
      "Epoch 207/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9673 - accuracy: 0.6108 - val_loss: 1.2105 - val_accuracy: 0.5402\n",
      "Epoch 208/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9597 - accuracy: 0.6104 - val_loss: 1.2141 - val_accuracy: 0.5595\n",
      "Epoch 209/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9685 - accuracy: 0.6087 - val_loss: 1.2008 - val_accuracy: 0.5651\n",
      "Epoch 210/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9747 - accuracy: 0.6100 - val_loss: 1.1911 - val_accuracy: 0.5346\n",
      "Epoch 211/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9516 - accuracy: 0.6113 - val_loss: 1.2222 - val_accuracy: 0.5490\n",
      "Epoch 212/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9410 - accuracy: 0.6126 - val_loss: 1.2631 - val_accuracy: 0.5434\n",
      "Epoch 213/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9448 - accuracy: 0.6121 - val_loss: 1.1831 - val_accuracy: 0.5587\n",
      "Epoch 214/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9439 - accuracy: 0.6173 - val_loss: 1.2053 - val_accuracy: 0.5547\n",
      "Epoch 215/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9502 - accuracy: 0.6126 - val_loss: 1.2305 - val_accuracy: 0.5563\n",
      "Epoch 216/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9614 - accuracy: 0.6013 - val_loss: 1.2226 - val_accuracy: 0.5651\n",
      "Epoch 217/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9482 - accuracy: 0.6069 - val_loss: 1.2297 - val_accuracy: 0.5523\n",
      "Epoch 218/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9336 - accuracy: 0.6247 - val_loss: 1.1958 - val_accuracy: 0.5643\n",
      "Epoch 219/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9162 - accuracy: 0.6290 - val_loss: 1.2146 - val_accuracy: 0.5587\n",
      "Epoch 220/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9470 - accuracy: 0.6117 - val_loss: 1.2005 - val_accuracy: 0.5571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/600\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.9332 - accuracy: 0.6169 - val_loss: 1.2196 - val_accuracy: 0.5603\n",
      "Epoch 222/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9433 - accuracy: 0.6087 - val_loss: 1.2121 - val_accuracy: 0.5627\n",
      "Epoch 223/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9170 - accuracy: 0.6403 - val_loss: 1.2394 - val_accuracy: 0.5498\n",
      "Epoch 224/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9529 - accuracy: 0.6117 - val_loss: 1.2057 - val_accuracy: 0.5587\n",
      "Epoch 225/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9328 - accuracy: 0.6173 - val_loss: 1.2577 - val_accuracy: 0.5506\n",
      "Epoch 226/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9388 - accuracy: 0.6199 - val_loss: 1.2052 - val_accuracy: 0.5635\n",
      "Epoch 227/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9410 - accuracy: 0.6126 - val_loss: 1.2221 - val_accuracy: 0.5563\n",
      "Epoch 228/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9297 - accuracy: 0.6121 - val_loss: 1.2527 - val_accuracy: 0.5523\n",
      "Epoch 229/600\n",
      "73/73 [==============================] - 2s 30ms/step - loss: 0.9342 - accuracy: 0.6316 - val_loss: 1.2119 - val_accuracy: 0.5514\n",
      "Epoch 230/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 0.9249 - accuracy: 0.6190 - val_loss: 1.2328 - val_accuracy: 0.5547\n",
      "Epoch 231/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 0.9220 - accuracy: 0.6325 - val_loss: 1.1928 - val_accuracy: 0.5796\n",
      "Epoch 232/600\n",
      "73/73 [==============================] - 4s 54ms/step - loss: 0.9432 - accuracy: 0.6091 - val_loss: 1.2220 - val_accuracy: 0.5643\n",
      "Epoch 233/600\n",
      "73/73 [==============================] - 3s 47ms/step - loss: 0.9168 - accuracy: 0.6329 - val_loss: 1.1902 - val_accuracy: 0.5643\n",
      "Epoch 234/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9493 - accuracy: 0.6117 - val_loss: 1.1895 - val_accuracy: 0.5715\n",
      "Epoch 235/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9100 - accuracy: 0.6264 - val_loss: 1.2033 - val_accuracy: 0.5699\n",
      "Epoch 236/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9237 - accuracy: 0.6169 - val_loss: 1.2110 - val_accuracy: 0.5683\n",
      "Epoch 237/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9183 - accuracy: 0.6247 - val_loss: 1.2049 - val_accuracy: 0.5627\n",
      "Epoch 238/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9278 - accuracy: 0.6195 - val_loss: 1.2471 - val_accuracy: 0.5595\n",
      "Epoch 239/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9034 - accuracy: 0.6342 - val_loss: 1.2073 - val_accuracy: 0.5643\n",
      "Epoch 240/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9137 - accuracy: 0.6273 - val_loss: 1.1800 - val_accuracy: 0.5707\n",
      "Epoch 241/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9276 - accuracy: 0.6212 - val_loss: 1.1902 - val_accuracy: 0.5707\n",
      "Epoch 242/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9157 - accuracy: 0.6190 - val_loss: 1.2268 - val_accuracy: 0.5498\n",
      "Epoch 243/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8845 - accuracy: 0.6325 - val_loss: 1.2258 - val_accuracy: 0.5595\n",
      "Epoch 244/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9212 - accuracy: 0.6121 - val_loss: 1.2076 - val_accuracy: 0.5547\n",
      "Epoch 245/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9406 - accuracy: 0.6091 - val_loss: 1.1896 - val_accuracy: 0.5667\n",
      "Epoch 246/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8848 - accuracy: 0.6416 - val_loss: 1.1748 - val_accuracy: 0.5780\n",
      "Epoch 247/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9143 - accuracy: 0.6299 - val_loss: 1.2120 - val_accuracy: 0.5667\n",
      "Epoch 248/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8947 - accuracy: 0.6273 - val_loss: 1.2048 - val_accuracy: 0.5627\n",
      "Epoch 249/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8964 - accuracy: 0.6255 - val_loss: 1.2454 - val_accuracy: 0.5490\n",
      "Epoch 250/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9100 - accuracy: 0.6312 - val_loss: 1.2232 - val_accuracy: 0.5563\n",
      "Epoch 251/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9172 - accuracy: 0.6316 - val_loss: 1.2016 - val_accuracy: 0.5707\n",
      "Epoch 252/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8902 - accuracy: 0.6450 - val_loss: 1.2197 - val_accuracy: 0.5402\n",
      "Epoch 253/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9036 - accuracy: 0.6190 - val_loss: 1.2009 - val_accuracy: 0.5603\n",
      "Epoch 254/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9310 - accuracy: 0.6156 - val_loss: 1.2228 - val_accuracy: 0.5667\n",
      "Epoch 255/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8982 - accuracy: 0.6333 - val_loss: 1.1989 - val_accuracy: 0.5603\n",
      "Epoch 256/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8717 - accuracy: 0.6476 - val_loss: 1.2272 - val_accuracy: 0.5571\n",
      "Epoch 257/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9010 - accuracy: 0.6195 - val_loss: 1.1926 - val_accuracy: 0.5740\n",
      "Epoch 258/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8744 - accuracy: 0.6394 - val_loss: 1.2178 - val_accuracy: 0.5482\n",
      "Epoch 259/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8820 - accuracy: 0.6442 - val_loss: 1.1965 - val_accuracy: 0.5748\n",
      "Epoch 260/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8922 - accuracy: 0.6333 - val_loss: 1.1888 - val_accuracy: 0.5723\n",
      "Epoch 261/600\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.8826 - accuracy: 0.6268 - val_loss: 1.1883 - val_accuracy: 0.5675\n",
      "Epoch 262/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.9019 - accuracy: 0.6299 - val_loss: 1.1860 - val_accuracy: 0.5756\n",
      "Epoch 263/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8793 - accuracy: 0.6394 - val_loss: 1.1895 - val_accuracy: 0.5748\n",
      "Epoch 264/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8761 - accuracy: 0.6442 - val_loss: 1.2026 - val_accuracy: 0.5707\n",
      "Epoch 265/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8813 - accuracy: 0.6342 - val_loss: 1.2211 - val_accuracy: 0.5619\n",
      "Epoch 266/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8936 - accuracy: 0.6394 - val_loss: 1.1823 - val_accuracy: 0.5740\n",
      "Epoch 267/600\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.8718 - accuracy: 0.6472 - val_loss: 1.1900 - val_accuracy: 0.5740\n",
      "Epoch 268/600\n",
      "73/73 [==============================] - 3s 45ms/step - loss: 0.8739 - accuracy: 0.6416 - val_loss: 1.2029 - val_accuracy: 0.5715\n",
      "Epoch 269/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 0.8803 - accuracy: 0.6238 - val_loss: 1.1761 - val_accuracy: 0.5715\n",
      "Epoch 270/600\n",
      "73/73 [==============================] - 5s 63ms/step - loss: 0.8648 - accuracy: 0.6416 - val_loss: 1.1939 - val_accuracy: 0.5820\n",
      "Epoch 271/600\n",
      "73/73 [==============================] - 5s 64ms/step - loss: 0.8727 - accuracy: 0.6407 - val_loss: 1.2323 - val_accuracy: 0.5764\n",
      "Epoch 272/600\n",
      "73/73 [==============================] - 2s 28ms/step - loss: 0.8758 - accuracy: 0.6411 - val_loss: 1.1952 - val_accuracy: 0.5732\n",
      "Epoch 273/600\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.8614 - accuracy: 0.6528 - val_loss: 1.2005 - val_accuracy: 0.5812\n",
      "Epoch 274/600\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.8774 - accuracy: 0.6273 - val_loss: 1.2426 - val_accuracy: 0.5611\n",
      "Epoch 275/600\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.8689 - accuracy: 0.6424 - val_loss: 1.2524 - val_accuracy: 0.5498\n",
      "Epoch 276/600\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.8778 - accuracy: 0.6433 - val_loss: 1.2263 - val_accuracy: 0.5683\n",
      "Epoch 277/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8717 - accuracy: 0.6394 - val_loss: 1.2348 - val_accuracy: 0.5812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8675 - accuracy: 0.6407 - val_loss: 1.2289 - val_accuracy: 0.5715\n",
      "Epoch 279/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8667 - accuracy: 0.6424 - val_loss: 1.2184 - val_accuracy: 0.5748\n",
      "Epoch 280/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8696 - accuracy: 0.6476 - val_loss: 1.1821 - val_accuracy: 0.5957\n",
      "Epoch 281/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8605 - accuracy: 0.6416 - val_loss: 1.2087 - val_accuracy: 0.5651\n",
      "Epoch 282/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8738 - accuracy: 0.6325 - val_loss: 1.2131 - val_accuracy: 0.5611\n",
      "Epoch 283/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8562 - accuracy: 0.6364 - val_loss: 1.1872 - val_accuracy: 0.5772\n",
      "Epoch 284/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8582 - accuracy: 0.6420 - val_loss: 1.2525 - val_accuracy: 0.5627\n",
      "Epoch 285/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8652 - accuracy: 0.6450 - val_loss: 1.2876 - val_accuracy: 0.5474\n",
      "Epoch 286/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8483 - accuracy: 0.6519 - val_loss: 1.2224 - val_accuracy: 0.5780\n",
      "Epoch 287/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8603 - accuracy: 0.6437 - val_loss: 1.2089 - val_accuracy: 0.5812\n",
      "Epoch 288/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8388 - accuracy: 0.6459 - val_loss: 1.1956 - val_accuracy: 0.5699\n",
      "Epoch 289/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8589 - accuracy: 0.6390 - val_loss: 1.1919 - val_accuracy: 0.5812\n",
      "Epoch 290/600\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.8567 - accuracy: 0.6346 - val_loss: 1.1911 - val_accuracy: 0.5844\n",
      "Epoch 291/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8514 - accuracy: 0.6416 - val_loss: 1.2231 - val_accuracy: 0.5780\n",
      "Epoch 292/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8439 - accuracy: 0.6563 - val_loss: 1.1974 - val_accuracy: 0.5740\n",
      "Epoch 293/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8681 - accuracy: 0.6277 - val_loss: 1.2191 - val_accuracy: 0.5707\n",
      "Epoch 294/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8879 - accuracy: 0.6316 - val_loss: 1.1862 - val_accuracy: 0.5860\n",
      "Epoch 295/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8557 - accuracy: 0.6459 - val_loss: 1.2384 - val_accuracy: 0.5667\n",
      "Epoch 296/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8395 - accuracy: 0.6472 - val_loss: 1.1779 - val_accuracy: 0.5876\n",
      "Epoch 297/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8532 - accuracy: 0.6446 - val_loss: 1.1891 - val_accuracy: 0.5860\n",
      "Epoch 298/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8523 - accuracy: 0.6472 - val_loss: 1.1832 - val_accuracy: 0.5892\n",
      "Epoch 299/600\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.8481 - accuracy: 0.6450 - val_loss: 1.2040 - val_accuracy: 0.5715\n",
      "Epoch 300/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8427 - accuracy: 0.6554 - val_loss: 1.1899 - val_accuracy: 0.5836\n",
      "Epoch 301/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8427 - accuracy: 0.6567 - val_loss: 1.1873 - val_accuracy: 0.5836\n",
      "Epoch 302/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8511 - accuracy: 0.6429 - val_loss: 1.1964 - val_accuracy: 0.5764\n",
      "Epoch 303/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8452 - accuracy: 0.6420 - val_loss: 1.1822 - val_accuracy: 0.5884\n",
      "Epoch 304/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8448 - accuracy: 0.6524 - val_loss: 1.1928 - val_accuracy: 0.5748\n",
      "Epoch 305/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8383 - accuracy: 0.6489 - val_loss: 1.2138 - val_accuracy: 0.5748\n",
      "Epoch 306/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8433 - accuracy: 0.6481 - val_loss: 1.2107 - val_accuracy: 0.5804\n",
      "Epoch 307/600\n",
      "73/73 [==============================] - 3s 47ms/step - loss: 0.8398 - accuracy: 0.6411 - val_loss: 1.2032 - val_accuracy: 0.5932\n",
      "Epoch 308/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 0.8272 - accuracy: 0.6632 - val_loss: 1.2137 - val_accuracy: 0.5916\n",
      "Epoch 309/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 0.8290 - accuracy: 0.6619 - val_loss: 1.1957 - val_accuracy: 0.5852\n",
      "Epoch 310/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 0.8266 - accuracy: 0.6550 - val_loss: 1.1950 - val_accuracy: 0.5973\n",
      "Epoch 311/600\n",
      "73/73 [==============================] - 2s 32ms/step - loss: 0.8350 - accuracy: 0.6567 - val_loss: 1.1507 - val_accuracy: 0.6069\n",
      "Epoch 312/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8290 - accuracy: 0.6563 - val_loss: 1.2276 - val_accuracy: 0.5820\n",
      "Epoch 313/600\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.8216 - accuracy: 0.6636 - val_loss: 1.2511 - val_accuracy: 0.5699\n",
      "Epoch 314/600\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.8306 - accuracy: 0.6537 - val_loss: 1.2376 - val_accuracy: 0.5748\n",
      "Epoch 315/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8180 - accuracy: 0.6550 - val_loss: 1.2133 - val_accuracy: 0.5876\n",
      "Epoch 316/600\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.8380 - accuracy: 0.6476 - val_loss: 1.1984 - val_accuracy: 0.5924\n",
      "Epoch 317/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8356 - accuracy: 0.6541 - val_loss: 1.1770 - val_accuracy: 0.6109\n",
      "Epoch 318/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7969 - accuracy: 0.6654 - val_loss: 1.2023 - val_accuracy: 0.5997\n",
      "Epoch 319/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8075 - accuracy: 0.6706 - val_loss: 1.2265 - val_accuracy: 0.5924\n",
      "Epoch 320/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8193 - accuracy: 0.6571 - val_loss: 1.1972 - val_accuracy: 0.5748\n",
      "Epoch 321/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8245 - accuracy: 0.6602 - val_loss: 1.2156 - val_accuracy: 0.5844\n",
      "Epoch 322/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8383 - accuracy: 0.6571 - val_loss: 1.2131 - val_accuracy: 0.5900\n",
      "Epoch 323/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8174 - accuracy: 0.6779 - val_loss: 1.2170 - val_accuracy: 0.5908\n",
      "Epoch 324/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8160 - accuracy: 0.6606 - val_loss: 1.2154 - val_accuracy: 0.5924\n",
      "Epoch 325/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8046 - accuracy: 0.6732 - val_loss: 1.2045 - val_accuracy: 0.5900\n",
      "Epoch 326/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8058 - accuracy: 0.6628 - val_loss: 1.2039 - val_accuracy: 0.5884\n",
      "Epoch 327/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8159 - accuracy: 0.6593 - val_loss: 1.2573 - val_accuracy: 0.5852\n",
      "Epoch 328/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8098 - accuracy: 0.6606 - val_loss: 1.2069 - val_accuracy: 0.6069\n",
      "Epoch 329/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8166 - accuracy: 0.6511 - val_loss: 1.2245 - val_accuracy: 0.5876\n",
      "Epoch 330/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8230 - accuracy: 0.6628 - val_loss: 1.2482 - val_accuracy: 0.5820\n",
      "Epoch 331/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8093 - accuracy: 0.6645 - val_loss: 1.2012 - val_accuracy: 0.5932\n",
      "Epoch 332/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8049 - accuracy: 0.6697 - val_loss: 1.2457 - val_accuracy: 0.5884\n",
      "Epoch 333/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8120 - accuracy: 0.6615 - val_loss: 1.2246 - val_accuracy: 0.5828\n",
      "Epoch 334/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7913 - accuracy: 0.6732 - val_loss: 1.2301 - val_accuracy: 0.5989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/600\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.7999 - accuracy: 0.6667 - val_loss: 1.2338 - val_accuracy: 0.5764\n",
      "Epoch 336/600\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.8003 - accuracy: 0.6697 - val_loss: 1.2097 - val_accuracy: 0.5876\n",
      "Epoch 337/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8041 - accuracy: 0.6619 - val_loss: 1.1983 - val_accuracy: 0.6061\n",
      "Epoch 338/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8152 - accuracy: 0.6580 - val_loss: 1.2235 - val_accuracy: 0.5836\n",
      "Epoch 339/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7895 - accuracy: 0.6762 - val_loss: 1.2210 - val_accuracy: 0.5924\n",
      "Epoch 340/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7924 - accuracy: 0.6775 - val_loss: 1.2115 - val_accuracy: 0.6045\n",
      "Epoch 341/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8063 - accuracy: 0.6628 - val_loss: 1.2281 - val_accuracy: 0.5860\n",
      "Epoch 342/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7926 - accuracy: 0.6775 - val_loss: 1.2197 - val_accuracy: 0.5844\n",
      "Epoch 343/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8008 - accuracy: 0.6623 - val_loss: 1.2479 - val_accuracy: 0.5908\n",
      "Epoch 344/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8021 - accuracy: 0.6680 - val_loss: 1.2091 - val_accuracy: 0.6077\n",
      "Epoch 345/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7945 - accuracy: 0.6619 - val_loss: 1.2129 - val_accuracy: 0.5908\n",
      "Epoch 346/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7724 - accuracy: 0.6879 - val_loss: 1.2149 - val_accuracy: 0.6005\n",
      "Epoch 347/600\n",
      "73/73 [==============================] - 3s 40ms/step - loss: 0.8185 - accuracy: 0.6537 - val_loss: 1.2316 - val_accuracy: 0.5852\n",
      "Epoch 348/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 0.8111 - accuracy: 0.6632 - val_loss: 1.2466 - val_accuracy: 0.5820\n",
      "Epoch 349/600\n",
      "73/73 [==============================] - 4s 54ms/step - loss: 0.8035 - accuracy: 0.6623 - val_loss: 1.2021 - val_accuracy: 0.6053\n",
      "Epoch 350/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 0.8003 - accuracy: 0.6619 - val_loss: 1.2136 - val_accuracy: 0.6005\n",
      "Epoch 351/600\n",
      "73/73 [==============================] - 3s 39ms/step - loss: 0.8088 - accuracy: 0.6680 - val_loss: 1.1983 - val_accuracy: 0.6166\n",
      "Epoch 352/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7905 - accuracy: 0.6675 - val_loss: 1.1763 - val_accuracy: 0.6069\n",
      "Epoch 353/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7944 - accuracy: 0.6645 - val_loss: 1.2376 - val_accuracy: 0.5981\n",
      "Epoch 354/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.8174 - accuracy: 0.6532 - val_loss: 1.1870 - val_accuracy: 0.5941\n",
      "Epoch 355/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7854 - accuracy: 0.6675 - val_loss: 1.2123 - val_accuracy: 0.5997\n",
      "Epoch 356/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7825 - accuracy: 0.6818 - val_loss: 1.2076 - val_accuracy: 0.5949\n",
      "Epoch 357/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7831 - accuracy: 0.6680 - val_loss: 1.2005 - val_accuracy: 0.6029\n",
      "Epoch 358/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7895 - accuracy: 0.6727 - val_loss: 1.2091 - val_accuracy: 0.6037\n",
      "Epoch 359/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7803 - accuracy: 0.6684 - val_loss: 1.2390 - val_accuracy: 0.5973\n",
      "Epoch 360/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7949 - accuracy: 0.6827 - val_loss: 1.2299 - val_accuracy: 0.5868\n",
      "Epoch 361/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7835 - accuracy: 0.6719 - val_loss: 1.2080 - val_accuracy: 0.6021\n",
      "Epoch 362/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7921 - accuracy: 0.6719 - val_loss: 1.1907 - val_accuracy: 0.6174\n",
      "Epoch 363/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7861 - accuracy: 0.6645 - val_loss: 1.2039 - val_accuracy: 0.6174\n",
      "Epoch 364/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7667 - accuracy: 0.6736 - val_loss: 1.2069 - val_accuracy: 0.6077\n",
      "Epoch 365/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7869 - accuracy: 0.6684 - val_loss: 1.2261 - val_accuracy: 0.5900\n",
      "Epoch 366/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7655 - accuracy: 0.6779 - val_loss: 1.2399 - val_accuracy: 0.5908\n",
      "Epoch 367/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7979 - accuracy: 0.6632 - val_loss: 1.2391 - val_accuracy: 0.6029\n",
      "Epoch 368/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7931 - accuracy: 0.6610 - val_loss: 1.2616 - val_accuracy: 0.5732\n",
      "Epoch 369/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7759 - accuracy: 0.6814 - val_loss: 1.2197 - val_accuracy: 0.5941\n",
      "Epoch 370/600\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.7745 - accuracy: 0.6818 - val_loss: 1.2229 - val_accuracy: 0.6109\n",
      "Epoch 371/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7901 - accuracy: 0.6727 - val_loss: 1.2708 - val_accuracy: 0.5651\n",
      "Epoch 372/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7748 - accuracy: 0.6758 - val_loss: 1.2363 - val_accuracy: 0.5804\n",
      "Epoch 373/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7815 - accuracy: 0.6753 - val_loss: 1.2119 - val_accuracy: 0.6093\n",
      "Epoch 374/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7647 - accuracy: 0.6753 - val_loss: 1.2266 - val_accuracy: 0.5924\n",
      "Epoch 375/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7668 - accuracy: 0.6758 - val_loss: 1.1986 - val_accuracy: 0.6093\n",
      "Epoch 376/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7693 - accuracy: 0.6779 - val_loss: 1.2012 - val_accuracy: 0.5860\n",
      "Epoch 377/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7617 - accuracy: 0.6758 - val_loss: 1.2815 - val_accuracy: 0.5531\n",
      "Epoch 378/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7725 - accuracy: 0.6797 - val_loss: 1.2297 - val_accuracy: 0.6053\n",
      "Epoch 379/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7584 - accuracy: 0.6801 - val_loss: 1.2234 - val_accuracy: 0.5908\n",
      "Epoch 380/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7829 - accuracy: 0.6758 - val_loss: 1.2520 - val_accuracy: 0.5796\n",
      "Epoch 381/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7883 - accuracy: 0.6710 - val_loss: 1.1817 - val_accuracy: 0.6013\n",
      "Epoch 382/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7697 - accuracy: 0.6818 - val_loss: 1.2123 - val_accuracy: 0.6174\n",
      "Epoch 383/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7677 - accuracy: 0.6688 - val_loss: 1.1856 - val_accuracy: 0.6045\n",
      "Epoch 384/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7701 - accuracy: 0.6848 - val_loss: 1.2483 - val_accuracy: 0.5892\n",
      "Epoch 385/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7536 - accuracy: 0.6844 - val_loss: 1.2200 - val_accuracy: 0.5916\n",
      "Epoch 386/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7752 - accuracy: 0.6749 - val_loss: 1.1985 - val_accuracy: 0.6198\n",
      "Epoch 387/600\n",
      "73/73 [==============================] - 2s 28ms/step - loss: 0.7632 - accuracy: 0.6671 - val_loss: 1.2127 - val_accuracy: 0.5916\n",
      "Epoch 388/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 0.7693 - accuracy: 0.6753 - val_loss: 1.2593 - val_accuracy: 0.5852\n",
      "Epoch 389/600\n",
      "73/73 [==============================] - 4s 55ms/step - loss: 0.7728 - accuracy: 0.6771 - val_loss: 1.2403 - val_accuracy: 0.5957\n",
      "Epoch 390/600\n",
      "73/73 [==============================] - 4s 56ms/step - loss: 0.7618 - accuracy: 0.6840 - val_loss: 1.2008 - val_accuracy: 0.6077\n",
      "Epoch 391/600\n",
      "73/73 [==============================] - 4s 50ms/step - loss: 0.7473 - accuracy: 0.6896 - val_loss: 1.2133 - val_accuracy: 0.6077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7825 - accuracy: 0.6610 - val_loss: 1.2428 - val_accuracy: 0.5989\n",
      "Epoch 393/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7647 - accuracy: 0.6727 - val_loss: 1.2012 - val_accuracy: 0.5957\n",
      "Epoch 394/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7837 - accuracy: 0.6732 - val_loss: 1.2578 - val_accuracy: 0.5723\n",
      "Epoch 395/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7553 - accuracy: 0.6784 - val_loss: 1.2107 - val_accuracy: 0.6150\n",
      "Epoch 396/600\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.7711 - accuracy: 0.6866 - val_loss: 1.1881 - val_accuracy: 0.6037\n",
      "Epoch 397/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7595 - accuracy: 0.6745 - val_loss: 1.2261 - val_accuracy: 0.5932\n",
      "Epoch 398/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7483 - accuracy: 0.6857 - val_loss: 1.2190 - val_accuracy: 0.6125\n",
      "Epoch 399/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7786 - accuracy: 0.6680 - val_loss: 1.2174 - val_accuracy: 0.5957\n",
      "Epoch 400/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7614 - accuracy: 0.6788 - val_loss: 1.2186 - val_accuracy: 0.6141\n",
      "Epoch 401/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7399 - accuracy: 0.6913 - val_loss: 1.2070 - val_accuracy: 0.6053\n",
      "Epoch 402/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7791 - accuracy: 0.6632 - val_loss: 1.1993 - val_accuracy: 0.6077\n",
      "Epoch 403/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7406 - accuracy: 0.6944 - val_loss: 1.2152 - val_accuracy: 0.5941\n",
      "Epoch 404/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7402 - accuracy: 0.6840 - val_loss: 1.2393 - val_accuracy: 0.5780\n",
      "Epoch 405/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7600 - accuracy: 0.6939 - val_loss: 1.2283 - val_accuracy: 0.5997\n",
      "Epoch 406/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7473 - accuracy: 0.6874 - val_loss: 1.2009 - val_accuracy: 0.6101\n",
      "Epoch 407/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7569 - accuracy: 0.6831 - val_loss: 1.2335 - val_accuracy: 0.5989\n",
      "Epoch 408/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7582 - accuracy: 0.6719 - val_loss: 1.2193 - val_accuracy: 0.5965\n",
      "Epoch 409/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7602 - accuracy: 0.6753 - val_loss: 1.2758 - val_accuracy: 0.5812\n",
      "Epoch 410/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7550 - accuracy: 0.6840 - val_loss: 1.2065 - val_accuracy: 0.6045\n",
      "Epoch 411/600\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.7722 - accuracy: 0.6684 - val_loss: 1.2486 - val_accuracy: 0.5916\n",
      "Accuracy of the model on test set: 60.691%\n",
      "Accuracy of the model on validation set: 16.983%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "np.random.seed = 123\n",
    "\n",
    "y = Data_train.Emotion\n",
    "X = pd.DataFrame(Data_train.drop(['Emotion','User'], axis = 1))\n",
    "\n",
    "y_val = Data_val.Emotion\n",
    "X_val = pd.DataFrame(Data_val.drop(['Emotion', 'User'], axis = 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.35, random_state = 123)\n",
    "\n",
    "\n",
    "#Trying adam optimizer\n",
    "model = initModelGRU(X.shape[1], 7, 'softmax') \n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy', # sparse because using integer labels for emotions (not OHE)\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    #validation_split = 0.3,\n",
    "    #validation_data = (X_val, y_val),\n",
    "    validation_data = (X_test, y_test),\n",
    "    epochs=600,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=100,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Result on test data\n",
    "model_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(\"Accuracy of the model on test set: {:.3f}%\".format(model_acc * 100))\n",
    "\n",
    "#Result on val data\n",
    "model_acc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "print(\"Accuracy of the model on validation set: {:.3f}%\".format(model_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f77d41c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 8_features_train_test_16.983\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x00000224D56F10D0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x00000224A2CBC370> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on test set: 60.691%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA7RElEQVR4nO3dd5hU5fnw8e9NRylLWVApLiAgCGJBEOwlShQVxF6wYzTYNaI/g4rxNSZRjMGaqFgBJQpEwQJqIlZAsIFKl0UQpOxSlv68f9zn4ZyZnd2dhZ2d3Z37c117nTpnnjniuc/TxTmHMcaYzFUt3QkwxhiTXhYIjDEmw1kgMMaYDGeBwBhjMpwFAmOMyXAWCIwxJsNZIDAVnog4EdkvWH9SRP6YzLm78D0Xisi7u5pOYyorsX4EJtVE5G3gC+fc0Lj9ZwBPAS2dc9uK+bwD2jvn5iXxXUmdKyI5wEKgZnHfbUwmsByBKQ/PAxeJiMTtvxh42R7EqSUiNdKdBlOxWSAw5WEc0AQ4yu8QkUZAX+AFEekhIp+KyFoRWSYiI0SkVqILichIEflTZPu24DM/i8jlceeeKiIzRSRfRJaIyD2Rw/8LlmtFZL2I9BKRS0VkauTzvUVkmojkBcvekWMfish9IvKxiKwTkXdFpGkRaW4kIm+KyEoRWROst4wcbywizwW/YY2IjIscO0NEZgW/Yb6I9An2LxKREyPn3SMiLwXrOUER2RUi8hPwfrD/NRFZHvye/4nIAZHP1xWRh0RkcXB8arDvLRG5Lu73fC0i/RP9VlM5WSAwKeecKwBeBQZGdp8DfO+c+wrYDtwENAV6AScA15Z03eCheCvwG6A9cGLcKRuC78wCTgWuEZF+wbGjg2WWc66ec+7TuGs3Bt4CHkWD2MPAWyLSJHLaBcBlQDOgVpCWRKoBzwH7Aq2BAmBE5PiLwB7AAcG1hgdp6AG8ANwW/IajgUVFfEcixwCdgJOD7UnofWoGfAm8HDn3b8ChQG+gMfAHYAdBbs6fJCLdgBbovTFVhXPO/uwv5X/AkcBaoE6w/TFwUxHn3gi8Edl2wH7B+kjgT8H6s8CfI+d1iJ6b4LqPAMOD9Zzg3BqR45cCU4P1i9F6jejnPwUuDdY/BO6KHLsWeDvJe3EQsCZY3xt94DZKcN5TPr0Jji0CToxs3wO8FPfb2haThqzgnIZooCoAuiU4rw6wBq13AQ0Yj6f735P9le2f5QhMuXDOTQV+BfqJSDugB/AKgIh0CIpLlotIPvD/0NxBSfYBlkS2F0cPikhPEfkgKJLJA36X5HX9tRfH7VuMvg17yyPrG4F6iS4kInuIyFNBsUs+WiyVJSLVgVbAaufcmgQfbQXMTzK9iey8NyJSXUT+HBQv5RPmLJoGf3USfZdzbhMwBq3jqQacj+ZgTBVigcCUpxfQopqLgHecc78E+58AvkffOhsAdwLxFcuJLEMfll7ruOOvABOAVs65hsCTkeuW1FzuZ7QoJ6o1sDSJdMW7BegI9Ax+ny+WEvRh3VhEshJ8bgnQrohrbkCLk7y9EpwT/Y0XAGegxWcN0VyDT8OvwKZivut54EK0yG6jiytGM5WfBQJTnl5AH0RXoQ8Xrz6QD6wXkf2Ba5K83qvApSLSWUT2AO6OO14ffdveFJS3XxA5thItkmlbxLUnAh1E5AIRqSEi5wKdgTeTTFt8OgrQiunG0XQ655ahZfePB5XKNUXEB4pngMtE5AQRqSYiLYL7AzALOC84vztwVhJp2AysQgPI/4ukYQdazPawiOwT5B56iUjt4Pin6L16CMsNVEkWCEy5cc4tAj4B9kTf1L1b0Yf0OuCfaFFEMtebhJb7vw/MC5ZR1wLDRGQdMBQNHP6zG4H7gY+D1kqHx117Fdqq6Rb04fkHoK9z7tdk0hbnEaAu+ub9GfB23PGLga1ormgFWkeCc+4LtDJ6OJAH/Jcwl/JH9A1+DXAvQTFbMV5Ai7aWArODdETdCnwDTANWAw8S+3x4AegKvFTC95hKyDqUGWNKJCIDgUHOuSPTnRZT9ixHYIwpVlDsdi3wdLrTYlLDAoExpkgicjJan/ILJRc/mUrKioaMMSbDWY7AGGMyXKUbjKpp06YuJycn3ckwxphKZcaMGb8657ITHat0gSAnJ4fp06enOxnGGFOpiEh8T/mdrGjIGGMynAUCY4zJcBYIjDEmw1W6OoJEtm7dSm5uLps2bUp3UiqtOnXq0LJlS2rWrJnupBhjylmVCAS5ubnUr1+fnJwcpNBsiKYkzjlWrVpFbm4ubdq0SXdyjDHlrEoUDW3atIkmTZpYENhFIkKTJk0sR2VMhqoSgQCwILCb7P4Zk7mqTCAwxpgK57vv4L//TXcqSmSBoAyNGzcOEeH7779Pd1KMMbvj11/h8cdh5szSf/ann8B3eu3SBY49tkyTlgoWCMrQqFGjOPLIIxk1alTKvmP79u0pu7YxGeOPf4Rjjin6+JNPwu9/D5ddVvprd+wIhx1W8nnffgv5+aW/fgpYICgj69evZ+rUqTzzzDOMHj0a0If2rbfeSpcuXTjwwAP5xz/+AcC0adPo3bs33bp1o0ePHqxbt46RI0cyePDgndfr27cvH374IQD16tXjlltuoVu3bnz66acMGzaMww47jC5dujBo0CD8CLLz5s3jxBNPpFu3bhxyyCHMnz+fgQMHMm7cuJ3XvfDCCxk/fnz53BRjKqovvoCpU2HjxsTHFwejMcyZA9u2le7avtFF9NqJRnk+8kh44AFYtUrTIqLBIQ2qRPPRGDfeCLNmle01DzoIHnmk2FPGjx9Pnz596NChA02aNGHGjBl88cUXLFq0iFmzZlGjRg1Wr17Nli1bOPfccxkzZgyHHXYY+fn51K1bt9hrb9iwgZ49e/LQQw8B0LlzZ4YOHQrAxRdfzJtvvslpp53GhRdeyJAhQ+jfvz+bNm1ix44dXHHFFQwfPpx+/fqRl5fHJ598wvPPP1/c1xmTXm+9Ba1awYEHpu47li6FHTtg9mzo3j3xcYAtW2DePNg/mCp6wQKYMQPOPrvk71i0KFzfuBH23DPc3roV8vLgm2+gadNw/z//CX//u66vXw/Vq0MJz4eyYDmCMjJq1CjOO+88AM477zxGjRrF5MmTufrqq6lRQ+Nt48aN+eGHH9h77705LMg6NmjQYOfxolSvXp0BAwbs3P7ggw/o2bMnXbt25f333+e7775j3bp1LF26lP79+wPaQWyPPfbgmGOOYe7cuaxcuZJRo0YxYMCAEr/PmLTq2xe6dSu76+3YoX9RP/+sy6+/TvyZ3FwNRhD7ln7ggXDOObBkCZx8MtxwA/zrX+Hx6Jv/woXhel4ebN+u3+scFBTo/h9+iP3en34K01q/vr6EloOq90Qo4c09FVavXs3777/PN998g4iwfft2RGTnwz4ZNWrUYEfkH2u0TX+dOnWoXr36zv3XXnst06dPp1WrVtxzzz0ltv8fOHAgL730EqNHj+a5554r5a8zJoWWLoW77tKK2bp19WFZklGjtGz96qsLH/vsM+jcGRo0CPfVqwc9e8IHH+h2QQGsWaPrxQWCfv1g5Eht+XPWWbp/wwZdDhsG776rfwBXXqnLaJl/fCC4+24NGvfeC4MGFT4HYNw4uPBCePll3f7xxyJuQtlKaY5ARPqIyA8iMk9EhhRxzjkiMltEvhORSjkV3tixY7n44otZvHgxixYtYsmSJbRp04Zu3brx1FNPsS0oY1y9ejUdO3Zk2bJlTJs2DYB169axbds2cnJymDVrFjt27GDJkiV88cUXCb/LP/SbNm3K+vXrGTt2LAD169enZcuWO+sDNm/ezMagjPLSSy/lkSBAdu7cOVW3wZjSGzRIH7a+ieWqVeGx+Ld474IL4He/K7x//Xro1QvOPVeDxcSJur+gAIL6NvLyYI89ws988024npenb/8bN2qgaN8emjULcw9R8f1ubrlFA0703DlzYq8d/D/PRx+F9QeJAt/o0Zoz8LZtgxdfhPfeK3xuGUlZjkBEqgOPAb8BcoFpIjLBOTc7ck574A7gCOfcGhFplqr0pNKoUaO4/fbbY/YNGDCAOXPm0Lp1aw488EBq1qzJVVddxeDBgxkzZgzXXXcdBQUF1K1bl8mTJ3PEEUfQpk0bOnfuTKdOnTjkkEMSfldWVhZXXXUVXbp0Ya+99orJdbz44otcffXVDB06lJo1a/Laa6/Rtm1bmjdvTqdOnejXr18qb4MxpefL0asF76S//BIey82F1q2Tv5b/7Oefw9tv6/rmzbHnRN/A990XvvpKi2pWrIC99tL9Pmi0bKn7li/Xt/RoGX98IHj4YV1GH+DRIqW8PJg/X9dnzQpzFvHatNHfEQ0iP/0EAwfqeqqmFnbOpeQP6AW8E9m+A7gj7py/AFeW5rqHHnqoizd79uxC+0xow4YNrm3btm7t2rXFnmf30ZS7hg2dA+dGj9bt997TbdD1RPzxrVvDfevXO/fxx7o/Kys8Z/HicP3YY52bMCHcvvJKXU6a5NxVV4X7r7hCl1OmOHfSSc716BEe838XXVR4Hzh3//26bN3auSZNwv0jRuiyQwddvv564c/WqOHc8OG6fued4f5Jk8L13QBMd0U8V1NZNNQCWBLZzg32RXUAOojIxyLymYj0SXQhERkkItNFZPrKlStTlNyqafLkyXTq1InrrruOhg0bpjs5xoSc0zdlCMvsozmCr75K/Bnv1191OWWKFsv8+9+6vXZteM6yZeH6hx/ChAm6fsYZWsQE8Nvfamsd0AraF17QdZ8jWBJ9jFE4nQC1aunyyy91efDBscVcfr9vbfTWW4WvuWOH5lJ8Wr1Jk8L1FPUjSneroRpAe+BY4HzgnyKSFX+Sc+5p51x351z37OyEU26aIpx44oksXryYG2+8Md1JMZXV8uVw/fXa5LEsRcvT4wNBo0bw6aeFPxOtjF2xQpf+Qfn664XPj3+I+6Kbf/wDevQofP5xx4W/s0ULDQTRYOItXx677VvizZypTT4POCD2+IwZurzgAu1t/Mwzuh1f3OQDwYwZ0K4dXHEFPPpoeE6itJSBVAaCpUCryHbLYF9ULjDBObfVObcQ+BENDKXmUlV2liHs/pkiDR6sD86yqqxcvRqGDNGyfC8aCGrVglNOgY8/DnMAa9fqwzf6lv3RR/C3v4UduKI5AS++VZDfbtxYH8LHHRceu/xyfUiD5jD23DOsN4gXHwh8HceCBdCkSdj01PvqKz2nXTv9Hs83Dz3nHM0F+ECwebP2L7jkktjrxLcyKiOpbD46DWgvIm3QAHAecEHcOePQnMBzItIULSpaUNovqlOnDqtWrbKhqHeRC+YjqFOnTrqTYioi/xYeNGHebRMnwoMPxu7zgWDuXH0TP/xwbUL588/6Fn/66Xp85MjwM74n/qGH6jJRIIjvXLp8OdSuHbYcGjNGi4vOPRfq1NHWRhAGl6ICQXwR9fr14XrTpvob4rVrp9/dLNIm5qKLdHv0aM0ROKfNaAsKNKDEX2fhQjjqqMRp2g0pCwTOuW0iMhh4B6gOPOuc+05EhqGVFhOCYyeJyGxgO3Cbc25V0VdNrGXLluTm5mL1B7vOz1BmTCG+5U1phlrYsEGbhg4cqB2vtm2D117TB260xy1oM801a2DdOm3tc/nl4ZvxlCm67cvG+/Yt/F2+2CWR99+H5s31Ievf4hs3Dlv9ZGdr8YvXqVPsby1uoqbjj9eRDHyQ8uIf4Icfrv0bfO/kxo3DY/36xTaFFYF99tEWRk2b6rrXuXN4X8pYSjuUOecmAhPj9g2NrDvg5uBvl9WsWdNm1jImVbZs0eW6dSWf++WX+vC97Tbdnj9fA8GIEXDTTVr+Hl+8kZ2tgeDdd/VN2L+dgw7+tn27lvV//nnYsaskBx+s5fUbNmixy7PP6oP7gw9iH8TxOnaM3e7ZU793+nQdhC6qefMwcEQ1bQpdu2qv48GDtT7gs8/Ch3r0+6N9GrxoIIjm0sePh/32K/5376J0VxYbYyo6HwiKGinzb3/T8nrntJjGBwGArCxtIeM7jP3yiwaCXr3Ccxo10kDgh1s49NCwSObTT+GQQ7QFz4ABei6EZfn16ydOU8+e4frxx+vSl9sX9Rl/bMgQDWagb+g9esQW53gNGoTpiWrYEGrW1FEO9tsvHIm0eXNdNmkSnptoHCEfKKLnJdouQxYIjDHwzjswebIWA/nWOJs26bovGooPBEuW6KiZt92mzTGjFbl77w1HHKHX7dtXh04AzVUsXKhFLp98op2ufCBYuFAfuHvsEfvg9Q9y0GDx2mthOfk558SmKbp/yhQttjn1VN3ncxOffVb8vXjggdhKZIgdssJr2DA2qNSsGf7GqP794aWXNMBAbI7AfybK5wLiH/wpbP5tgcCYimbmzJIfVmWtTx/4zW+0zLp5c327P/NMXffDIUQDweTJ2uvXP3jXro0t8mnWLHGv4HnzNIC0aaO5ggMO0O9YvlyLQ3wRb+3a4Weio5BmZ+sD/Q9/0P133hlbgXzTTZrrOO44DSDjx4dv7X37amAIhoMvlUSBoEEDbeHk+xD4tK9eHXueiPZM9m//JT3Q/W/3TVIPPliX1VL3uLZAYExFc8ghsUUnxXnrLbjjjt37vmglsB+aYcOGsH2+f8Dn5+vxggL4059ir+Fc2KELtHw7UYubUaO0zD869HPbtpr7+OSTxJWzvhgoKidHm2S2batNLH17fD8+UCIiGhgi834kLVEg8EU9Pldw9NG6vOmm4q9VUusrfz3fdPZ//4sduiIFLBAYU5n17Qt//nNYjl+Ur7/WN9WxY+H222PfWhO1TU/UAu+bb7QX7ksvxY6jc/nlWpwTbRKanR0+KE8+OfY6tWrBiSeG274CdPPmxIHAt7Ypju/A1a5dyefuikRv8b6VXb16utxnH314n3ba7n3XvffqyKq+53O9eoX7JZSxqjcMtTFVRUFB8pOSLFxYuMULaHl6tBy9TRs99+eftSL3yScTT9no6wmi/EidCxfGloN3767FFtFx+Rs1Csu6991Xi5ImTYKHHtLA4B+eEPvw7tAhXD/mGK1kTuYe/Oc/OslMqiZx8W/p1aqFo6L6JqK+aKis+uE0aaL/XcqR5QiMqaieeUbLuf20iaDNMP/0J22GGe0NPneuLidNih1a2VdQev7t/9VX4ZVXtFhoyhTd9/HHYbHF7Nmxn+vaNcwlzJ8fmwNp3x5ujmsBXq1a+IBs0QJOOAH+8het7B0zJvbcaF3CKaeE6++9V/RUkvGaNUvtJPH16+v133gj3OdzBL4svzSBwN+bCsJyBMZUJNFBxe67T9/Mjz5a34y3b4frrtNjxx+v5eOen8DEP0h9kEg0adEf/6jXXr1aO301aqTFOL1763XatdM5fQEuvRQuvliLfXyA8UGiZk0NSPvtp2X2V18NTz0Vfv/ll+t3+CBRrVrsG7/nW87UqBFbvl+zZuJWNekgEk5s42Vl6dKnsTSBYOXKoudbSAMLBMZUJH40TtAg0LOnPoAffFArkb2VK2ODxvffxz70X39dcwl+SsSoK67QQABarHPVVeExP6ij7617882aG3jiifAc397/iSf08zk5uv3kk9qS5/e/14d+7drwf/+X3O9esCC2uKgy8L2TdyUQJKp8TiMLBMaUpfx8rVgcNQqCOawBHR6gfXvtiTpsWGzRwObNWtzSuXM45o530UXauemtt2KP/fprWOF7wAE6Xk60tUpkjuudXnhBizOiwxTEV67Wq6cPcF8Z7Fv+RCtL/eicTZoUnlt44EBt+vrHPxb+/uJU5pEBfCAoh0nmU8XqCEzVtmJFyS1qytLkybr0RSSgb+pz5ujD+sEHtZx5zBh9iG7YoM0/DzhAmwj6h33dutrD9rTTtEPUkiX6mXPP1eMrV2qb/Bo1tAPUL7+UXMHYqlXhjlLxgUBEi2cKCrS+wHdqirby8RK91darpwGnqCacVcG0abH1MLuSI6hgLBCYqmvHDi37vvTS8vtO3w7fd4Jaty62qSVoe/vzztMmnTNnajtx0DdpHwjefVfHt9l3X+3Y5V16qTbVfOMNrfBt0wZOOkmPJZrsJMqXafs0HH54WOEZ5R/i2dlhJ6ZoGrwKVrxRbrp3j+3b4ANBtBNcJWOBwFRdfmhgP7RwefBj7BcUaDFRgwaFR6d87bVw/aijwvL4Tz4JA0F0DJtGjXTcmq5dtfVNdrZW5s6bpxW1tWvrkA5+TlwvviNWNBCceaaO45Ooc5PPJfh+AKBFWbm5OmSEl6mBIF5FqdDeDRYITNVV1CBpu+Orr7T45JNPwn3btum+++8P29/7MXUgdlapevW0cvWiiwpf+4MPEgcC0JEsv/5aHzrRsmhf7BU/PHGNGjriZlQ0EBSnffvEaWjRIja4FDd4WybxzUdLM0x3BWOBwFRNW7YUnpSkNB55RItNrrlG2/H73IV/m4/OI+vnzr3rrrCtfX4+LI1MyOfL9jt21Dd5Py+uJ6IP+hEj9O27uJEmo529fC/W+EDQoIGOehl9OCX7Bu+beCZqcdS8efjgsxyB8vejrKfyLEcWCEzVdNBBhbv6z56trXbie83m5WlTyNWrtWI3L09H1NywQStgc3K0OOa448KHe/RtOHo936QzP1+LUvz3+uEXzjhDi2PiZ9Lr319zC99+q+3xiytv9q2FZswI+xX4t30fQPzno0U/yQ5a5nME0aasXvXqmjOoVi3xWPqZaNgwHQYjviK+ErFAYKoG53S6vy1btPhmzpzC5wwdqu3t/dy7zun5f/87XHutPkTPPFPrFLZt0zF1vE2bdE7Z0aN12+cCIPFwDFOn6gO9WjUtx993X52ZK9quPjo+/R13aP3CXXfBPfcU/1v9kBDduoUPdx+A/Dj8u1Nx6cf+OeKIxMdbttTcgE0Lqw48UP+9JZqboJKwQGCqhvfeg/PP12GJ/Zt4PD9Foi9jv/tufWBGi08mTdLioCZNdGjm+KEAfKetX34J98UHgmhLnB07wsrEffeNfSv/5hutR/j1V22J0rmzdvQqbgYt0BE0f/gh9m3/3nu185ef7DwaCPr1i+2FXJLsbE3biBGJj7dtq6OLmirDAoFJn40bwzFyirNkSeEx3r2RI/XN1BfZvPde4knM778/DARLl+pnfO/av/419tzsbG2KWb26PnBvuKHw9V54QZtvQuFAkOx0gtnZYa/c0mjYsPBQDfvsowO6+Qd0NBC88UbhFkUl6dKl6HbxDzwQO+S0qfQsEJj0ufhifaCV1OGrdevEk5wAXHaZLn0rnrlzC/fOBS1y8TNozZwZe2zTJs3WFxTA88/rw98XseTkaM7hpJN0lq2pU8MJ1H0FcHGBoEeP4n9bWfMP71S2aW/RInayGFPp2RATJn38qJfLlhVu9RJvw4bC+6Kjb06bpsuCAu3BWxyfM4hq1kwfogMHFj7WqFFs+/nomD7du2ul7d57h81E/W+55BJ4/PHi05IqVblnrylzliMw6eNbuhRVpg+xD/v4fgHRdvJffaVvqllZYWVwVLVqGiAaNw5H6owqqVw+KlpM5TuDLVsGX36pFc8+h9O6dfm3rDn8cK1sfuaZ8v1eU6lZIDDpU1QguOGGsEVKtC37McfEFiPdfnvsiJwdOoTDLeyzT+w1hw/X5qRZWbHt+73StIl/5pmweAh0DJ8LLtC5Za+/PqyjSLYDV1mqVk2LsqK9go0pgQUCkz7+QRl9MC9cCI8+quubNoVv3KAdxD7/XFvIzJ2rZf7nnBOOjNmyZVj5Gh0tc+zYcJ7aopr4laYz0EEHhROUXHmlpjna1NS3J/dz2BpTwVkgMOWvoEB76voembfcom/zc+bENnO8557wYeonaH/pJd3vK3Nbtw6LjA48MCyf37w5vM6AAWGzzfi3dL+/tCOU1qihHa6efLJwB7H+/fVYdIJ2YyowCwSm/J18svbMjc57O3euttiJGjcuXD/6aNhzz7DS1rcMatUqrEcYODAMBIl6xULhHIGfFDwaOJLVoEHiQdv8MWMqCWs1ZMrfRx/p0k+HeMghOs7Of/4Te160crhRIx2z33/Ga90a3nxTJ2Nv1iwMBPn5ui9a2QyFH9A5OTqWUNeuu/WTjKnMLBCY8tG/v05H+NVX2kLHt7y5+GLNCXTtCt99F/uZ6Ft9VpYW/cQHgn32ie1j4APB1q3apDPeAQfEbnfpokVN5d3e35gKxIqGTNlxTt/CQTtZjRgRvpGPG6dv/Vu2xDa/rFdPy9ejwxufcIIuN24M92VlwbHHFv7OGnHvMvXrw4UXwsSJidN4001aDHTqqbpdt65e1wZQMxnMAoEpO/ffr235lyyByy/XkTGjU/oBLF8eu73nnrqMjtw4eXLht/mGDWPP+eKLwkVJ3ksvwW9/m/iYiI4f5McbqsTzzBpTVqxoyJSdkSN1uWZNWJkbP+6P730rormFevV0+8or9QHuW9q0aBE7oUudOloMdMABWsx02GG7l1ZfyWuBwBgLBKYMDByoRTG+89fWrWFRi5+oxVu8WJf77acthXwgqF49rEQGLfefPr3wd8XP/7urfHNPCwTGWNGQKQMvvqidu3yZ/saN4QN2xozYcYJ++EGXfl7cosrmfcewAQMKt/wpSxYIjLEcgdkNmzaFk6REbdwYVuI+8ICOweN99pnWC7Rpo9tFdeSKtv5JBcsRGLOT5QjMrps9u3BzTtAiomhnsejInRMnaq9gP9VjolFFoeSOYWUlvtWRMRnIAoFJzqpV2hIovjdwIhs3xlYS77VX7PHevXXuYEjc1h/CQeNSFQh8jiCVxU7GVBIpDQQi0kdEfhCReSIyJMHxS0VkpYjMCv6uTGV6zG74y1/guefgn/8M9/nhnF9/PfbcjRtjH+DxM1316qVj9U+aBJdemvj7fB1CovkBjDFlKmX5YhGpDjwG/AbIBaaJyATn3Oy4U8c45wanKh2mjPgilPXrw31z5+pYPdE5eiHMERxzjLb8iTYDBZ10XUTnBC5K48ba8cvP92uMSZlU5gh6APOccwucc1uA0cAZKfw+k0q+UrWgQIeJOO44rR9o377wQG4+R3D44fqwjx/QLX6ugKLUqhU7qmdZ8nUU8ZPTG5OBUllT1gJYEtnOBXomOG+AiBwN/Ajc5JxbEn+CiAwCBgG0LmruWpNa27bpcv16OPRQ2L5dt484ovDsXqtXa2ugrKzwgRuVqod7afz5zzp5fP/+6U6JMWmX7sri/wA5zrkDgfeA5xOd5Jx72jnX3TnXPTs7u1wTaAK+zH/EiDAIgFYERyeBqVsXfvpJ1xs2LBwImjZNbTqTlZUF991nrYaMIbWBYCnQKrLdMti3k3NulXPOlxv8Czg0hekxuyPaCig60fxee8WOyb/HHjBmjK536BAbCF58UQeeM8ZUKKkMBNOA9iLSRkRqAecBE6IniEi07eDpwJwUpsfsiu3btelotBXQ3XeH69GmoW3bhnUJZ52lo4hGA8FppxXdXNQYkzYpCwTOuW3AYOAd9AH/qnPuOxEZJiKnB6ddLyLfichXwPXApalKjynB55/r0Mwffxzu27JF2/u3aBE7dPSZZ4brPhCsWKGVyJs26faRR+rSjyUENmuXMRVUSgtInXMTgYlx+4ZG1u8A7khlGkySJkzQXr8LFujcwQBTpoSdxubPh6OOgqefjq0TaN5cl77uxo866lsG+RxBgwYVo5LYGFNIuiuLTUWxNKi+mTcvHN8n2nM4N1dHBN1//9jPxfca9hXJLVro0geCilJJbIwpxAKBUbm5uty2TXMF69bBzJmx50RzAl6i5qEQ5gh80ZAFAmMqLGs7l8kKCsLK3dxcbQ20eLEWDZ16qhYH1a8fji+UlRV+dvZsnRugqOIeXyns6wwsEBhTYVmOIFPNn69NPV94QQdey80N5wqeM0ePQ2zRT7TFT6dOcPbZRV+/dm1dHnKILm+9tezSbowpU5YjyFT+Qf/883DGGTocdOfO2gR02rTwvHbtwrqCRHMPxJs0KZx8BnQcIhvh05gKzXIEmcqPCLp2rU42D1rB27s3jB+v26efHs5DDDpfcEn69IEbbijLlBpjUsxyBJnKzy+8Zg18/72ud+yogeGll3T7ssu0eejQofpWX83eG4ypiiwQZCofCNau1UrfatW0aWh0DuFWwQgh995b7skzxpQfe8XLVH6ieR8I9ttPWxB17BieYyO9GpMRLEeQqXwgcE4DQZcu4bGpU3WAOGvyaUxGsECQqXwgAG3lc+qp4fYRR+ifMSYjWNFQpooGAogdHM4Yk1EsEGSq+ECw557pSYcxJu0sEGQqCwTGmIDVEWSSZ56B6dN1KIloRzGwoiFjMpgFgkzhHFx5pa4/+WTh45YjMCZjWdFQpvATyhfFAoExGcsCQab49tvij1sgMCZjWSCoipYuhV9/jd3nA0G7dok/Y4HAmIxVYiAQkdNExAJGZeCcBoGWLXWSmb/9TWccA51trFUraNQo8WetstiYjJXMA/5cYK6I/EVE9i/xbJM+kyZpEABtHnrbbTB6tAaIDz6Ao4+Ghx6CWrUKf9ZyBMZkrBJbDTnnLhKRBsD5wEgRccBzwCjn3LpUJ9CUgh9OOmrmTFi0CFasgOOP12CQlxdOUelZIDAmYyXVfNQ5ly8iY4G6wI1Af+A2EXnUOfePFKbPlMbq1YX3PfywLmvWhJNO0nU/KU2DBpCfr+sWCIzJWMnUEZwuIm8AHwI1gR7Oud8C3YBbUps8U6zvv4euXeG553Q7N1dnGRs3Ljzn4IPhnns0SPhiI4BPPoltSZSouMgYkxGSyREMAIY75/4X3emc2ygiV6QmWSYpN92kD/PBg6FvX51buFUraNNGj7doAV9+mfizvXqVXzqNMRVaMoHgHmCZ3xCRukBz59wi59yUVCXMJGH5cqheXSuGmzXTfWedBe3bQ3Y2PPpoetNnjKkUkmk19BqwI7K9Pdhn0i0/Hzp1Kryvbl2tHD7zzPSkyxhTqSSTI6jhnNviN5xzW0TECpQrgvx86Nw5tqy/b9/SXWPMGPj557JNlzGmUkkmEKwUkdOdcxMAROQM4NcSPmPKQ36+dhzzbrlF6wtK45xzyjZNxphKJ5lA8DvgZREZAQiwBBiY0lSZkm3eDFu2wF57hftatACR9KXJGFMpJdOhbD5wuIjUC7bXpzxVpmTrgr58DRuG+xo3Tk9ajDGVWlIdykTkVOAAoI4Eb5zOuWEpTJcpie8I1qBBuM8CgTFmFyTToexJdLyh69CiobOBfYv9kEmNLVtgyRJdt0BgjCkjyTQf7e2cGwiscc7dC/QCOqQ2WSahm2+G1q01CCQKBE2apCddxphKLZlAsClYbhSRfYCtwN6pS5JJ6IYb4LHHdP3HH2HNGl23HIExZjclEwj+IyJZwF+BL4FFwCspTJOJ51xsL+FXXoF+/XQ9GgiKmmvAGGOKUWwgCCakmeKcW+uc+zdaN7C/c25oMhcXkT4i8oOIzBORIcWcN0BEnIh0L1Xqq7qtW+HOOwt3+Bo+PFxv0AA++kj7ENSsWb7pM8ZUCcW2GnLO7RCRx4CDg+3NwOZkLiwi1YHHgN8AucA0EZngnJsdd1594Abg89Inv4r78EN44AEdKbQo9evDkUfqnzHG7IJkioamBG/spe2p1AOY55xbEAxRMRo4I8F59wEPEtZFGK92bV0WFQh697Z5BIwxuy2ZQHA1OsjcZhHJF5F1IpKfxOdaoL2Qvdxg304icgjQyjn3VnEXEpFBIjJdRKavXLkyia+uIjZs0OXWreG+gQMhJweefho+/th6EhtjdlsyPYvrp+KLg/qHh4FLk0jD08DTAN27d3epSE+FtD5BJ+4GDWDhwvJPizGmyioxEIjI0Yn2x09Uk8BSoFVku2Wwz6sPdAE+DEqd9gImBAPcTS8pXRkhUSBo2rT802GMqdKSGWLitsh6HbTsfwZwfAmfmwa0F5E2aAA4D7jAH3TO5QE7n2oi8iFwa8YHgQkTdIax7dth/PjYYzfeCLffnpZkGWOqrmSKhk6LbotIK+CRJD63TUQGA+8A1YFnnXPficgwYLof1tpE5OXBGWdoub9LUAL2hz+EE88bY0wZSWrQuTi5QKcSzwKccxOBiXH7EvZBcM4duwtpqVr8pPOJggBoU1FjjCljydQR/APwT6ZqwEFoD2NT1t57r/C+aO7AmooaY1IgmRxBtMx+GzDKOfdxitKTeZ56CkaN0s5jS5dCr17af+DDD/V49eqwbZuuW1NRY0wKJBMIxgKbnHPbQXsMi8gezrmNqU1ahvjd73S5dCksWwZdu8Krr8KIEXD99WEQMMaYFEmqZzFQN7JdF5icmuRkoJYtdXnjjdo/YO+99c2/Y8e0JssYkzmSyRHUiU5P6ZxbLyJ7pDBNmaVNG8jNhbFjdXuffXQZHVJ67FhYtar802aMyQjJBIINInKIc+5LABE5FChIbbIyyPr1OqGMf9DvHUz1EJ1kZsCA8k+XMSZjJBMIbgReE5Gf0akq90KnrjRlIS8PTj4Z3nlHg0GiQGCMMSmUTIeyaSKyP+ALrX9wzm0t7jOmFPLzoWFD6NxZ5xXwk8tYnwFjTDlJZvL63wN7Oue+dc59C9QTkWtTn7QMkZ+vA8m9/LJWGB98sO73TUWvuSZtSTPGZIZkioaucs495jecc2tE5Crg8dQlK0Ns3gxbtmggaNUqduYxKLqHsTHGlKFkmo9Wj05KE8w8Vit1SarCtm6FDh3gjTd0Oz+Y1iE677AxxpSzZALB28AYETlBRE4ARgGTUpusKmr5cpg7Fy67TLfz8nTZsGH60mSMyXjJFA3dDgwCgi6wfI22HDKltXq1Ln1OwHIExpgKoMQcgXNuBzqx/CJ0LoLjgTmpTVYV5QOBc7BgAfz4o25bIDDGpFGROQIR6QCcH/z9CowBcM4dVz5Jq4KivYPbtQvXLRAYY9KouKKh74GPgL7OuXkAInJTuaSqqipqmAjfd8AYY9KguKKhM4FlwAci8s+gotjGQd4dRQWCZs3KNx3GGBNRZCBwzo1zzp0H7A98gA410UxEnhCRk8opfVXLqlVQq5b2IPYdxerWtQlnjDFplUxl8Qbn3CvB3MUtgZloSyJTGk8+CQ8/DE2bwpFHQna27m/SxCacMcakVTL9CHZyzq1xzj3tnDshVQmqsu6+W5c//6zLpk11WbNmetJjjDGBUgUCsxt6947d9oGgevXyT4sxxkRYICgvW7bo8q23dOmLhqrZfwJjTHrZU6i8rF0LJ5wAp5yi236+AasfMMakmQWC8pKXFzumkO9ElpOTluQYY4yXzFhDZnfcfbcOKbF2LWRlhfvbtYORI+HUU9OUMGOMURYIUm3YMF2KFB5l9JJLyj89xhgTx4qGUmlrZEZP52JzBMYYU0FYIEiVr7/WXsRRNu+AMaYCskCQKg8/XHif5QiMMRWQBYKytnIlvPkmTJkS7mvTRpf166cnTcYYUwwLBGXtqafgtNMgN1ebiDZrBscco8c2bEhv2owxJgFrNVTWVq4M1+++G26+WfeJQP/+6UuXMcYUwQJBWfPTUQLssYcus7Ph2WfTkx5jjCmBFQ2VtUSBwBhjKjALBGUtOguZTThjjKkEUhoIRKSPiPwgIvNEZEiC478TkW9EZJaITBWRzqlMT7mwHIExppJJWSAQkerAY8Bvgc7A+Qke9K8457o65w4C/gIkaHxfyVggMMZUMqnMEfQA5jnnFjjntgCjgTOiJzjn8iObewIuhelJvR07YM2acNsCgTGmEkhlq6EWwJLIdi7QM/4kEfk9cDNQCzg+0YVEZBAwCKB169ZlntAyk5+vwcCzQGCMqQTSXlnsnHvMOdcOuB24q4hznnbOdXfOdc/2M3ul0333wcSJhfdHK4rBAoExplJIZY5gKdAqst0y2FeU0cATKUxP2Rk6VJcuriQrWj8A1mrIGFMppDJHMA1oLyJtRKQWcB4wIXqCiLSPbJ4KzE1hespGtOgnXnwgsByBMaYSSFmOwDm3TUQGA+8A1YFnnXPficgwYLpzbgIwWEROBLYCa4CKP1NLXl7Rx+IDQd26qU2LMcaUgZQOMeGcmwhMjNs3NLJ+Qyq/PyWirYJ27IB16+DCC2HIkMKBoHr18k2bMcbsgrRXFlc60UCwYgXMmAFvvQVHHaUjjhpjTCVjgaC01q4N13NzYUmkhexnn9mcA8aYSscCQWlFcwRLlhQOBE2alH+ajDFmN1ggKMnYsdpRzIsGggULNBD41kGbNkHjxuWbPmOM2U0WCIozdy6cfTZcfnm4zweCOnXgxx/hp5+gUydo0UL3WyAwxlQyNjFNcfzUknPmhPvWrIEaNeCgg+DDDzUY9Oun01IuXaqBYOFC2L49DQk2xpjSsxxBcXyR0LZt4b61ayErCzp00CAAmiO44AJd//FHyMmBdu3KMaHGGLPrLEdQHF8MtHUrvPuuFv+sWQONGoX1AkOGwL336vqYMTBoUHrSaowxu8gCQXF8U9GtW+Hkk3X9pJM0EAwZooFhyBAtKgJ47720JNMYY3aHBYLi+BxBQUHsvsaNYd994a6Eg6UaY0ylYnUExfE5gujw0kuXah2BMcZUERYIihPtM+D9/LMWDRljTBVhgaAoBQWxw0lEWSAwxlQhFggSefNNbRX0v/8lPm6BwBhThVggSGTUKF0uWgSHH174uNURGGOqEAsEiSxcGK7vsw/06KHrvu+A5QiMMVWINR8F+PRTqFULDj0UNm/WOQaaNoWOHeHOO6FLF92///6wcaMFAmNMlWKBAKB3b106p4PIbdkCDz0EAweG59SureMJLVsGDRumJ53GGJMCVjQUJaKzjQG0alX4eK9euqxXr/zSZIwxKWaBIN6//qXL1q0LH3viCXj7bS0iMsaYKsICQbzvv9dly5aFj9WpE445ZIwxVYQFgnjbt0OzZlonYIwxGcACgXOF9yUqFjLGmCrKAsHWrYX3tW1b/ukwxpg0sUDgp6OMOumk8k+HMcakiQWCjRsL7zvllPJPhzHGpIkFgvhA8PjjsPfe6UmLMcakgQWCaCDYc0+45pr0pcUYY9IgswPB3Lmxk89Uy+zbYYzJTJk51tAvv+i8wx06xO63QGCMyUCZ9+T74gvYay8YMaLwsT59yj89xhiTZpmXI/jpJ13ee2/s/vHjrdmoMSYjZV6OYMsWXeblxe4/6CAdS8gYYzJM5gSC4cP1Qf/LL4mP+9nHjDEmw2ROIKhRQ2cZW7Ik8XELBMaYDJU5gaB+fV3m5iY+Xrdu+aXFGGMqkJQGAhHpIyI/iMg8ERmS4PjNIjJbRL4WkSkism/KEuNnFVuyRIeZ9qZNg/vu09nJjDEmA6UsEIhIdeAx4LdAZ+B8Eekcd9pMoLtz7kBgLPCXVKUnJkfQpEm4v3t3uOuulH2tMcZUdKnMEfQA5jnnFjjntgCjgTOiJzjnPnDO+TEePgMSTAtWRnyOIDcXsrK0P8Hnn6fs64wxprJIZT+CFkC0ZjYX6FnM+VcAkxIdEJFBwCCA1rs6aYzPEYAGgsMO27XrGGNMFVMhKotF5CKgO/DXRMedc08757o757pnZ2fv2pf4HAFoIDDGGAOkNkewFGgV2W4Z7IshIicC/wcc45zbnLLUxOcIjDHGAKnNEUwD2otIGxGpBZwHTIieICIHA08BpzvnVqQwLbE5gkaNUvpVxhhTmaQsEDjntgGDgXeAOcCrzrnvRGSYiJwenPZXoB7wmojMEpEJRVxu90WHj2iZujppY4ypbFI66JxzbiIwMW7f0Mj6ian8/hjRfgK7WuFsjDFVUIWoLC53rVqVfI4xxmQICwTGGJPhMjMQWKshY4zZKTMDgY0rZIwxO2XWDGVvvgkbNqQ7FcYYU6FkViA49dR0p8AYYyqczCwaMsYYs5MFAmOMyXAWCIwxJsNZIDDGmAxngcAYYzKcBQJjjMlwFgiMMSbDWSAwxpgMJ865dKehVERkJbB4Fz/eFPi1DJNTldm9So7dp+TYfUpOKu/Tvs65hHP9VrpAsDtEZLpzrnu601EZ2L1Kjt2n5Nh9Sk667pMVDRljTIazQGCMMRku0wLB0+lOQCVi9yo5dp+SY/cpOWm5TxlVR2CMMaawTMsRGGOMiWOBwBhjMlzGBAIR6SMiP4jIPBEZku70pJOIPCsiK0Tk28i+xiLynojMDZaNgv0iIo8G9+1rETkkfSkvXyLSSkQ+EJHZIvKdiNwQ7Ld7FSEidUTkCxH5KrhP9wb724jI58H9GCMitYL9tYPtecHxnLT+gHImItVFZKaIvBlsp/0+ZUQgEJHqwGPAb4HOwPki0jm9qUqrkUCfuH1DgCnOufbAlGAb9J61D/4GAU+UUxorgm3ALc65zsDhwO+Dfzd2r2JtBo53znUDDgL6iMjhwIPAcOfcfsAa4Irg/CuANcH+4cF5meQGYE5kO/33yTlX5f+AXsA7ke07gDvSna4035Mc4NvI9g/A3sH63sAPwfpTwPmJzsu0P2A88Bu7V8Xeoz2AL4GeaA/ZGsH+nf8PAu8AvYL1GsF5ku60l9P9aYm+PBwPvAlIRbhPGZEjAFoASyLbucE+E2runFsWrC8Hmgfrdu+AIFt+MPA5dq8KCYo7ZgErgPeA+cBa59y24JTovdh5n4LjeUCTck1w+jwC/AHYEWw3oQLcp0wJBKYUnL6CWLvigIjUA/4N3Oicy48es3ulnHPbnXMHoW+8PYD905uiikdE+gIrnHMz0p2WeJkSCJYCrSLbLYN9JvSLiOwNECxXBPsz+t6JSE00CLzsnHs92G33qgjOubXAB2gRR5aI1AgORe/FzvsUHG8IrCrflKbFEcDpIrIIGI0WD/2dCnCfMiUQTAPaB7XztYDzgAlpTlNFMwG4JFi/BC0P9/sHBi1iDgfyIsUiVZqICPAMMMc593DkkN2rCBHJFpGsYL0uWo8yBw0IZwWnxd8nf//OAt4PclZVmnPuDudcS+dcDvoMet85dyEV4T6lu/KkHCtpTgF+RMsu/y/d6UnzvRgFLAO2omWSV6Blj1OAucBkoHFwrqAtruYD3wDd053+crxPR6LFPl8Ds4K/U+xeFbpPBwIzg/v0LTA02N8W+AKYB7wG1A721wm25wXH26b7N6Thnh0LvFlR7pMNMWGMMRkuU4qGjDHGFMECgTHGZDgLBMYYk+EsEBhjTIazQGCMMRnOAoGpsETEichDke1bReSeMrr2SBE5q+Qzd/t7zhaROSLyQdz+HBEpEJFZkb+BZfi9x/rRLY0pSY2STzEmbTYDZ4rIA865X9OdGE9EarhwbJiSXAFc5ZybmuDYfKfDMhiTVpYjMBXZNnQO15viD8S/0YvI+mB5rIj8V0TGi8gCEfmziFwYjJf/jYi0i1zmRBGZLiI/BuPA+MHT/ioi04I5Ba6OXPcjEZkAzE6QnvOD638rIg8G+4aindKeEZG/JvujRWS9iAwPxvafIiLZwf6DROSzIF1vSDgPwn4iMjmYD+DLyG+sJyJjReR7EXk56ClNcE9mB9f5W7LpMlVYunvY2Z/9FfUHrAcaAIvQcVZuBe4Jjo0EzoqeGyyPBdaiw0PXRsdruTc4dgPwSOTzb6MvQ+3RHtZ10HkE7grOqQ1MB9oE190AtEmQzn2An4BsNJf9PtAvOPYhCXoYo8OAFxD2WJ4FHBUcc8CFwfpQYESw/jVwTLA+LPJbPgf6B+t10KGgj0VHq2wZ/MZP0aDUBB0e23cmzUr3f2f7S/+f5QhMheZ0tM8XgOtL8bFpzrllzrnN6HAP7wb7v0EfwN6rzrkdzrm5wAJ0xMyT0PGCZqEP2CZooAD4wjm3MMH3HQZ86Jxb6bTI6GXg6CTSOd85d1Dk76Ng/w5gTLD+EnCkiDREH9r/DfY/DxwtIvWBFs65NwCcc5uccxsj6c11zu1AA00OGhw2obmUMwF/rslgFghMZfAIWta+Z2TfNoJ/vyJSDagVObY5sr4jsr2D2Hqx+PFVHDpe0HWRh3Mb55wPJBt250fshl0dByZ6H7ajk59sQ4eJHgv0RXNFJsNZIDAVnnNuNfAq4RR+oMVFhwbrpwM1d+HSZ4tItaBMvS1aZPIOcE0w/DQi0kFE9izuIuiAYMeISNNgWtTzgf+W8JniVCMcjfICYKpzLg9YIyJHBfsvBv7rnFsH5IpIvyC9tUVkj6IuHMyt0NA5NxGte+m2G+k0VYS1GjKVxUPA4Mj2P4HxIvIV+la7K2/rP6EP8QbA75xzm0TkX2gRypdB5epKoF9xF3HOLRORIehwwgK85ZwbX9xnAu2CIijvWefco+hv6SEid6FzHZwbHL8EeDJ40C8ALgv2Xww8JSLD0BFlzy7mO+uj961OkNabk0inqeJs9FFjKhgRWe+cq5fudJjMYUVDxhiT4SxHYIwxGc5yBMYYk+EsEBhjTIazQGCMMRnOAoExxmQ4CwTGGJPh/j8EQCdBjvOMzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on validation set: 16.983%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "#model.save('8_features_train_test_16.983')\n",
    "#test 60.691  val 16.983\n",
    "#model = load_model('8_features_train_test') #val 19%!\n",
    "\n",
    "model_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(\"Accuracy of the model on test set: {:.3f}%\".format(model_acc * 100))\n",
    "\n",
    "\n",
    "\n",
    "# Plot the accuracy curve for training\n",
    "plt.plot(history.history['val_accuracy'], color='r', label=\"Accuracy\")\n",
    "\n",
    "plt.title(\"Validation accuracy\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "model_acc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "print(\"Accuracy of the model on validation set: {:.3f}%\".format(model_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f2f7d63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 9)]               0         \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (None, 9, 1)             0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 9, 256)            198912    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 16135     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 215,047\n",
      "Trainable params: 215,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "38/38 [==============================] - 4s 47ms/step - loss: 1.9661 - accuracy: 0.1556 - val_loss: 1.9222 - val_accuracy: 0.1762\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.9319 - accuracy: 0.1835 - val_loss: 1.9217 - val_accuracy: 0.1820\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.9220 - accuracy: 0.1811 - val_loss: 1.9028 - val_accuracy: 0.2107\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.9161 - accuracy: 0.1942 - val_loss: 1.9073 - val_accuracy: 0.2165\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.9197 - accuracy: 0.1778 - val_loss: 1.9098 - val_accuracy: 0.2241\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.9153 - accuracy: 0.2074 - val_loss: 1.8978 - val_accuracy: 0.1935\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.9063 - accuracy: 0.1959 - val_loss: 1.8900 - val_accuracy: 0.2414\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.9046 - accuracy: 0.2008 - val_loss: 1.8857 - val_accuracy: 0.2280\n",
      "Epoch 9/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8964 - accuracy: 0.2115 - val_loss: 1.8606 - val_accuracy: 0.2682\n",
      "Epoch 10/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8970 - accuracy: 0.2049 - val_loss: 1.8765 - val_accuracy: 0.2222\n",
      "Epoch 11/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8959 - accuracy: 0.2025 - val_loss: 1.8642 - val_accuracy: 0.2759\n",
      "Epoch 12/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.8876 - accuracy: 0.2354 - val_loss: 1.8639 - val_accuracy: 0.2395\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.8827 - accuracy: 0.2280 - val_loss: 1.8542 - val_accuracy: 0.2510\n",
      "Epoch 14/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8719 - accuracy: 0.2255 - val_loss: 1.8634 - val_accuracy: 0.2490\n",
      "Epoch 15/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8747 - accuracy: 0.2337 - val_loss: 1.8859 - val_accuracy: 0.2126\n",
      "Epoch 16/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8710 - accuracy: 0.2494 - val_loss: 1.8212 - val_accuracy: 0.2682\n",
      "Epoch 17/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8537 - accuracy: 0.2502 - val_loss: 1.8272 - val_accuracy: 0.2414\n",
      "Epoch 18/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.8570 - accuracy: 0.2519 - val_loss: 1.8242 - val_accuracy: 0.2625\n",
      "Epoch 19/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8554 - accuracy: 0.2510 - val_loss: 1.8168 - val_accuracy: 0.3161\n",
      "Epoch 20/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8521 - accuracy: 0.2494 - val_loss: 1.8458 - val_accuracy: 0.2816\n",
      "Epoch 21/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.8397 - accuracy: 0.2486 - val_loss: 1.8150 - val_accuracy: 0.2778\n",
      "Epoch 22/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8284 - accuracy: 0.2724 - val_loss: 1.8165 - val_accuracy: 0.2931\n",
      "Epoch 23/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8334 - accuracy: 0.2576 - val_loss: 1.8035 - val_accuracy: 0.2816\n",
      "Epoch 24/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8292 - accuracy: 0.2626 - val_loss: 1.8061 - val_accuracy: 0.2720\n",
      "Epoch 25/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8171 - accuracy: 0.2642 - val_loss: 1.7945 - val_accuracy: 0.3027\n",
      "Epoch 26/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8026 - accuracy: 0.2840 - val_loss: 1.7890 - val_accuracy: 0.2701\n",
      "Epoch 27/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.7913 - accuracy: 0.2955 - val_loss: 1.7922 - val_accuracy: 0.2989\n",
      "Epoch 28/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.7942 - accuracy: 0.2856 - val_loss: 1.7721 - val_accuracy: 0.2778\n",
      "Epoch 29/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7994 - accuracy: 0.2733 - val_loss: 1.8004 - val_accuracy: 0.3046\n",
      "Epoch 30/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7787 - accuracy: 0.2922 - val_loss: 1.7713 - val_accuracy: 0.2950\n",
      "Epoch 31/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7845 - accuracy: 0.2765 - val_loss: 1.7789 - val_accuracy: 0.3372\n",
      "Epoch 32/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.7715 - accuracy: 0.2914 - val_loss: 1.7928 - val_accuracy: 0.2739\n",
      "Epoch 33/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7793 - accuracy: 0.2782 - val_loss: 1.7694 - val_accuracy: 0.2931\n",
      "Epoch 34/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7575 - accuracy: 0.3111 - val_loss: 1.7505 - val_accuracy: 0.2874\n",
      "Epoch 35/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7412 - accuracy: 0.2947 - val_loss: 1.7608 - val_accuracy: 0.3142\n",
      "Epoch 36/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7309 - accuracy: 0.3062 - val_loss: 1.7236 - val_accuracy: 0.2912\n",
      "Epoch 37/1000\n",
      "38/38 [==============================] - 1s 40ms/step - loss: 1.7269 - accuracy: 0.3062 - val_loss: 1.7549 - val_accuracy: 0.2893\n",
      "Epoch 38/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.7238 - accuracy: 0.3045 - val_loss: 1.7565 - val_accuracy: 0.2893\n",
      "Epoch 39/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.7044 - accuracy: 0.3095 - val_loss: 1.7531 - val_accuracy: 0.2605\n",
      "Epoch 40/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.7036 - accuracy: 0.3226 - val_loss: 1.7157 - val_accuracy: 0.3276\n",
      "Epoch 41/1000\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 1.6841 - accuracy: 0.3144 - val_loss: 1.6986 - val_accuracy: 0.3142\n",
      "Epoch 42/1000\n",
      "38/38 [==============================] - 2s 48ms/step - loss: 1.6689 - accuracy: 0.3300 - val_loss: 1.7188 - val_accuracy: 0.3276\n",
      "Epoch 43/1000\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 1.6689 - accuracy: 0.3185 - val_loss: 1.6751 - val_accuracy: 0.3525\n",
      "Epoch 44/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.6648 - accuracy: 0.3267 - val_loss: 1.6855 - val_accuracy: 0.3257\n",
      "Epoch 45/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.6372 - accuracy: 0.3366 - val_loss: 1.6817 - val_accuracy: 0.3276\n",
      "Epoch 46/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.6425 - accuracy: 0.3267 - val_loss: 1.6552 - val_accuracy: 0.3640\n",
      "Epoch 47/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.6398 - accuracy: 0.3317 - val_loss: 1.6644 - val_accuracy: 0.3391\n",
      "Epoch 48/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.6132 - accuracy: 0.3481 - val_loss: 1.6434 - val_accuracy: 0.3716\n",
      "Epoch 49/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.5937 - accuracy: 0.3597 - val_loss: 1.6387 - val_accuracy: 0.3391\n",
      "Epoch 50/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.5942 - accuracy: 0.3457 - val_loss: 1.6051 - val_accuracy: 0.3525\n",
      "Epoch 51/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.5897 - accuracy: 0.3449 - val_loss: 1.6380 - val_accuracy: 0.3429\n",
      "Epoch 52/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.5639 - accuracy: 0.3728 - val_loss: 1.5930 - val_accuracy: 0.3544\n",
      "Epoch 53/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.5433 - accuracy: 0.3720 - val_loss: 1.6207 - val_accuracy: 0.3640\n",
      "Epoch 54/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5675 - accuracy: 0.3663 - val_loss: 1.6187 - val_accuracy: 0.3602\n",
      "Epoch 55/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5494 - accuracy: 0.3770 - val_loss: 1.5902 - val_accuracy: 0.3755\n",
      "Epoch 56/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.5262 - accuracy: 0.3712 - val_loss: 1.5532 - val_accuracy: 0.3640\n",
      "Epoch 57/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5206 - accuracy: 0.3761 - val_loss: 1.5460 - val_accuracy: 0.4023\n",
      "Epoch 58/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5175 - accuracy: 0.4016 - val_loss: 1.5668 - val_accuracy: 0.3602\n",
      "Epoch 59/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5154 - accuracy: 0.3860 - val_loss: 1.5388 - val_accuracy: 0.3774\n",
      "Epoch 60/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5000 - accuracy: 0.3893 - val_loss: 1.5381 - val_accuracy: 0.3774\n",
      "Epoch 61/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4843 - accuracy: 0.4123 - val_loss: 1.5952 - val_accuracy: 0.3238\n",
      "Epoch 62/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4773 - accuracy: 0.3959 - val_loss: 1.5598 - val_accuracy: 0.3448\n",
      "Epoch 63/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4781 - accuracy: 0.4074 - val_loss: 1.4844 - val_accuracy: 0.4272\n",
      "Epoch 64/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4428 - accuracy: 0.3992 - val_loss: 1.5117 - val_accuracy: 0.4368\n",
      "Epoch 65/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4390 - accuracy: 0.3926 - val_loss: 1.5630 - val_accuracy: 0.3927\n",
      "Epoch 66/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4525 - accuracy: 0.3951 - val_loss: 1.5329 - val_accuracy: 0.3621\n",
      "Epoch 67/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4327 - accuracy: 0.4288 - val_loss: 1.5145 - val_accuracy: 0.3870\n",
      "Epoch 68/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4532 - accuracy: 0.3934 - val_loss: 1.4805 - val_accuracy: 0.4330\n",
      "Epoch 69/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4135 - accuracy: 0.4313 - val_loss: 1.4607 - val_accuracy: 0.4253\n",
      "Epoch 70/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4071 - accuracy: 0.4214 - val_loss: 1.5036 - val_accuracy: 0.4042\n",
      "Epoch 71/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4097 - accuracy: 0.4239 - val_loss: 1.4817 - val_accuracy: 0.4119\n",
      "Epoch 72/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4084 - accuracy: 0.4091 - val_loss: 1.5304 - val_accuracy: 0.3870\n",
      "Epoch 73/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.3759 - accuracy: 0.4535 - val_loss: 1.4497 - val_accuracy: 0.4138\n",
      "Epoch 74/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3731 - accuracy: 0.4362 - val_loss: 1.4643 - val_accuracy: 0.4330\n",
      "Epoch 75/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3753 - accuracy: 0.4576 - val_loss: 1.4655 - val_accuracy: 0.4368\n",
      "Epoch 76/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3693 - accuracy: 0.4502 - val_loss: 1.4518 - val_accuracy: 0.4425\n",
      "Epoch 77/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3566 - accuracy: 0.4436 - val_loss: 1.4169 - val_accuracy: 0.4176\n",
      "Epoch 78/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.3651 - accuracy: 0.4387 - val_loss: 1.4515 - val_accuracy: 0.4004\n",
      "Epoch 79/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.3593 - accuracy: 0.4543 - val_loss: 1.4112 - val_accuracy: 0.4579\n",
      "Epoch 80/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.3385 - accuracy: 0.4543 - val_loss: 1.4286 - val_accuracy: 0.4502\n",
      "Epoch 81/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3449 - accuracy: 0.4568 - val_loss: 1.4086 - val_accuracy: 0.4272\n",
      "Epoch 82/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3381 - accuracy: 0.4601 - val_loss: 1.4298 - val_accuracy: 0.4540\n",
      "Epoch 83/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.3181 - accuracy: 0.4708 - val_loss: 1.3983 - val_accuracy: 0.4655\n",
      "Epoch 84/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.3264 - accuracy: 0.4658 - val_loss: 1.4243 - val_accuracy: 0.4004\n",
      "Epoch 85/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.3292 - accuracy: 0.4543 - val_loss: 1.4357 - val_accuracy: 0.4310\n",
      "Epoch 86/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.2780 - accuracy: 0.4872 - val_loss: 1.3853 - val_accuracy: 0.4406\n",
      "Epoch 87/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2921 - accuracy: 0.4675 - val_loss: 1.4128 - val_accuracy: 0.4272\n",
      "Epoch 88/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2789 - accuracy: 0.4765 - val_loss: 1.4092 - val_accuracy: 0.4444\n",
      "Epoch 89/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.2640 - accuracy: 0.4947 - val_loss: 1.3904 - val_accuracy: 0.4732\n",
      "Epoch 90/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2964 - accuracy: 0.4642 - val_loss: 1.4073 - val_accuracy: 0.4655\n",
      "Epoch 91/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2739 - accuracy: 0.4782 - val_loss: 1.3893 - val_accuracy: 0.4425\n",
      "Epoch 92/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.2584 - accuracy: 0.4930 - val_loss: 1.4007 - val_accuracy: 0.4444\n",
      "Epoch 93/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2714 - accuracy: 0.4848 - val_loss: 1.3558 - val_accuracy: 0.4847\n",
      "Epoch 94/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2566 - accuracy: 0.4938 - val_loss: 1.3715 - val_accuracy: 0.4713\n",
      "Epoch 95/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.2834 - accuracy: 0.4757 - val_loss: 1.3602 - val_accuracy: 0.4770\n",
      "Epoch 96/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.2656 - accuracy: 0.4864 - val_loss: 1.3667 - val_accuracy: 0.4713\n",
      "Epoch 97/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.2624 - accuracy: 0.4905 - val_loss: 1.3592 - val_accuracy: 0.4483\n",
      "Epoch 98/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.2294 - accuracy: 0.4996 - val_loss: 1.3742 - val_accuracy: 0.4464\n",
      "Epoch 99/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.2351 - accuracy: 0.4971 - val_loss: 1.3108 - val_accuracy: 0.4962\n",
      "Epoch 100/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2187 - accuracy: 0.5045 - val_loss: 1.2828 - val_accuracy: 0.5172\n",
      "Epoch 101/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.2010 - accuracy: 0.5021 - val_loss: 1.3359 - val_accuracy: 0.4483\n",
      "Epoch 102/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2150 - accuracy: 0.5029 - val_loss: 1.3436 - val_accuracy: 0.4674\n",
      "Epoch 103/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.2199 - accuracy: 0.5226 - val_loss: 1.3288 - val_accuracy: 0.4981\n",
      "Epoch 104/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.2127 - accuracy: 0.5103 - val_loss: 1.3377 - val_accuracy: 0.4866\n",
      "Epoch 105/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.1954 - accuracy: 0.5119 - val_loss: 1.3275 - val_accuracy: 0.4713\n",
      "Epoch 106/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.1776 - accuracy: 0.5226 - val_loss: 1.3134 - val_accuracy: 0.5057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2008 - accuracy: 0.5053 - val_loss: 1.3129 - val_accuracy: 0.4866\n",
      "Epoch 108/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1968 - accuracy: 0.5251 - val_loss: 1.2973 - val_accuracy: 0.4789\n",
      "Epoch 109/1000\n",
      "38/38 [==============================] - 2s 57ms/step - loss: 1.1777 - accuracy: 0.5136 - val_loss: 1.3076 - val_accuracy: 0.5077\n",
      "Epoch 110/1000\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.1519 - accuracy: 0.5284 - val_loss: 1.3027 - val_accuracy: 0.5077\n",
      "Epoch 111/1000\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 1.1545 - accuracy: 0.5333 - val_loss: 1.3478 - val_accuracy: 0.5096\n",
      "Epoch 112/1000\n",
      "38/38 [==============================] - 3s 92ms/step - loss: 1.1566 - accuracy: 0.5202 - val_loss: 1.3114 - val_accuracy: 0.4981\n",
      "Epoch 113/1000\n",
      "38/38 [==============================] - 3s 84ms/step - loss: 1.1667 - accuracy: 0.5284 - val_loss: 1.2720 - val_accuracy: 0.5268\n",
      "Epoch 114/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.1552 - accuracy: 0.5350 - val_loss: 1.2924 - val_accuracy: 0.5268\n",
      "Epoch 115/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.1688 - accuracy: 0.5202 - val_loss: 1.2600 - val_accuracy: 0.5230\n",
      "Epoch 116/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1511 - accuracy: 0.5235 - val_loss: 1.2568 - val_accuracy: 0.5249\n",
      "Epoch 117/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1509 - accuracy: 0.5465 - val_loss: 1.2540 - val_accuracy: 0.5172\n",
      "Epoch 118/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1255 - accuracy: 0.5440 - val_loss: 1.3337 - val_accuracy: 0.5038\n",
      "Epoch 119/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.1638 - accuracy: 0.5243 - val_loss: 1.2599 - val_accuracy: 0.5192\n",
      "Epoch 120/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1287 - accuracy: 0.5440 - val_loss: 1.3064 - val_accuracy: 0.4904\n",
      "Epoch 121/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.1218 - accuracy: 0.5374 - val_loss: 1.2939 - val_accuracy: 0.4904\n",
      "Epoch 122/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.1298 - accuracy: 0.5391 - val_loss: 1.3516 - val_accuracy: 0.5000\n",
      "Epoch 123/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1211 - accuracy: 0.5547 - val_loss: 1.2625 - val_accuracy: 0.5268\n",
      "Epoch 124/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0960 - accuracy: 0.5613 - val_loss: 1.3190 - val_accuracy: 0.4904\n",
      "Epoch 125/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1141 - accuracy: 0.5547 - val_loss: 1.2439 - val_accuracy: 0.5441\n",
      "Epoch 126/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1070 - accuracy: 0.5440 - val_loss: 1.2560 - val_accuracy: 0.5192\n",
      "Epoch 127/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1127 - accuracy: 0.5424 - val_loss: 1.3472 - val_accuracy: 0.4962\n",
      "Epoch 128/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1242 - accuracy: 0.5597 - val_loss: 1.2408 - val_accuracy: 0.5460\n",
      "Epoch 129/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.0925 - accuracy: 0.5646 - val_loss: 1.3133 - val_accuracy: 0.5000\n",
      "Epoch 130/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1287 - accuracy: 0.5399 - val_loss: 1.2655 - val_accuracy: 0.5077\n",
      "Epoch 131/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.1264 - accuracy: 0.5284 - val_loss: 1.2549 - val_accuracy: 0.5498\n",
      "Epoch 132/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.1118 - accuracy: 0.5490 - val_loss: 1.2450 - val_accuracy: 0.5498\n",
      "Epoch 133/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.0891 - accuracy: 0.5588 - val_loss: 1.3179 - val_accuracy: 0.5153\n",
      "Epoch 134/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0706 - accuracy: 0.5539 - val_loss: 1.2552 - val_accuracy: 0.5402\n",
      "Epoch 135/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1007 - accuracy: 0.5547 - val_loss: 1.2381 - val_accuracy: 0.5268\n",
      "Epoch 136/1000\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 1.1005 - accuracy: 0.5473 - val_loss: 1.2956 - val_accuracy: 0.4828\n",
      "Epoch 137/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.0820 - accuracy: 0.5350 - val_loss: 1.2561 - val_accuracy: 0.5287\n",
      "Epoch 138/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0846 - accuracy: 0.5317 - val_loss: 1.2588 - val_accuracy: 0.5517\n",
      "Epoch 139/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.0544 - accuracy: 0.5770 - val_loss: 1.2545 - val_accuracy: 0.5211\n",
      "Epoch 140/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.0725 - accuracy: 0.5737 - val_loss: 1.2638 - val_accuracy: 0.5134\n",
      "Epoch 141/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0633 - accuracy: 0.5580 - val_loss: 1.2467 - val_accuracy: 0.5307\n",
      "Epoch 142/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0681 - accuracy: 0.5588 - val_loss: 1.2845 - val_accuracy: 0.5211\n",
      "Epoch 143/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.0552 - accuracy: 0.5506 - val_loss: 1.2927 - val_accuracy: 0.5230\n",
      "Epoch 144/1000\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 1.0753 - accuracy: 0.5490 - val_loss: 1.2338 - val_accuracy: 0.5479\n",
      "Epoch 145/1000\n",
      "38/38 [==============================] - 2s 43ms/step - loss: 1.0703 - accuracy: 0.5564 - val_loss: 1.2353 - val_accuracy: 0.5230\n",
      "Epoch 146/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.0432 - accuracy: 0.5687 - val_loss: 1.2340 - val_accuracy: 0.5460\n",
      "Epoch 147/1000\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 1.0201 - accuracy: 0.5638 - val_loss: 1.2059 - val_accuracy: 0.5364\n",
      "Epoch 148/1000\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 1.0312 - accuracy: 0.5794 - val_loss: 1.2329 - val_accuracy: 0.5326\n",
      "Epoch 149/1000\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 1.0429 - accuracy: 0.5794 - val_loss: 1.2605 - val_accuracy: 0.5307\n",
      "Epoch 150/1000\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 1.0575 - accuracy: 0.5605 - val_loss: 1.2892 - val_accuracy: 0.5230\n",
      "Epoch 151/1000\n",
      "38/38 [==============================] - 3s 82ms/step - loss: 1.0228 - accuracy: 0.5868 - val_loss: 1.2095 - val_accuracy: 0.5517\n",
      "Epoch 152/1000\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 1.0542 - accuracy: 0.5712 - val_loss: 1.2583 - val_accuracy: 0.5211\n",
      "Epoch 153/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.0466 - accuracy: 0.5621 - val_loss: 1.2808 - val_accuracy: 0.5268\n",
      "Epoch 154/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.0291 - accuracy: 0.5753 - val_loss: 1.2825 - val_accuracy: 0.5192\n",
      "Epoch 155/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0197 - accuracy: 0.5745 - val_loss: 1.2422 - val_accuracy: 0.5402\n",
      "Epoch 156/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0166 - accuracy: 0.5663 - val_loss: 1.2389 - val_accuracy: 0.5670\n",
      "Epoch 157/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.0266 - accuracy: 0.5770 - val_loss: 1.2478 - val_accuracy: 0.5172\n",
      "Epoch 158/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0267 - accuracy: 0.5613 - val_loss: 1.2382 - val_accuracy: 0.5460\n",
      "Epoch 159/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0198 - accuracy: 0.5737 - val_loss: 1.2647 - val_accuracy: 0.5287\n",
      "Epoch 160/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0273 - accuracy: 0.5802 - val_loss: 1.2397 - val_accuracy: 0.5345\n",
      "Epoch 161/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0164 - accuracy: 0.5819 - val_loss: 1.2616 - val_accuracy: 0.5268\n",
      "Epoch 162/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9815 - accuracy: 0.5951 - val_loss: 1.2715 - val_accuracy: 0.5479\n",
      "Epoch 163/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9969 - accuracy: 0.5753 - val_loss: 1.2420 - val_accuracy: 0.5556\n",
      "Epoch 164/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0304 - accuracy: 0.5728 - val_loss: 1.2265 - val_accuracy: 0.5441\n",
      "Epoch 165/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.0132 - accuracy: 0.5844 - val_loss: 1.2195 - val_accuracy: 0.5862\n",
      "Epoch 166/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0023 - accuracy: 0.5802 - val_loss: 1.2264 - val_accuracy: 0.5536\n",
      "Epoch 167/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.0126 - accuracy: 0.5737 - val_loss: 1.2459 - val_accuracy: 0.5077\n",
      "Epoch 168/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9591 - accuracy: 0.5926 - val_loss: 1.2415 - val_accuracy: 0.5517\n",
      "Epoch 169/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9744 - accuracy: 0.5893 - val_loss: 1.2400 - val_accuracy: 0.5556\n",
      "Epoch 170/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9802 - accuracy: 0.5901 - val_loss: 1.2125 - val_accuracy: 0.5651\n",
      "Epoch 171/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9986 - accuracy: 0.5860 - val_loss: 1.2370 - val_accuracy: 0.5728\n",
      "Epoch 172/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9966 - accuracy: 0.5695 - val_loss: 1.2548 - val_accuracy: 0.5479\n",
      "Epoch 173/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.0015 - accuracy: 0.5720 - val_loss: 1.2497 - val_accuracy: 0.5556\n",
      "Epoch 174/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.9670 - accuracy: 0.5877 - val_loss: 1.2200 - val_accuracy: 0.5613\n",
      "Epoch 175/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9572 - accuracy: 0.6099 - val_loss: 1.2546 - val_accuracy: 0.5613\n",
      "Epoch 176/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9871 - accuracy: 0.5827 - val_loss: 1.2441 - val_accuracy: 0.5536\n",
      "Epoch 177/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9680 - accuracy: 0.5959 - val_loss: 1.2285 - val_accuracy: 0.5785\n",
      "Epoch 178/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9736 - accuracy: 0.6049 - val_loss: 1.2644 - val_accuracy: 0.5613\n",
      "Epoch 179/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9641 - accuracy: 0.6016 - val_loss: 1.3206 - val_accuracy: 0.5498\n",
      "Epoch 180/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9605 - accuracy: 0.6091 - val_loss: 1.2341 - val_accuracy: 0.5747\n",
      "Epoch 181/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9496 - accuracy: 0.6033 - val_loss: 1.2518 - val_accuracy: 0.5747\n",
      "Epoch 182/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.9524 - accuracy: 0.6148 - val_loss: 1.2432 - val_accuracy: 0.5441\n",
      "Epoch 183/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.9716 - accuracy: 0.5835 - val_loss: 1.2157 - val_accuracy: 0.5651\n",
      "Epoch 184/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9385 - accuracy: 0.6156 - val_loss: 1.2059 - val_accuracy: 0.5785\n",
      "Epoch 185/1000\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.9583 - accuracy: 0.6140 - val_loss: 1.1834 - val_accuracy: 0.5728\n",
      "Epoch 186/1000\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 0.9726 - accuracy: 0.5918 - val_loss: 1.1975 - val_accuracy: 0.5709\n",
      "Epoch 187/1000\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.9400 - accuracy: 0.5909 - val_loss: 1.2023 - val_accuracy: 0.5613\n",
      "Epoch 188/1000\n",
      "38/38 [==============================] - 3s 83ms/step - loss: 0.9652 - accuracy: 0.5992 - val_loss: 1.2433 - val_accuracy: 0.5632\n",
      "Epoch 189/1000\n",
      "38/38 [==============================] - 4s 93ms/step - loss: 0.9928 - accuracy: 0.5852 - val_loss: 1.2802 - val_accuracy: 0.5383\n",
      "Epoch 190/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9612 - accuracy: 0.5819 - val_loss: 1.1950 - val_accuracy: 0.5766\n",
      "Epoch 191/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9697 - accuracy: 0.5901 - val_loss: 1.2398 - val_accuracy: 0.5441\n",
      "Epoch 192/1000\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.9453 - accuracy: 0.6033 - val_loss: 1.2272 - val_accuracy: 0.5709\n",
      "Epoch 193/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9606 - accuracy: 0.6173 - val_loss: 1.2493 - val_accuracy: 0.5805\n",
      "Epoch 194/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9383 - accuracy: 0.6049 - val_loss: 1.1945 - val_accuracy: 0.5632\n",
      "Epoch 195/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.9598 - accuracy: 0.5959 - val_loss: 1.2030 - val_accuracy: 0.5843\n",
      "Epoch 196/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.9407 - accuracy: 0.6049 - val_loss: 1.2183 - val_accuracy: 0.5900\n",
      "Epoch 197/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.9099 - accuracy: 0.6165 - val_loss: 1.1710 - val_accuracy: 0.5958\n",
      "Epoch 198/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9545 - accuracy: 0.6058 - val_loss: 1.2426 - val_accuracy: 0.5498\n",
      "Epoch 199/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.9410 - accuracy: 0.5959 - val_loss: 1.2218 - val_accuracy: 0.5556\n",
      "Epoch 200/1000\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.9250 - accuracy: 0.6058 - val_loss: 1.2301 - val_accuracy: 0.5651\n",
      "Epoch 201/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9173 - accuracy: 0.6247 - val_loss: 1.2187 - val_accuracy: 0.5843\n",
      "Epoch 202/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9334 - accuracy: 0.6099 - val_loss: 1.2843 - val_accuracy: 0.5421\n",
      "Epoch 203/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9277 - accuracy: 0.6140 - val_loss: 1.2395 - val_accuracy: 0.5613\n",
      "Epoch 204/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9284 - accuracy: 0.6082 - val_loss: 1.1955 - val_accuracy: 0.5728\n",
      "Epoch 205/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.9155 - accuracy: 0.6189 - val_loss: 1.2985 - val_accuracy: 0.5383\n",
      "Epoch 206/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9458 - accuracy: 0.6058 - val_loss: 1.1895 - val_accuracy: 0.5785\n",
      "Epoch 207/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8789 - accuracy: 0.6362 - val_loss: 1.1923 - val_accuracy: 0.5900\n",
      "Epoch 208/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9195 - accuracy: 0.6132 - val_loss: 1.2108 - val_accuracy: 0.5594\n",
      "Epoch 209/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9222 - accuracy: 0.6189 - val_loss: 1.2136 - val_accuracy: 0.5747\n",
      "Epoch 210/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8959 - accuracy: 0.6255 - val_loss: 1.1964 - val_accuracy: 0.5824\n",
      "Epoch 211/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9292 - accuracy: 0.6016 - val_loss: 1.1987 - val_accuracy: 0.5575\n",
      "Epoch 212/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9126 - accuracy: 0.6025 - val_loss: 1.2278 - val_accuracy: 0.5709\n",
      "Epoch 213/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9079 - accuracy: 0.6370 - val_loss: 1.2206 - val_accuracy: 0.5747\n",
      "Epoch 214/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8949 - accuracy: 0.6091 - val_loss: 1.1984 - val_accuracy: 0.5766\n",
      "Epoch 215/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8658 - accuracy: 0.6403 - val_loss: 1.2174 - val_accuracy: 0.5805\n",
      "Epoch 216/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8831 - accuracy: 0.6239 - val_loss: 1.2579 - val_accuracy: 0.5402\n",
      "Epoch 217/1000\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.9174 - accuracy: 0.6272 - val_loss: 1.2453 - val_accuracy: 0.5824\n",
      "Epoch 218/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9270 - accuracy: 0.6041 - val_loss: 1.2090 - val_accuracy: 0.5632\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8975 - accuracy: 0.6255 - val_loss: 1.1933 - val_accuracy: 0.6054\n",
      "Epoch 220/1000\n",
      "38/38 [==============================] - 2s 47ms/step - loss: 0.8827 - accuracy: 0.6362 - val_loss: 1.2186 - val_accuracy: 0.5747\n",
      "Epoch 221/1000\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 0.8770 - accuracy: 0.6370 - val_loss: 1.2194 - val_accuracy: 0.5690\n",
      "Epoch 222/1000\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 0.8879 - accuracy: 0.6354 - val_loss: 1.2194 - val_accuracy: 0.5977\n",
      "Epoch 223/1000\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 0.8923 - accuracy: 0.6387 - val_loss: 1.2297 - val_accuracy: 0.5728\n",
      "Epoch 224/1000\n",
      "38/38 [==============================] - 3s 79ms/step - loss: 0.8979 - accuracy: 0.6272 - val_loss: 1.2010 - val_accuracy: 0.5690\n",
      "Epoch 225/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8750 - accuracy: 0.6263 - val_loss: 1.2033 - val_accuracy: 0.5958\n",
      "Epoch 226/1000\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 0.8973 - accuracy: 0.6156 - val_loss: 1.1807 - val_accuracy: 0.5881\n",
      "Epoch 227/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.8932 - accuracy: 0.6156 - val_loss: 1.2052 - val_accuracy: 0.6034\n",
      "Epoch 228/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8771 - accuracy: 0.6346 - val_loss: 1.2351 - val_accuracy: 0.5843\n",
      "Epoch 229/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9087 - accuracy: 0.6239 - val_loss: 1.1978 - val_accuracy: 0.5594\n",
      "Epoch 230/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8660 - accuracy: 0.6280 - val_loss: 1.2104 - val_accuracy: 0.5805\n",
      "Epoch 231/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8682 - accuracy: 0.6247 - val_loss: 1.1774 - val_accuracy: 0.5881\n",
      "Epoch 232/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8650 - accuracy: 0.6362 - val_loss: 1.1920 - val_accuracy: 0.6130\n",
      "Epoch 233/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9083 - accuracy: 0.6313 - val_loss: 1.2133 - val_accuracy: 0.5785\n",
      "Epoch 234/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8709 - accuracy: 0.6181 - val_loss: 1.1856 - val_accuracy: 0.5824\n",
      "Epoch 235/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9061 - accuracy: 0.6033 - val_loss: 1.2361 - val_accuracy: 0.5843\n",
      "Epoch 236/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8646 - accuracy: 0.6370 - val_loss: 1.2156 - val_accuracy: 0.5556\n",
      "Epoch 237/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8579 - accuracy: 0.6321 - val_loss: 1.1983 - val_accuracy: 0.5824\n",
      "Epoch 238/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8866 - accuracy: 0.6280 - val_loss: 1.2180 - val_accuracy: 0.5690\n",
      "Epoch 239/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8685 - accuracy: 0.6354 - val_loss: 1.2503 - val_accuracy: 0.5575\n",
      "Epoch 240/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8477 - accuracy: 0.6436 - val_loss: 1.1771 - val_accuracy: 0.6092\n",
      "Epoch 241/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8720 - accuracy: 0.6247 - val_loss: 1.2104 - val_accuracy: 0.5670\n",
      "Epoch 242/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8717 - accuracy: 0.6420 - val_loss: 1.1836 - val_accuracy: 0.6245\n",
      "Epoch 243/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8613 - accuracy: 0.6288 - val_loss: 1.2509 - val_accuracy: 0.5920\n",
      "Epoch 244/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8667 - accuracy: 0.6370 - val_loss: 1.2103 - val_accuracy: 0.5785\n",
      "Epoch 245/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8409 - accuracy: 0.6494 - val_loss: 1.2403 - val_accuracy: 0.5651\n",
      "Epoch 246/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8555 - accuracy: 0.6477 - val_loss: 1.2451 - val_accuracy: 0.6034\n",
      "Epoch 247/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8745 - accuracy: 0.6247 - val_loss: 1.2194 - val_accuracy: 0.5785\n",
      "Epoch 248/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8323 - accuracy: 0.6362 - val_loss: 1.2419 - val_accuracy: 0.6034\n",
      "Epoch 249/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8488 - accuracy: 0.6379 - val_loss: 1.2185 - val_accuracy: 0.5900\n",
      "Epoch 250/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.8748 - accuracy: 0.6305 - val_loss: 1.1968 - val_accuracy: 0.6015\n",
      "Epoch 251/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8556 - accuracy: 0.6329 - val_loss: 1.1659 - val_accuracy: 0.6054\n",
      "Epoch 252/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8362 - accuracy: 0.6576 - val_loss: 1.1999 - val_accuracy: 0.6054\n",
      "Epoch 253/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8444 - accuracy: 0.6403 - val_loss: 1.1905 - val_accuracy: 0.5996\n",
      "Epoch 254/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8179 - accuracy: 0.6494 - val_loss: 1.2465 - val_accuracy: 0.5958\n",
      "Epoch 255/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8491 - accuracy: 0.6510 - val_loss: 1.2265 - val_accuracy: 0.5843\n",
      "Epoch 256/1000\n",
      "38/38 [==============================] - 3s 80ms/step - loss: 0.9059 - accuracy: 0.6305 - val_loss: 1.1837 - val_accuracy: 0.5977\n",
      "Epoch 257/1000\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.8496 - accuracy: 0.6412 - val_loss: 1.1859 - val_accuracy: 0.5881\n",
      "Epoch 258/1000\n",
      "38/38 [==============================] - 4s 95ms/step - loss: 0.8367 - accuracy: 0.6379 - val_loss: 1.2009 - val_accuracy: 0.6130\n",
      "Epoch 259/1000\n",
      "38/38 [==============================] - 4s 97ms/step - loss: 0.8341 - accuracy: 0.6461 - val_loss: 1.2062 - val_accuracy: 0.5805\n",
      "Epoch 260/1000\n",
      "38/38 [==============================] - 3s 79ms/step - loss: 0.8519 - accuracy: 0.6379 - val_loss: 1.2824 - val_accuracy: 0.5690\n",
      "Epoch 261/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8310 - accuracy: 0.6568 - val_loss: 1.2163 - val_accuracy: 0.5805\n",
      "Epoch 262/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8705 - accuracy: 0.6346 - val_loss: 1.2696 - val_accuracy: 0.5747\n",
      "Epoch 263/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8795 - accuracy: 0.6214 - val_loss: 1.2437 - val_accuracy: 0.5900\n",
      "Epoch 264/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8289 - accuracy: 0.6494 - val_loss: 1.2222 - val_accuracy: 0.5920\n",
      "Epoch 265/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8548 - accuracy: 0.6494 - val_loss: 1.2161 - val_accuracy: 0.5939\n",
      "Epoch 266/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8381 - accuracy: 0.6486 - val_loss: 1.1846 - val_accuracy: 0.6149\n",
      "Epoch 267/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8122 - accuracy: 0.6609 - val_loss: 1.2365 - val_accuracy: 0.6092\n",
      "Epoch 268/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8396 - accuracy: 0.6395 - val_loss: 1.2846 - val_accuracy: 0.6073\n",
      "Epoch 269/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8182 - accuracy: 0.6560 - val_loss: 1.2851 - val_accuracy: 0.6015\n",
      "Epoch 270/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8192 - accuracy: 0.6535 - val_loss: 1.2270 - val_accuracy: 0.5900\n",
      "Epoch 271/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8289 - accuracy: 0.6420 - val_loss: 1.2611 - val_accuracy: 0.6226\n",
      "Epoch 272/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8135 - accuracy: 0.6601 - val_loss: 1.2795 - val_accuracy: 0.5766\n",
      "Epoch 273/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8595 - accuracy: 0.6395 - val_loss: 1.2891 - val_accuracy: 0.5805\n",
      "Epoch 274/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8147 - accuracy: 0.6724 - val_loss: 1.2620 - val_accuracy: 0.6111\n",
      "Epoch 275/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8085 - accuracy: 0.6519 - val_loss: 1.2263 - val_accuracy: 0.6015\n",
      "Epoch 276/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8309 - accuracy: 0.6494 - val_loss: 1.2252 - val_accuracy: 0.5920\n",
      "Epoch 277/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8286 - accuracy: 0.6403 - val_loss: 1.2703 - val_accuracy: 0.5632\n",
      "Epoch 278/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8438 - accuracy: 0.6362 - val_loss: 1.2111 - val_accuracy: 0.6073\n",
      "Epoch 279/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8163 - accuracy: 0.6576 - val_loss: 1.2538 - val_accuracy: 0.6015\n",
      "Epoch 280/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.8339 - accuracy: 0.6560 - val_loss: 1.2512 - val_accuracy: 0.5939\n",
      "Epoch 281/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8290 - accuracy: 0.6477 - val_loss: 1.2405 - val_accuracy: 0.5881\n",
      "Epoch 282/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8358 - accuracy: 0.6510 - val_loss: 1.2704 - val_accuracy: 0.5651\n",
      "Epoch 283/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8177 - accuracy: 0.6519 - val_loss: 1.2122 - val_accuracy: 0.5958\n",
      "Epoch 284/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.8122 - accuracy: 0.6510 - val_loss: 1.2605 - val_accuracy: 0.5747\n",
      "Epoch 285/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8199 - accuracy: 0.6486 - val_loss: 1.2512 - val_accuracy: 0.6149\n",
      "Epoch 286/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8105 - accuracy: 0.6576 - val_loss: 1.2188 - val_accuracy: 0.6245\n",
      "Epoch 287/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7880 - accuracy: 0.6626 - val_loss: 1.3096 - val_accuracy: 0.5843\n",
      "Epoch 288/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8253 - accuracy: 0.6576 - val_loss: 1.2674 - val_accuracy: 0.6188\n",
      "Epoch 289/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.7991 - accuracy: 0.6568 - val_loss: 1.2404 - val_accuracy: 0.6054\n",
      "Epoch 290/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7936 - accuracy: 0.6634 - val_loss: 1.2423 - val_accuracy: 0.6130\n",
      "Epoch 291/1000\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.7945 - accuracy: 0.6543 - val_loss: 1.2750 - val_accuracy: 0.6034\n",
      "Epoch 292/1000\n",
      "38/38 [==============================] - 4s 118ms/step - loss: 0.8217 - accuracy: 0.6461 - val_loss: 1.2304 - val_accuracy: 0.6092\n",
      "Epoch 293/1000\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 0.8030 - accuracy: 0.6617 - val_loss: 1.2410 - val_accuracy: 0.6111\n",
      "Epoch 294/1000\n",
      "38/38 [==============================] - 4s 95ms/step - loss: 0.8204 - accuracy: 0.6576 - val_loss: 1.2987 - val_accuracy: 0.5709\n",
      "Epoch 295/1000\n",
      "38/38 [==============================] - 2s 47ms/step - loss: 0.8318 - accuracy: 0.6362 - val_loss: 1.2765 - val_accuracy: 0.5766\n",
      "Epoch 296/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.8267 - accuracy: 0.6420 - val_loss: 1.2606 - val_accuracy: 0.6015\n",
      "Epoch 297/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8095 - accuracy: 0.6617 - val_loss: 1.2833 - val_accuracy: 0.5900\n",
      "Epoch 298/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8045 - accuracy: 0.6667 - val_loss: 1.2069 - val_accuracy: 0.6398\n",
      "Epoch 299/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8091 - accuracy: 0.6444 - val_loss: 1.2112 - val_accuracy: 0.6034\n",
      "Epoch 300/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8028 - accuracy: 0.6626 - val_loss: 1.2234 - val_accuracy: 0.6111\n",
      "Epoch 301/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.7981 - accuracy: 0.6749 - val_loss: 1.2077 - val_accuracy: 0.6207\n",
      "Epoch 302/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7891 - accuracy: 0.6626 - val_loss: 1.2448 - val_accuracy: 0.5881\n",
      "Epoch 303/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7988 - accuracy: 0.6543 - val_loss: 1.2783 - val_accuracy: 0.5996\n",
      "Epoch 304/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.7971 - accuracy: 0.6527 - val_loss: 1.2485 - val_accuracy: 0.6264\n",
      "Epoch 305/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7934 - accuracy: 0.6650 - val_loss: 1.2263 - val_accuracy: 0.6149\n",
      "Epoch 306/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7813 - accuracy: 0.6716 - val_loss: 1.3060 - val_accuracy: 0.5939\n",
      "Epoch 307/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.8110 - accuracy: 0.6617 - val_loss: 1.2526 - val_accuracy: 0.5996\n",
      "Epoch 308/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7887 - accuracy: 0.6658 - val_loss: 1.2693 - val_accuracy: 0.5881\n",
      "Epoch 309/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7991 - accuracy: 0.6749 - val_loss: 1.2614 - val_accuracy: 0.6073\n",
      "Epoch 310/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7716 - accuracy: 0.6733 - val_loss: 1.2964 - val_accuracy: 0.5920\n",
      "Epoch 311/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8059 - accuracy: 0.6576 - val_loss: 1.2691 - val_accuracy: 0.5766\n",
      "Epoch 312/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.8201 - accuracy: 0.6337 - val_loss: 1.2712 - val_accuracy: 0.5977\n",
      "Epoch 313/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.7745 - accuracy: 0.6675 - val_loss: 1.2468 - val_accuracy: 0.6073\n",
      "Epoch 314/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7899 - accuracy: 0.6551 - val_loss: 1.2350 - val_accuracy: 0.6207\n",
      "Epoch 315/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.8136 - accuracy: 0.6494 - val_loss: 1.3031 - val_accuracy: 0.5881\n",
      "Epoch 316/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7614 - accuracy: 0.6848 - val_loss: 1.2412 - val_accuracy: 0.6360\n",
      "Epoch 317/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8030 - accuracy: 0.6510 - val_loss: 1.2350 - val_accuracy: 0.6073\n",
      "Epoch 318/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7831 - accuracy: 0.6576 - val_loss: 1.2431 - val_accuracy: 0.6073\n",
      "Epoch 319/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7870 - accuracy: 0.6700 - val_loss: 1.2667 - val_accuracy: 0.6054\n",
      "Epoch 320/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7764 - accuracy: 0.6700 - val_loss: 1.2237 - val_accuracy: 0.6092\n",
      "Epoch 321/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7716 - accuracy: 0.6642 - val_loss: 1.2303 - val_accuracy: 0.6073\n",
      "Epoch 322/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7716 - accuracy: 0.6642 - val_loss: 1.3363 - val_accuracy: 0.5881\n",
      "Epoch 323/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7783 - accuracy: 0.6601 - val_loss: 1.2119 - val_accuracy: 0.6130\n",
      "Epoch 324/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7872 - accuracy: 0.6675 - val_loss: 1.2256 - val_accuracy: 0.6130\n",
      "Epoch 325/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7774 - accuracy: 0.6765 - val_loss: 1.3077 - val_accuracy: 0.5594\n",
      "Epoch 326/1000\n",
      "38/38 [==============================] - 2s 48ms/step - loss: 0.7710 - accuracy: 0.6749 - val_loss: 1.2657 - val_accuracy: 0.6169\n",
      "Epoch 327/1000\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.7575 - accuracy: 0.6749 - val_loss: 1.2670 - val_accuracy: 0.6245\n",
      "Epoch 328/1000\n",
      "38/38 [==============================] - 4s 100ms/step - loss: 0.7873 - accuracy: 0.6609 - val_loss: 1.3344 - val_accuracy: 0.6054\n",
      "Epoch 329/1000\n",
      "38/38 [==============================] - 3s 86ms/step - loss: 0.7985 - accuracy: 0.6733 - val_loss: 1.2898 - val_accuracy: 0.5996\n",
      "Epoch 330/1000\n",
      "38/38 [==============================] - 4s 97ms/step - loss: 0.7795 - accuracy: 0.6798 - val_loss: 1.2858 - val_accuracy: 0.5996\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 2s 57ms/step - loss: 0.7569 - accuracy: 0.6741 - val_loss: 1.2542 - val_accuracy: 0.6456\n",
      "Epoch 332/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7976 - accuracy: 0.6650 - val_loss: 1.2216 - val_accuracy: 0.6245\n",
      "Epoch 333/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7627 - accuracy: 0.6642 - val_loss: 1.2549 - val_accuracy: 0.5977\n",
      "Epoch 334/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7383 - accuracy: 0.6724 - val_loss: 1.2573 - val_accuracy: 0.6226\n",
      "Epoch 335/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7911 - accuracy: 0.6560 - val_loss: 1.3300 - val_accuracy: 0.5728\n",
      "Epoch 336/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7552 - accuracy: 0.6683 - val_loss: 1.2894 - val_accuracy: 0.6111\n",
      "Epoch 337/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7837 - accuracy: 0.6708 - val_loss: 1.3041 - val_accuracy: 0.5958\n",
      "Epoch 338/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7804 - accuracy: 0.6650 - val_loss: 1.2878 - val_accuracy: 0.5824\n",
      "Epoch 339/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.7608 - accuracy: 0.6774 - val_loss: 1.2711 - val_accuracy: 0.5862\n",
      "Epoch 340/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7631 - accuracy: 0.6733 - val_loss: 1.2505 - val_accuracy: 0.6226\n",
      "Epoch 341/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7487 - accuracy: 0.6675 - val_loss: 1.2879 - val_accuracy: 0.5900\n",
      "Epoch 342/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7629 - accuracy: 0.6782 - val_loss: 1.2361 - val_accuracy: 0.6073\n",
      "Epoch 343/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7788 - accuracy: 0.6658 - val_loss: 1.2899 - val_accuracy: 0.6149\n",
      "Epoch 344/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7675 - accuracy: 0.6634 - val_loss: 1.2440 - val_accuracy: 0.5843\n",
      "Epoch 345/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7846 - accuracy: 0.6601 - val_loss: 1.2380 - val_accuracy: 0.5862\n",
      "Epoch 346/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7747 - accuracy: 0.6584 - val_loss: 1.2826 - val_accuracy: 0.6149\n",
      "Epoch 347/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7888 - accuracy: 0.6634 - val_loss: 1.2206 - val_accuracy: 0.6379\n",
      "Epoch 348/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7307 - accuracy: 0.6897 - val_loss: 1.2334 - val_accuracy: 0.6456\n",
      "Epoch 349/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7458 - accuracy: 0.6782 - val_loss: 1.2157 - val_accuracy: 0.6130\n",
      "Epoch 350/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7320 - accuracy: 0.6979 - val_loss: 1.3067 - val_accuracy: 0.5651\n",
      "Epoch 351/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7757 - accuracy: 0.6807 - val_loss: 1.2217 - val_accuracy: 0.6379\n",
      "Validation Accuracy: 60.536%\n"
     ]
    }
   ],
   "source": [
    "# # Training on validation data (Experimental)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# y_val = Data_val.Emotion\n",
    "# X_val = pd.DataFrame(Data_val.drop(['Emotion', 'User'], axis = 1))\n",
    "\n",
    "# X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(X_val, y_val, test_size = 0.3, random_state = 123)\n",
    "\n",
    "\n",
    "# #Trying adam optimizer\n",
    "# modelVal = initModelGRU(X.shape[1], 7, 'softmax')\n",
    "# modelVal.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# historyVal = modelVal.fit(\n",
    "#     X_train_val,\n",
    "#     y_train_val,\n",
    "#     validation_data = (X_test_val, y_test_val),\n",
    "#     epochs=1000,\n",
    "#     callbacks=[\n",
    "#         tf.keras.callbacks.EarlyStopping(\n",
    "#             monitor='val_loss',\n",
    "#             patience=100,\n",
    "#             restore_best_weights=True\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# #Result of adam optimizer on validation data\n",
    "# model_acc = modelVal.evaluate(X_test_val, y_test_val, verbose=0)[1]\n",
    "# print(\"Validation Accuracy: {:.3f}%\".format(model_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2cd3b7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Plot the accuracy curve for validation set\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(historyVal.history['val_accuracy'], color='r', label=\"Accuracy\")\n",
    "\n",
    "# plt.title(\"Val accuracy\")\n",
    "# plt.xlabel(\"Number of Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b225588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict = model.predict(X_test)[0]\n",
    "# predict = [np.argmax(pre) for pre in predict]\n",
    "# print(predict)\n",
    "# y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e5e15a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
