{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8778ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.signal import medfilt\n",
    "from scipy.signal import wiener\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "genders = ['male', 'female']\n",
    "labels = ['Happy', 'Surprise', 'Disgust', 'Angry', 'Fear', 'Sad', 'Neutral'] # 0-6, 7 classes\n",
    "\n",
    "def preprocess_data(dataPath, train):\n",
    "    if train:\n",
    "        path = os.path.join(dataPath, 'train')\n",
    "        output_dir = os.path.join(dataPath, 'train.csv')\n",
    "    else:\n",
    "        path = os.path.join(dataPath, 'val')\n",
    "        output_dir = os.path.join(dataPath, 'val.csv')\n",
    "    folders = glob.glob(os.path.join(path, '*'))\n",
    "    folders.sort()\n",
    "\n",
    "    with open(output_dir, 'a+') as csv_output_file:\n",
    "        fieldnames = ['User', 'Person_min', 'Max', 'Min', 'Mean', 'Var', 'Mean Abs Diff', 'Mean Abs Second Diff', 'Emotion', 'Gender', 'Age'] # The features extracted\n",
    "        writer = csv.DictWriter(csv_output_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for dir in folders:\n",
    "            with open(os.path.join(dir, 'EDA.csv')) as csv_file:\n",
    "                csv_reader = csv.reader(csv_file)\n",
    "                line_count = 0\n",
    "                data = [] # all data for one person\n",
    "                time_stamp = [] # time stamp for each item\n",
    "\n",
    "                for row in csv_reader:\n",
    "                    if line_count == 0:\n",
    "                        start_time = float(row[0])\n",
    "                    elif line_count == 1:\n",
    "                        freq = float(row[0])\n",
    "                    elif line_count>2 :\n",
    "                        data.append(float(row[0]))\n",
    "                        time_stamp.append(start_time + float((line_count-2)/freq))\n",
    "                    line_count += 1\n",
    "\n",
    "                person_Max = max(data)\n",
    "                person_Min = min(data)\n",
    "                data = (data - np.average(data)) / (np.std(data)) # standartization filter\n",
    "                #data = (np.array(data) - float(person_Min)) / (float(person_Max) - float(person_Min)) # normalised data for each person\n",
    "                #data = medfilt(data, 11) # median filter; can be substituted by your preprocessing methods\n",
    "                #data = wiener(data)\n",
    "                #data = savgol_filter(data, 11, 5)\n",
    "                person_Max = max(data)\n",
    "                person_Min = min(data)\n",
    "                \n",
    "            \n",
    "                log = open(os.path.join(dir, 'log.txt'), 'r')\n",
    "                log_count = 0\n",
    "                for line in log:\n",
    "                    if log_count == 0:\n",
    "                        user = line.split(';')[0].split(':')[-1]\n",
    "                        age = line.split(';')[1].split(':')[-1]\n",
    "                        gender = line.split(';')[2].split(':')[-1]\n",
    "                        gender = genders.index(gender.lower())\n",
    "                        log_count += 1\n",
    "                    elif log_count == 1:\n",
    "                        log_count += 1\n",
    "                    else:\n",
    "                        st = float(line.split(';')[1]) # start time of each video\n",
    "                        et = float(line.split(';')[3]) # end time of each video\n",
    "                        video_name = line.split(';')[2]\n",
    "                        if \"_\" in video_name:\n",
    "                            emotion_label = line.split(';')[2].split('.')[0][:-10] # emotion label of each video\n",
    "                        else:\n",
    "                            emotion_label = line.split(';')[2].split('.')[0][:-9]  # emotion label of each video\n",
    "                        emotion_label = labels.index(emotion_label)\n",
    "\n",
    "                        index = np.where(np.logical_and((np.array(time_stamp) >= st), (np.array(time_stamp) <= et)))\n",
    "                        data_list = data[index[0]]\n",
    "                        if len(data_list)== 0:\n",
    "                            break\n",
    "                        diff_list = [data_list[k+1]-data_list[k] for k in range(len(data_list)-1)]\n",
    "                        abs_diff_list = abs(np.array(diff_list))\n",
    "                        second_diff_list = [diff_list[k + 1] - diff_list[k] for k in range(len(diff_list) - 1)]\n",
    "                        abs_second_diff_list = abs(np.array(second_diff_list))\n",
    "                        writer.writerow({'User': user, 'Person_min': person_Min,  'Max': max(data_list), 'Min': min(data_list), 'Mean': np.mean(data_list), 'Var': np.var(data_list), 'Mean Abs Diff': np.mean(abs_diff_list), 'Mean Abs Second Diff': np.mean(abs_second_diff_list),'Emotion': emotion_label, 'Gender': gender, 'Age': age})\n",
    "                log.close()\n",
    "        csv_file.close()\n",
    "    csv_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8285489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and reading dat\n",
    "\n",
    "os.remove('train.csv')\n",
    "preprocess_data('', train=1)\n",
    "os.remove('val.csv')\n",
    "preprocess_data('', train=0)\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "Data_train = pd.read_csv(\"train.csv\", sep = \",\")\n",
    "Data_train = shuffle(Data_train)\n",
    "#Data_train[Data_train.User == \"Person_25\"].head(10)\n",
    "#Data_train.head(20)\n",
    "\n",
    "Data_val = pd.read_csv(\"val.csv\")\n",
    "Data_val = shuffle(Data_val)\n",
    "#Data_val[Data_val.User == \"Person_25\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca097b4",
   "metadata": {},
   "source": [
    "# Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "22e78213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import seaborn as sns\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(16, 10))\n",
    "# plt.plot(np.arange(0, 1000, 1), Data_train.Mean.iloc[:1000], scaley = 100)\n",
    "# plt.title(\"Mean variations\")\n",
    "# plt.legend([\"y = mean common variation\"])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e9f27eba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #Max\tMin\tMean\tVar\tMean Abs Diff\tMean Abs Second Diff\tEmotion\n",
    "\n",
    "# sns.set(rc = {'figure.figsize':(16, 10)})\n",
    "# sns.set_theme(style=\"darkgrid\")\n",
    "# sns.scatterplot(data = Data_train, x = \"Mean\", y = Data_train.index, hue = \"Emotion\", palette = \"tab10\", x_bins= 150)\n",
    "# #sns.lineplot(data = Data_train.iloc[:1500], x = Data_train.Mean.iloc[:1500], y = np.arange(0, 1500, 1), hue = \"Emotion\", palette = \"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "81e60458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9a21b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data_train.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a95ae",
   "metadata": {},
   "source": [
    "####  Data is distributed normally. No NaN values. Sad and happy emotions have more samples than others -> might have to equalize value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7072b73",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "08962cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def initModelGRU(shape, outputUnits, outputActivation) -> tf.keras.Model:\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    inputs = tf.keras.Input(shape = (shape))\n",
    "    expand = tf.expand_dims(inputs, axis = 2)\n",
    "\n",
    "    gru = tf.keras.layers.GRU(256, return_sequences = True, recurrent_dropout = 0.25, activation = 'relu')(expand)\n",
    "    flatten = tf.keras.layers.Flatten()(gru)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(outputUnits, activation = outputActivation)(flatten)    \n",
    "    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9176b7a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 9)]               0         \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (None, 9, 1)             0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 9, 256)            198912    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 16135     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 215,047\n",
      "Trainable params: 215,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "39/39 [==============================] - 5s 58ms/step - loss: 1.9359 - accuracy: 0.1962 - val_loss: 1.9134 - val_accuracy: 0.2081\n",
      "Epoch 2/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 1.9088 - accuracy: 0.2079 - val_loss: 1.9299 - val_accuracy: 0.1696\n",
      "Epoch 3/1000\n",
      "39/39 [==============================] - 2s 44ms/step - loss: 1.9006 - accuracy: 0.2183 - val_loss: 1.8939 - val_accuracy: 0.1940\n",
      "Epoch 4/1000\n",
      "39/39 [==============================] - 2s 50ms/step - loss: 1.8883 - accuracy: 0.2191 - val_loss: 1.8962 - val_accuracy: 0.2043\n",
      "Epoch 5/1000\n",
      "39/39 [==============================] - 2s 45ms/step - loss: 1.8839 - accuracy: 0.2055 - val_loss: 1.8855 - val_accuracy: 0.1874\n",
      "Epoch 6/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.8894 - accuracy: 0.2252 - val_loss: 1.8839 - val_accuracy: 0.1987\n",
      "Epoch 7/1000\n",
      "39/39 [==============================] - 2s 46ms/step - loss: 1.8786 - accuracy: 0.2111 - val_loss: 1.8885 - val_accuracy: 0.1903\n",
      "Epoch 8/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.8749 - accuracy: 0.2280 - val_loss: 1.8850 - val_accuracy: 0.2184\n",
      "Epoch 9/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.8745 - accuracy: 0.2207 - val_loss: 1.8810 - val_accuracy: 0.2259\n",
      "Epoch 10/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.8657 - accuracy: 0.2392 - val_loss: 1.8848 - val_accuracy: 0.2071\n",
      "Epoch 11/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.8623 - accuracy: 0.2312 - val_loss: 1.8794 - val_accuracy: 0.2259\n",
      "Epoch 12/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.8613 - accuracy: 0.2409 - val_loss: 1.8771 - val_accuracy: 0.2249\n",
      "Epoch 13/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.8587 - accuracy: 0.2485 - val_loss: 1.8783 - val_accuracy: 0.2174\n",
      "Epoch 14/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.8513 - accuracy: 0.2465 - val_loss: 1.8649 - val_accuracy: 0.2127\n",
      "Epoch 15/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.8444 - accuracy: 0.2437 - val_loss: 1.8791 - val_accuracy: 0.2296\n",
      "Epoch 16/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.8379 - accuracy: 0.2485 - val_loss: 1.8648 - val_accuracy: 0.2390\n",
      "Epoch 17/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.8344 - accuracy: 0.2517 - val_loss: 1.8574 - val_accuracy: 0.2165\n",
      "Epoch 18/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.8346 - accuracy: 0.2425 - val_loss: 1.8594 - val_accuracy: 0.2221\n",
      "Epoch 19/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.8276 - accuracy: 0.2521 - val_loss: 1.8515 - val_accuracy: 0.2493\n",
      "Epoch 20/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.8221 - accuracy: 0.2469 - val_loss: 1.8403 - val_accuracy: 0.2484\n",
      "Epoch 21/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.8149 - accuracy: 0.2553 - val_loss: 1.8422 - val_accuracy: 0.2455\n",
      "Epoch 22/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.8078 - accuracy: 0.2602 - val_loss: 1.8490 - val_accuracy: 0.2231\n",
      "Epoch 23/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.8098 - accuracy: 0.2606 - val_loss: 1.8433 - val_accuracy: 0.2493\n",
      "Epoch 24/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.8025 - accuracy: 0.2758 - val_loss: 1.8239 - val_accuracy: 0.2484\n",
      "Epoch 25/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7993 - accuracy: 0.2690 - val_loss: 1.8327 - val_accuracy: 0.2390\n",
      "Epoch 26/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.7960 - accuracy: 0.2682 - val_loss: 1.8257 - val_accuracy: 0.2512\n",
      "Epoch 27/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7896 - accuracy: 0.2879 - val_loss: 1.8354 - val_accuracy: 0.2306\n",
      "Epoch 28/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7918 - accuracy: 0.2762 - val_loss: 1.8183 - val_accuracy: 0.2559\n",
      "Epoch 29/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.7807 - accuracy: 0.2815 - val_loss: 1.8153 - val_accuracy: 0.2690\n",
      "Epoch 30/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.7794 - accuracy: 0.2903 - val_loss: 1.8117 - val_accuracy: 0.2652\n",
      "Epoch 31/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7808 - accuracy: 0.2867 - val_loss: 1.8305 - val_accuracy: 0.2746\n",
      "Epoch 32/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7761 - accuracy: 0.2799 - val_loss: 1.8025 - val_accuracy: 0.2755\n",
      "Epoch 33/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.7687 - accuracy: 0.2811 - val_loss: 1.7981 - val_accuracy: 0.2512\n",
      "Epoch 34/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.7560 - accuracy: 0.3040 - val_loss: 1.7990 - val_accuracy: 0.2793\n",
      "Epoch 35/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7650 - accuracy: 0.2855 - val_loss: 1.7992 - val_accuracy: 0.2737\n",
      "Epoch 36/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7525 - accuracy: 0.2947 - val_loss: 1.8063 - val_accuracy: 0.2746\n",
      "Epoch 37/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.7476 - accuracy: 0.2971 - val_loss: 1.7852 - val_accuracy: 0.2765\n",
      "Epoch 38/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7481 - accuracy: 0.3096 - val_loss: 1.7879 - val_accuracy: 0.2755\n",
      "Epoch 39/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7579 - accuracy: 0.2887 - val_loss: 1.7906 - val_accuracy: 0.2784\n",
      "Epoch 40/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7457 - accuracy: 0.3052 - val_loss: 1.7982 - val_accuracy: 0.2849\n",
      "Epoch 41/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7437 - accuracy: 0.3020 - val_loss: 1.7760 - val_accuracy: 0.2821\n",
      "Epoch 42/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7283 - accuracy: 0.3064 - val_loss: 1.7948 - val_accuracy: 0.2812\n",
      "Epoch 43/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7372 - accuracy: 0.3108 - val_loss: 1.7779 - val_accuracy: 0.2671\n",
      "Epoch 44/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7230 - accuracy: 0.3084 - val_loss: 1.7652 - val_accuracy: 0.2971\n",
      "Epoch 45/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.7139 - accuracy: 0.3197 - val_loss: 1.7714 - val_accuracy: 0.2933\n",
      "Epoch 46/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7259 - accuracy: 0.3060 - val_loss: 1.7657 - val_accuracy: 0.2905\n",
      "Epoch 47/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7166 - accuracy: 0.3249 - val_loss: 1.7656 - val_accuracy: 0.3112\n",
      "Epoch 48/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7118 - accuracy: 0.3136 - val_loss: 1.7653 - val_accuracy: 0.2933\n",
      "Epoch 49/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.7004 - accuracy: 0.3225 - val_loss: 1.7450 - val_accuracy: 0.3083\n",
      "Epoch 50/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 2s 41ms/step - loss: 1.6958 - accuracy: 0.3217 - val_loss: 1.7608 - val_accuracy: 0.2905\n",
      "Epoch 51/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.6974 - accuracy: 0.3245 - val_loss: 1.7706 - val_accuracy: 0.2868\n",
      "Epoch 52/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.6989 - accuracy: 0.3124 - val_loss: 1.7501 - val_accuracy: 0.3018\n",
      "Epoch 53/1000\n",
      "39/39 [==============================] - 1s 39ms/step - loss: 1.6892 - accuracy: 0.3386 - val_loss: 1.7354 - val_accuracy: 0.3008\n",
      "Epoch 54/1000\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 1.6957 - accuracy: 0.3285 - val_loss: 1.7374 - val_accuracy: 0.3093\n",
      "Epoch 55/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.6796 - accuracy: 0.3374 - val_loss: 1.7270 - val_accuracy: 0.3271\n",
      "Epoch 56/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.6807 - accuracy: 0.3361 - val_loss: 1.7368 - val_accuracy: 0.3130\n",
      "Epoch 57/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.6738 - accuracy: 0.3438 - val_loss: 1.7396 - val_accuracy: 0.3065\n",
      "Epoch 58/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.6586 - accuracy: 0.3454 - val_loss: 1.7533 - val_accuracy: 0.2999\n",
      "Epoch 59/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 1.6631 - accuracy: 0.3458 - val_loss: 1.7215 - val_accuracy: 0.3055\n",
      "Epoch 60/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.6591 - accuracy: 0.3341 - val_loss: 1.7563 - val_accuracy: 0.2971\n",
      "Epoch 61/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.6573 - accuracy: 0.3466 - val_loss: 1.7291 - val_accuracy: 0.3233\n",
      "Epoch 62/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.6478 - accuracy: 0.3454 - val_loss: 1.6986 - val_accuracy: 0.3327\n",
      "Epoch 63/1000\n",
      "39/39 [==============================] - 2s 50ms/step - loss: 1.6418 - accuracy: 0.3422 - val_loss: 1.6987 - val_accuracy: 0.3177\n",
      "Epoch 64/1000\n",
      "39/39 [==============================] - 4s 110ms/step - loss: 1.6463 - accuracy: 0.3426 - val_loss: 1.7316 - val_accuracy: 0.3027\n",
      "Epoch 65/1000\n",
      "39/39 [==============================] - 4s 101ms/step - loss: 1.6466 - accuracy: 0.3494 - val_loss: 1.7005 - val_accuracy: 0.3299\n",
      "Epoch 66/1000\n",
      "39/39 [==============================] - 4s 112ms/step - loss: 1.6345 - accuracy: 0.3530 - val_loss: 1.6873 - val_accuracy: 0.3327\n",
      "Epoch 67/1000\n",
      "39/39 [==============================] - 3s 66ms/step - loss: 1.6281 - accuracy: 0.3579 - val_loss: 1.6985 - val_accuracy: 0.3243\n",
      "Epoch 68/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.6318 - accuracy: 0.3530 - val_loss: 1.6898 - val_accuracy: 0.3383\n",
      "Epoch 69/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.6133 - accuracy: 0.3575 - val_loss: 1.6896 - val_accuracy: 0.3308\n",
      "Epoch 70/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.6168 - accuracy: 0.3599 - val_loss: 1.6783 - val_accuracy: 0.3346\n",
      "Epoch 71/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.6130 - accuracy: 0.3615 - val_loss: 1.6925 - val_accuracy: 0.3336\n",
      "Epoch 72/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.5959 - accuracy: 0.3683 - val_loss: 1.6733 - val_accuracy: 0.3552\n",
      "Epoch 73/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.5906 - accuracy: 0.3691 - val_loss: 1.6669 - val_accuracy: 0.3449\n",
      "Epoch 74/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.5911 - accuracy: 0.3679 - val_loss: 1.6739 - val_accuracy: 0.3505\n",
      "Epoch 75/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.5722 - accuracy: 0.3792 - val_loss: 1.6542 - val_accuracy: 0.3458\n",
      "Epoch 76/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.5832 - accuracy: 0.3747 - val_loss: 1.6593 - val_accuracy: 0.3486\n",
      "Epoch 77/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.5753 - accuracy: 0.3776 - val_loss: 1.6432 - val_accuracy: 0.3636\n",
      "Epoch 78/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.5754 - accuracy: 0.3611 - val_loss: 1.6778 - val_accuracy: 0.3477\n",
      "Epoch 79/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.5748 - accuracy: 0.3691 - val_loss: 1.6740 - val_accuracy: 0.3346\n",
      "Epoch 80/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.5635 - accuracy: 0.3816 - val_loss: 1.6700 - val_accuracy: 0.3365\n",
      "Epoch 81/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.5593 - accuracy: 0.3731 - val_loss: 1.6537 - val_accuracy: 0.3608\n",
      "Epoch 82/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.5588 - accuracy: 0.3723 - val_loss: 1.6462 - val_accuracy: 0.3411\n",
      "Epoch 83/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.5478 - accuracy: 0.3904 - val_loss: 1.6420 - val_accuracy: 0.3515\n",
      "Epoch 84/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.5392 - accuracy: 0.3884 - val_loss: 1.6336 - val_accuracy: 0.3515\n",
      "Epoch 85/1000\n",
      "39/39 [==============================] - 2s 45ms/step - loss: 1.5440 - accuracy: 0.3864 - val_loss: 1.6185 - val_accuracy: 0.3646\n",
      "Epoch 86/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 1.5251 - accuracy: 0.3872 - val_loss: 1.6093 - val_accuracy: 0.3683\n",
      "Epoch 87/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.5249 - accuracy: 0.4025 - val_loss: 1.6332 - val_accuracy: 0.3496\n",
      "Epoch 88/1000\n",
      "39/39 [==============================] - 3s 67ms/step - loss: 1.5138 - accuracy: 0.4045 - val_loss: 1.6116 - val_accuracy: 0.3664\n",
      "Epoch 89/1000\n",
      "39/39 [==============================] - 5s 117ms/step - loss: 1.5240 - accuracy: 0.3989 - val_loss: 1.6059 - val_accuracy: 0.3824\n",
      "Epoch 90/1000\n",
      "39/39 [==============================] - 5s 133ms/step - loss: 1.5326 - accuracy: 0.4005 - val_loss: 1.6073 - val_accuracy: 0.3608\n",
      "Epoch 91/1000\n",
      "39/39 [==============================] - 5s 118ms/step - loss: 1.5021 - accuracy: 0.4190 - val_loss: 1.5972 - val_accuracy: 0.3824\n",
      "Epoch 92/1000\n",
      "39/39 [==============================] - 2s 50ms/step - loss: 1.5063 - accuracy: 0.4081 - val_loss: 1.5948 - val_accuracy: 0.3777\n",
      "Epoch 93/1000\n",
      "39/39 [==============================] - 2s 46ms/step - loss: 1.4962 - accuracy: 0.4049 - val_loss: 1.6256 - val_accuracy: 0.3561\n",
      "Epoch 94/1000\n",
      "39/39 [==============================] - 2s 46ms/step - loss: 1.4945 - accuracy: 0.4154 - val_loss: 1.5867 - val_accuracy: 0.3664\n",
      "Epoch 95/1000\n",
      "39/39 [==============================] - 2s 47ms/step - loss: 1.4874 - accuracy: 0.4089 - val_loss: 1.5821 - val_accuracy: 0.3674\n",
      "Epoch 96/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.4866 - accuracy: 0.4129 - val_loss: 1.5840 - val_accuracy: 0.3768\n",
      "Epoch 97/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.4643 - accuracy: 0.4262 - val_loss: 1.5822 - val_accuracy: 0.3805\n",
      "Epoch 98/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 1.4845 - accuracy: 0.4202 - val_loss: 1.6045 - val_accuracy: 0.3861\n",
      "Epoch 99/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 1.4846 - accuracy: 0.4089 - val_loss: 1.5932 - val_accuracy: 0.3693\n",
      "Epoch 100/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.4687 - accuracy: 0.4162 - val_loss: 1.5715 - val_accuracy: 0.3852\n",
      "Epoch 101/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.4792 - accuracy: 0.4081 - val_loss: 1.5699 - val_accuracy: 0.3852\n",
      "Epoch 102/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.4566 - accuracy: 0.4218 - val_loss: 1.5434 - val_accuracy: 0.3993\n",
      "Epoch 103/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.4551 - accuracy: 0.4186 - val_loss: 1.5462 - val_accuracy: 0.4030\n",
      "Epoch 104/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.4326 - accuracy: 0.4294 - val_loss: 1.5572 - val_accuracy: 0.3814\n",
      "Epoch 105/1000\n",
      "39/39 [==============================] - 2s 44ms/step - loss: 1.4498 - accuracy: 0.4310 - val_loss: 1.5452 - val_accuracy: 0.3974\n",
      "Epoch 106/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.4397 - accuracy: 0.4242 - val_loss: 1.5395 - val_accuracy: 0.4049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.4334 - accuracy: 0.4310 - val_loss: 1.5564 - val_accuracy: 0.4002\n",
      "Epoch 108/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.4140 - accuracy: 0.4363 - val_loss: 1.5282 - val_accuracy: 0.4002\n",
      "Epoch 109/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.4157 - accuracy: 0.4395 - val_loss: 1.5512 - val_accuracy: 0.3927\n",
      "Epoch 110/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.4196 - accuracy: 0.4339 - val_loss: 1.5529 - val_accuracy: 0.4039\n",
      "Epoch 111/1000\n",
      "39/39 [==============================] - 3s 74ms/step - loss: 1.4255 - accuracy: 0.4326 - val_loss: 1.5183 - val_accuracy: 0.4086\n",
      "Epoch 112/1000\n",
      "39/39 [==============================] - 4s 103ms/step - loss: 1.4046 - accuracy: 0.4515 - val_loss: 1.5371 - val_accuracy: 0.3974\n",
      "Epoch 113/1000\n",
      "39/39 [==============================] - 4s 108ms/step - loss: 1.3935 - accuracy: 0.4499 - val_loss: 1.5390 - val_accuracy: 0.4002\n",
      "Epoch 114/1000\n",
      "39/39 [==============================] - 4s 102ms/step - loss: 1.4164 - accuracy: 0.4379 - val_loss: 1.5351 - val_accuracy: 0.4189\n",
      "Epoch 115/1000\n",
      "39/39 [==============================] - 3s 72ms/step - loss: 1.4177 - accuracy: 0.4371 - val_loss: 1.5596 - val_accuracy: 0.3880\n",
      "Epoch 116/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.4222 - accuracy: 0.4427 - val_loss: 1.5658 - val_accuracy: 0.3889\n",
      "Epoch 117/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.4024 - accuracy: 0.4423 - val_loss: 1.4773 - val_accuracy: 0.4367\n",
      "Epoch 118/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.3867 - accuracy: 0.4387 - val_loss: 1.5246 - val_accuracy: 0.3964\n",
      "Epoch 119/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.3871 - accuracy: 0.4612 - val_loss: 1.4967 - val_accuracy: 0.4058\n",
      "Epoch 120/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3819 - accuracy: 0.4423 - val_loss: 1.4911 - val_accuracy: 0.4208\n",
      "Epoch 121/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.3665 - accuracy: 0.4544 - val_loss: 1.5562 - val_accuracy: 0.3927\n",
      "Epoch 122/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 1.3878 - accuracy: 0.4491 - val_loss: 1.4817 - val_accuracy: 0.4161\n",
      "Epoch 123/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3694 - accuracy: 0.4620 - val_loss: 1.4843 - val_accuracy: 0.4255\n",
      "Epoch 124/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3793 - accuracy: 0.4528 - val_loss: 1.5102 - val_accuracy: 0.4058\n",
      "Epoch 125/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.3677 - accuracy: 0.4620 - val_loss: 1.4896 - val_accuracy: 0.4246\n",
      "Epoch 126/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.3369 - accuracy: 0.4608 - val_loss: 1.4934 - val_accuracy: 0.4349\n",
      "Epoch 127/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3525 - accuracy: 0.4684 - val_loss: 1.4696 - val_accuracy: 0.4330\n",
      "Epoch 128/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3416 - accuracy: 0.4612 - val_loss: 1.5262 - val_accuracy: 0.4152\n",
      "Epoch 129/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.3509 - accuracy: 0.4644 - val_loss: 1.4900 - val_accuracy: 0.4217\n",
      "Epoch 130/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.3439 - accuracy: 0.4676 - val_loss: 1.4931 - val_accuracy: 0.4236\n",
      "Epoch 131/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3268 - accuracy: 0.4785 - val_loss: 1.4755 - val_accuracy: 0.4152\n",
      "Epoch 132/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.3149 - accuracy: 0.4773 - val_loss: 1.4530 - val_accuracy: 0.4208\n",
      "Epoch 133/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.3227 - accuracy: 0.4648 - val_loss: 1.4615 - val_accuracy: 0.4236\n",
      "Epoch 134/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.3251 - accuracy: 0.4672 - val_loss: 1.4596 - val_accuracy: 0.4199\n",
      "Epoch 135/1000\n",
      "39/39 [==============================] - 3s 66ms/step - loss: 1.3186 - accuracy: 0.4805 - val_loss: 1.4655 - val_accuracy: 0.4161\n",
      "Epoch 136/1000\n",
      "39/39 [==============================] - 4s 105ms/step - loss: 1.3098 - accuracy: 0.4765 - val_loss: 1.4682 - val_accuracy: 0.4217\n",
      "Epoch 137/1000\n",
      "39/39 [==============================] - 4s 113ms/step - loss: 1.3416 - accuracy: 0.4765 - val_loss: 1.4825 - val_accuracy: 0.4292\n",
      "Epoch 138/1000\n",
      "39/39 [==============================] - 5s 115ms/step - loss: 1.3177 - accuracy: 0.4749 - val_loss: 1.4414 - val_accuracy: 0.4349\n",
      "Epoch 139/1000\n",
      "39/39 [==============================] - 3s 71ms/step - loss: 1.2998 - accuracy: 0.4672 - val_loss: 1.4624 - val_accuracy: 0.4264\n",
      "Epoch 140/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.3063 - accuracy: 0.4737 - val_loss: 1.4669 - val_accuracy: 0.4255\n",
      "Epoch 141/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.3075 - accuracy: 0.4861 - val_loss: 1.4338 - val_accuracy: 0.4367\n",
      "Epoch 142/1000\n",
      "39/39 [==============================] - 2s 44ms/step - loss: 1.2851 - accuracy: 0.4901 - val_loss: 1.4627 - val_accuracy: 0.4274\n",
      "Epoch 143/1000\n",
      "39/39 [==============================] - 2s 46ms/step - loss: 1.3111 - accuracy: 0.4737 - val_loss: 1.4472 - val_accuracy: 0.4302\n",
      "Epoch 144/1000\n",
      "39/39 [==============================] - 2s 46ms/step - loss: 1.3143 - accuracy: 0.4708 - val_loss: 1.4614 - val_accuracy: 0.4386\n",
      "Epoch 145/1000\n",
      "39/39 [==============================] - 2s 45ms/step - loss: 1.2908 - accuracy: 0.4845 - val_loss: 1.4307 - val_accuracy: 0.4405\n",
      "Epoch 146/1000\n",
      "39/39 [==============================] - 2s 48ms/step - loss: 1.2885 - accuracy: 0.4853 - val_loss: 1.4329 - val_accuracy: 0.4470\n",
      "Epoch 147/1000\n",
      "39/39 [==============================] - 2s 45ms/step - loss: 1.3002 - accuracy: 0.4809 - val_loss: 1.4353 - val_accuracy: 0.4367\n",
      "Epoch 148/1000\n",
      "39/39 [==============================] - 2s 45ms/step - loss: 1.2770 - accuracy: 0.4918 - val_loss: 1.4653 - val_accuracy: 0.4255\n",
      "Epoch 149/1000\n",
      "39/39 [==============================] - 2s 48ms/step - loss: 1.2855 - accuracy: 0.4817 - val_loss: 1.4360 - val_accuracy: 0.4311\n",
      "Epoch 150/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.2653 - accuracy: 0.4942 - val_loss: 1.4191 - val_accuracy: 0.4527\n",
      "Epoch 151/1000\n",
      "39/39 [==============================] - 2s 44ms/step - loss: 1.2646 - accuracy: 0.4938 - val_loss: 1.4286 - val_accuracy: 0.4180\n",
      "Epoch 152/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 1.2741 - accuracy: 0.4897 - val_loss: 1.4083 - val_accuracy: 0.4424\n",
      "Epoch 153/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.2627 - accuracy: 0.4946 - val_loss: 1.4386 - val_accuracy: 0.4583\n",
      "Epoch 154/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.2541 - accuracy: 0.4926 - val_loss: 1.4176 - val_accuracy: 0.4470\n",
      "Epoch 155/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.2655 - accuracy: 0.5070 - val_loss: 1.4455 - val_accuracy: 0.4311\n",
      "Epoch 156/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.2545 - accuracy: 0.4889 - val_loss: 1.4089 - val_accuracy: 0.4508\n",
      "Epoch 157/1000\n",
      "39/39 [==============================] - 2s 61ms/step - loss: 1.2475 - accuracy: 0.4954 - val_loss: 1.3982 - val_accuracy: 0.4339\n",
      "Epoch 158/1000\n",
      "39/39 [==============================] - 4s 101ms/step - loss: 1.2339 - accuracy: 0.5038 - val_loss: 1.4190 - val_accuracy: 0.4321\n",
      "Epoch 159/1000\n",
      "39/39 [==============================] - 4s 104ms/step - loss: 1.2588 - accuracy: 0.4897 - val_loss: 1.4343 - val_accuracy: 0.4274\n",
      "Epoch 160/1000\n",
      "39/39 [==============================] - 4s 106ms/step - loss: 1.2572 - accuracy: 0.4986 - val_loss: 1.4157 - val_accuracy: 0.4396\n",
      "Epoch 161/1000\n",
      "39/39 [==============================] - 3s 86ms/step - loss: 1.2272 - accuracy: 0.5014 - val_loss: 1.4306 - val_accuracy: 0.4386\n",
      "Epoch 162/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.2469 - accuracy: 0.4938 - val_loss: 1.3828 - val_accuracy: 0.4367\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 2s 41ms/step - loss: 1.2364 - accuracy: 0.5107 - val_loss: 1.4078 - val_accuracy: 0.4620\n",
      "Epoch 164/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.2176 - accuracy: 0.5066 - val_loss: 1.4192 - val_accuracy: 0.4414\n",
      "Epoch 165/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.2400 - accuracy: 0.4958 - val_loss: 1.4170 - val_accuracy: 0.4452\n",
      "Epoch 166/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 1.2244 - accuracy: 0.5151 - val_loss: 1.3867 - val_accuracy: 0.4677\n",
      "Epoch 167/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.2342 - accuracy: 0.4970 - val_loss: 1.3985 - val_accuracy: 0.4602\n",
      "Epoch 168/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.2354 - accuracy: 0.4885 - val_loss: 1.3696 - val_accuracy: 0.4761\n",
      "Epoch 169/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.2227 - accuracy: 0.5094 - val_loss: 1.3884 - val_accuracy: 0.4396\n",
      "Epoch 170/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.2055 - accuracy: 0.5199 - val_loss: 1.3880 - val_accuracy: 0.4724\n",
      "Epoch 171/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.2492 - accuracy: 0.4978 - val_loss: 1.3884 - val_accuracy: 0.4705\n",
      "Epoch 172/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.2208 - accuracy: 0.5090 - val_loss: 1.3816 - val_accuracy: 0.4742\n",
      "Epoch 173/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.2038 - accuracy: 0.5163 - val_loss: 1.3857 - val_accuracy: 0.4761\n",
      "Epoch 174/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.2109 - accuracy: 0.5074 - val_loss: 1.3880 - val_accuracy: 0.4564\n",
      "Epoch 175/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.2037 - accuracy: 0.5062 - val_loss: 1.4025 - val_accuracy: 0.4611\n",
      "Epoch 176/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.2005 - accuracy: 0.5175 - val_loss: 1.3771 - val_accuracy: 0.4714\n",
      "Epoch 177/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.1856 - accuracy: 0.5155 - val_loss: 1.3700 - val_accuracy: 0.4686\n",
      "Epoch 178/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.1982 - accuracy: 0.5155 - val_loss: 1.3615 - val_accuracy: 0.4677\n",
      "Epoch 179/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.2031 - accuracy: 0.5062 - val_loss: 1.3542 - val_accuracy: 0.4545\n",
      "Epoch 180/1000\n",
      "39/39 [==============================] - 2s 44ms/step - loss: 1.1863 - accuracy: 0.5199 - val_loss: 1.3404 - val_accuracy: 0.4761\n",
      "Epoch 181/1000\n",
      "39/39 [==============================] - 4s 103ms/step - loss: 1.2022 - accuracy: 0.5179 - val_loss: 1.3841 - val_accuracy: 0.4583\n",
      "Epoch 182/1000\n",
      "39/39 [==============================] - 4s 110ms/step - loss: 1.2010 - accuracy: 0.5195 - val_loss: 1.3688 - val_accuracy: 0.4705\n",
      "Epoch 183/1000\n",
      "39/39 [==============================] - 4s 103ms/step - loss: 1.1611 - accuracy: 0.5292 - val_loss: 1.3966 - val_accuracy: 0.4442\n",
      "Epoch 184/1000\n",
      "39/39 [==============================] - 4s 107ms/step - loss: 1.1908 - accuracy: 0.5211 - val_loss: 1.4201 - val_accuracy: 0.4639\n",
      "Epoch 185/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.2082 - accuracy: 0.5111 - val_loss: 1.3780 - val_accuracy: 0.4752\n",
      "Epoch 186/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.2056 - accuracy: 0.5062 - val_loss: 1.4135 - val_accuracy: 0.4695\n",
      "Epoch 187/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.1781 - accuracy: 0.5175 - val_loss: 1.3602 - val_accuracy: 0.4948\n",
      "Epoch 188/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.1829 - accuracy: 0.5159 - val_loss: 1.3875 - val_accuracy: 0.4752\n",
      "Epoch 189/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.1831 - accuracy: 0.5175 - val_loss: 1.3770 - val_accuracy: 0.4649\n",
      "Epoch 190/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.1590 - accuracy: 0.5360 - val_loss: 1.3664 - val_accuracy: 0.4780\n",
      "Epoch 191/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.1862 - accuracy: 0.5191 - val_loss: 1.3615 - val_accuracy: 0.4620\n",
      "Epoch 192/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.1682 - accuracy: 0.5292 - val_loss: 1.3482 - val_accuracy: 0.4930\n",
      "Epoch 193/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.1489 - accuracy: 0.5231 - val_loss: 1.3326 - val_accuracy: 0.4995\n",
      "Epoch 194/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.1458 - accuracy: 0.5328 - val_loss: 1.3957 - val_accuracy: 0.4658\n",
      "Epoch 195/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.1533 - accuracy: 0.5296 - val_loss: 1.3731 - val_accuracy: 0.4658\n",
      "Epoch 196/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.1815 - accuracy: 0.5147 - val_loss: 1.3468 - val_accuracy: 0.4920\n",
      "Epoch 197/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.1471 - accuracy: 0.5344 - val_loss: 1.3380 - val_accuracy: 0.4817\n",
      "Epoch 198/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 1.1576 - accuracy: 0.5183 - val_loss: 1.3517 - val_accuracy: 0.4902\n",
      "Epoch 199/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.1706 - accuracy: 0.5275 - val_loss: 1.3558 - val_accuracy: 0.4920\n",
      "Epoch 200/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.1432 - accuracy: 0.5372 - val_loss: 1.3544 - val_accuracy: 0.4855\n",
      "Epoch 201/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.1251 - accuracy: 0.5324 - val_loss: 1.3440 - val_accuracy: 0.4817\n",
      "Epoch 202/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.1400 - accuracy: 0.5396 - val_loss: 1.3756 - val_accuracy: 0.4574\n",
      "Epoch 203/1000\n",
      "39/39 [==============================] - 3s 76ms/step - loss: 1.1592 - accuracy: 0.5304 - val_loss: 1.3660 - val_accuracy: 0.4911\n",
      "Epoch 204/1000\n",
      "39/39 [==============================] - 4s 107ms/step - loss: 1.1683 - accuracy: 0.5215 - val_loss: 1.3902 - val_accuracy: 0.4686\n",
      "Epoch 205/1000\n",
      "39/39 [==============================] - 4s 106ms/step - loss: 1.1370 - accuracy: 0.5396 - val_loss: 1.3693 - val_accuracy: 0.4752\n",
      "Epoch 206/1000\n",
      "39/39 [==============================] - 4s 109ms/step - loss: 1.1291 - accuracy: 0.5384 - val_loss: 1.3534 - val_accuracy: 0.4864\n",
      "Epoch 207/1000\n",
      "39/39 [==============================] - 3s 66ms/step - loss: 1.1331 - accuracy: 0.5452 - val_loss: 1.3395 - val_accuracy: 0.5014\n",
      "Epoch 208/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 1.1512 - accuracy: 0.5279 - val_loss: 1.3451 - val_accuracy: 0.4667\n",
      "Epoch 209/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.1469 - accuracy: 0.5344 - val_loss: 1.3511 - val_accuracy: 0.4799\n",
      "Epoch 210/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.1238 - accuracy: 0.5448 - val_loss: 1.3459 - val_accuracy: 0.4817\n",
      "Epoch 211/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.1437 - accuracy: 0.5175 - val_loss: 1.3662 - val_accuracy: 0.4752\n",
      "Epoch 212/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.1450 - accuracy: 0.5456 - val_loss: 1.3500 - val_accuracy: 0.4920\n",
      "Epoch 213/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.1263 - accuracy: 0.5328 - val_loss: 1.3354 - val_accuracy: 0.4977\n",
      "Epoch 214/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.1329 - accuracy: 0.5396 - val_loss: 1.3534 - val_accuracy: 0.4902\n",
      "Epoch 215/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.1389 - accuracy: 0.5308 - val_loss: 1.3463 - val_accuracy: 0.4855\n",
      "Epoch 216/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.1265 - accuracy: 0.5489 - val_loss: 1.3328 - val_accuracy: 0.4911\n",
      "Epoch 217/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.1035 - accuracy: 0.5489 - val_loss: 1.3374 - val_accuracy: 0.4799\n",
      "Epoch 218/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.1186 - accuracy: 0.5404 - val_loss: 1.3422 - val_accuracy: 0.4817\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 2s 42ms/step - loss: 1.1183 - accuracy: 0.5501 - val_loss: 1.3484 - val_accuracy: 0.4939\n",
      "Epoch 220/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.1282 - accuracy: 0.5432 - val_loss: 1.3642 - val_accuracy: 0.4939\n",
      "Epoch 221/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.1106 - accuracy: 0.5497 - val_loss: 1.3078 - val_accuracy: 0.4977\n",
      "Epoch 222/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0907 - accuracy: 0.5585 - val_loss: 1.3289 - val_accuracy: 0.4967\n",
      "Epoch 223/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 1.1081 - accuracy: 0.5432 - val_loss: 1.3255 - val_accuracy: 0.5023\n",
      "Epoch 224/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.1112 - accuracy: 0.5440 - val_loss: 1.3425 - val_accuracy: 0.4958\n",
      "Epoch 225/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.1014 - accuracy: 0.5460 - val_loss: 1.3169 - val_accuracy: 0.4939\n",
      "Epoch 226/1000\n",
      "39/39 [==============================] - 4s 99ms/step - loss: 1.1078 - accuracy: 0.5468 - val_loss: 1.3071 - val_accuracy: 0.5023\n",
      "Epoch 227/1000\n",
      "39/39 [==============================] - 4s 110ms/step - loss: 1.1100 - accuracy: 0.5440 - val_loss: 1.3287 - val_accuracy: 0.4864\n",
      "Epoch 228/1000\n",
      "39/39 [==============================] - 4s 107ms/step - loss: 1.0934 - accuracy: 0.5577 - val_loss: 1.3413 - val_accuracy: 0.4780\n",
      "Epoch 229/1000\n",
      "39/39 [==============================] - 4s 114ms/step - loss: 1.1041 - accuracy: 0.5553 - val_loss: 1.3110 - val_accuracy: 0.5005\n",
      "Epoch 230/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 1.0831 - accuracy: 0.5557 - val_loss: 1.3299 - val_accuracy: 0.5033\n",
      "Epoch 231/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.1102 - accuracy: 0.5392 - val_loss: 1.3567 - val_accuracy: 0.4930\n",
      "Epoch 232/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0597 - accuracy: 0.5601 - val_loss: 1.3667 - val_accuracy: 0.4883\n",
      "Epoch 233/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0901 - accuracy: 0.5601 - val_loss: 1.3511 - val_accuracy: 0.4808\n",
      "Epoch 234/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.0701 - accuracy: 0.5617 - val_loss: 1.3082 - val_accuracy: 0.5070\n",
      "Epoch 235/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0774 - accuracy: 0.5521 - val_loss: 1.3272 - val_accuracy: 0.5005\n",
      "Epoch 236/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0885 - accuracy: 0.5529 - val_loss: 1.3337 - val_accuracy: 0.4995\n",
      "Epoch 237/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.0740 - accuracy: 0.5613 - val_loss: 1.3225 - val_accuracy: 0.4958\n",
      "Epoch 238/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.0900 - accuracy: 0.5440 - val_loss: 1.3537 - val_accuracy: 0.4883\n",
      "Epoch 239/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.0964 - accuracy: 0.5545 - val_loss: 1.3324 - val_accuracy: 0.5108\n",
      "Epoch 240/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.0752 - accuracy: 0.5593 - val_loss: 1.3344 - val_accuracy: 0.5117\n",
      "Epoch 241/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.0720 - accuracy: 0.5573 - val_loss: 1.2918 - val_accuracy: 0.5173\n",
      "Epoch 242/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0847 - accuracy: 0.5641 - val_loss: 1.3164 - val_accuracy: 0.4892\n",
      "Epoch 243/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.0671 - accuracy: 0.5657 - val_loss: 1.3169 - val_accuracy: 0.5230\n",
      "Epoch 244/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0839 - accuracy: 0.5472 - val_loss: 1.3073 - val_accuracy: 0.5230\n",
      "Epoch 245/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0523 - accuracy: 0.5577 - val_loss: 1.3563 - val_accuracy: 0.5155\n",
      "Epoch 246/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.0565 - accuracy: 0.5625 - val_loss: 1.3217 - val_accuracy: 0.5042\n",
      "Epoch 247/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.0468 - accuracy: 0.5810 - val_loss: 1.3334 - val_accuracy: 0.4995\n",
      "Epoch 248/1000\n",
      "39/39 [==============================] - 2s 55ms/step - loss: 1.0927 - accuracy: 0.5581 - val_loss: 1.3246 - val_accuracy: 0.5033\n",
      "Epoch 249/1000\n",
      "39/39 [==============================] - 4s 106ms/step - loss: 1.0786 - accuracy: 0.5565 - val_loss: 1.3149 - val_accuracy: 0.5108\n",
      "Epoch 250/1000\n",
      "39/39 [==============================] - 4s 107ms/step - loss: 1.0801 - accuracy: 0.5609 - val_loss: 1.3258 - val_accuracy: 0.5117\n",
      "Epoch 251/1000\n",
      "39/39 [==============================] - 4s 112ms/step - loss: 1.0855 - accuracy: 0.5577 - val_loss: 1.3137 - val_accuracy: 0.5080\n",
      "Epoch 252/1000\n",
      "39/39 [==============================] - 4s 93ms/step - loss: 1.0635 - accuracy: 0.5613 - val_loss: 1.3188 - val_accuracy: 0.5098\n",
      "Epoch 253/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.0794 - accuracy: 0.5565 - val_loss: 1.3333 - val_accuracy: 0.5070\n",
      "Epoch 254/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0687 - accuracy: 0.5613 - val_loss: 1.3409 - val_accuracy: 0.5014\n",
      "Epoch 255/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0644 - accuracy: 0.5589 - val_loss: 1.3229 - val_accuracy: 0.5005\n",
      "Epoch 256/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.0591 - accuracy: 0.5505 - val_loss: 1.3629 - val_accuracy: 0.4780\n",
      "Epoch 257/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0711 - accuracy: 0.5613 - val_loss: 1.3476 - val_accuracy: 0.4911\n",
      "Epoch 258/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0493 - accuracy: 0.5637 - val_loss: 1.3341 - val_accuracy: 0.5023\n",
      "Epoch 259/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0559 - accuracy: 0.5714 - val_loss: 1.3483 - val_accuracy: 0.4911\n",
      "Epoch 260/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0593 - accuracy: 0.5826 - val_loss: 1.2974 - val_accuracy: 0.5145\n",
      "Epoch 261/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0414 - accuracy: 0.5633 - val_loss: 1.3345 - val_accuracy: 0.5089\n",
      "Epoch 262/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0550 - accuracy: 0.5653 - val_loss: 1.3076 - val_accuracy: 0.5267\n",
      "Epoch 263/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0456 - accuracy: 0.5738 - val_loss: 1.3060 - val_accuracy: 0.5127\n",
      "Epoch 264/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0331 - accuracy: 0.5758 - val_loss: 1.3001 - val_accuracy: 0.5295\n",
      "Epoch 265/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0330 - accuracy: 0.5830 - val_loss: 1.3368 - val_accuracy: 0.4892\n",
      "Epoch 266/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.0618 - accuracy: 0.5589 - val_loss: 1.3089 - val_accuracy: 0.5080\n",
      "Epoch 267/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0371 - accuracy: 0.5597 - val_loss: 1.3047 - val_accuracy: 0.4977\n",
      "Epoch 268/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.0305 - accuracy: 0.5842 - val_loss: 1.3124 - val_accuracy: 0.5173\n",
      "Epoch 269/1000\n",
      "39/39 [==============================] - 2s 46ms/step - loss: 1.0354 - accuracy: 0.5714 - val_loss: 1.3311 - val_accuracy: 0.5052\n",
      "Epoch 270/1000\n",
      "39/39 [==============================] - 2s 47ms/step - loss: 1.0258 - accuracy: 0.5750 - val_loss: 1.3379 - val_accuracy: 0.5042\n",
      "Epoch 271/1000\n",
      "39/39 [==============================] - 4s 108ms/step - loss: 1.0430 - accuracy: 0.5814 - val_loss: 1.3021 - val_accuracy: 0.5389\n",
      "Epoch 272/1000\n",
      "39/39 [==============================] - 4s 112ms/step - loss: 1.0544 - accuracy: 0.5593 - val_loss: 1.3588 - val_accuracy: 0.4836\n",
      "Epoch 273/1000\n",
      "39/39 [==============================] - 4s 106ms/step - loss: 1.0478 - accuracy: 0.5762 - val_loss: 1.3254 - val_accuracy: 0.5089\n",
      "Epoch 274/1000\n",
      "39/39 [==============================] - 4s 99ms/step - loss: 1.0252 - accuracy: 0.5766 - val_loss: 1.3031 - val_accuracy: 0.5201\n",
      "Epoch 275/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0356 - accuracy: 0.5746 - val_loss: 1.3085 - val_accuracy: 0.5127\n",
      "Epoch 276/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0319 - accuracy: 0.5834 - val_loss: 1.3240 - val_accuracy: 0.5070\n",
      "Epoch 277/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0151 - accuracy: 0.5883 - val_loss: 1.2971 - val_accuracy: 0.5276\n",
      "Epoch 278/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0380 - accuracy: 0.5706 - val_loss: 1.3336 - val_accuracy: 0.5183\n",
      "Epoch 279/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.0293 - accuracy: 0.5794 - val_loss: 1.3038 - val_accuracy: 0.5239\n",
      "Epoch 280/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0242 - accuracy: 0.5790 - val_loss: 1.3016 - val_accuracy: 0.5239\n",
      "Epoch 281/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0129 - accuracy: 0.5746 - val_loss: 1.3301 - val_accuracy: 0.5080\n",
      "Epoch 282/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.0018 - accuracy: 0.5943 - val_loss: 1.3303 - val_accuracy: 0.4911\n",
      "Epoch 283/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0165 - accuracy: 0.5782 - val_loss: 1.3421 - val_accuracy: 0.5127\n",
      "Epoch 284/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0127 - accuracy: 0.5871 - val_loss: 1.3419 - val_accuracy: 0.5023\n",
      "Epoch 285/1000\n",
      "39/39 [==============================] - 2s 49ms/step - loss: 1.0246 - accuracy: 0.5846 - val_loss: 1.3231 - val_accuracy: 0.5052\n",
      "Epoch 286/1000\n",
      "39/39 [==============================] - 2s 49ms/step - loss: 1.0185 - accuracy: 0.5814 - val_loss: 1.2960 - val_accuracy: 0.5201\n",
      "Epoch 287/1000\n",
      "39/39 [==============================] - 2s 47ms/step - loss: 1.0178 - accuracy: 0.5730 - val_loss: 1.2971 - val_accuracy: 0.5258\n",
      "Epoch 288/1000\n",
      "39/39 [==============================] - 2s 46ms/step - loss: 1.0204 - accuracy: 0.5826 - val_loss: 1.3262 - val_accuracy: 0.5005\n",
      "Epoch 289/1000\n",
      "39/39 [==============================] - 2s 46ms/step - loss: 1.0143 - accuracy: 0.5810 - val_loss: 1.3136 - val_accuracy: 0.5220\n",
      "Epoch 290/1000\n",
      "39/39 [==============================] - 2s 44ms/step - loss: 1.0129 - accuracy: 0.5971 - val_loss: 1.3180 - val_accuracy: 0.5211\n",
      "Epoch 291/1000\n",
      "39/39 [==============================] - 2s 61ms/step - loss: 1.0101 - accuracy: 0.5754 - val_loss: 1.2984 - val_accuracy: 0.5286\n",
      "Epoch 292/1000\n",
      "39/39 [==============================] - 5s 132ms/step - loss: 1.0086 - accuracy: 0.5862 - val_loss: 1.3014 - val_accuracy: 0.5155\n",
      "Epoch 293/1000\n",
      "39/39 [==============================] - 5s 121ms/step - loss: 1.0070 - accuracy: 0.5842 - val_loss: 1.2964 - val_accuracy: 0.5417\n",
      "Epoch 294/1000\n",
      "39/39 [==============================] - 4s 110ms/step - loss: 1.0063 - accuracy: 0.5862 - val_loss: 1.3463 - val_accuracy: 0.4977\n",
      "Epoch 295/1000\n",
      "39/39 [==============================] - 3s 66ms/step - loss: 0.9960 - accuracy: 0.5911 - val_loss: 1.3105 - val_accuracy: 0.5127\n",
      "Epoch 296/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.0055 - accuracy: 0.5818 - val_loss: 1.3541 - val_accuracy: 0.5136\n",
      "Epoch 297/1000\n",
      "39/39 [==============================] - 2s 45ms/step - loss: 1.0036 - accuracy: 0.5903 - val_loss: 1.3482 - val_accuracy: 0.5211\n",
      "Epoch 298/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 1.0093 - accuracy: 0.5883 - val_loss: 1.3250 - val_accuracy: 0.5136\n",
      "Epoch 299/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.0151 - accuracy: 0.5883 - val_loss: 1.2925 - val_accuracy: 0.5483\n",
      "Epoch 300/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 1.0075 - accuracy: 0.5867 - val_loss: 1.3191 - val_accuracy: 0.5042\n",
      "Epoch 301/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9767 - accuracy: 0.6011 - val_loss: 1.3109 - val_accuracy: 0.5342\n",
      "Epoch 302/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9810 - accuracy: 0.5935 - val_loss: 1.3079 - val_accuracy: 0.5164\n",
      "Epoch 303/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9981 - accuracy: 0.6043 - val_loss: 1.3079 - val_accuracy: 0.5127\n",
      "Epoch 304/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9990 - accuracy: 0.5758 - val_loss: 1.3139 - val_accuracy: 0.5276\n",
      "Epoch 305/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0093 - accuracy: 0.5826 - val_loss: 1.3131 - val_accuracy: 0.5258\n",
      "Epoch 306/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 1.0018 - accuracy: 0.5854 - val_loss: 1.3204 - val_accuracy: 0.5192\n",
      "Epoch 307/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 1.0102 - accuracy: 0.5830 - val_loss: 1.3156 - val_accuracy: 0.5239\n",
      "Epoch 308/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9785 - accuracy: 0.5907 - val_loss: 1.3388 - val_accuracy: 0.5117\n",
      "Epoch 309/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9862 - accuracy: 0.5951 - val_loss: 1.3495 - val_accuracy: 0.5005\n",
      "Epoch 310/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9921 - accuracy: 0.5883 - val_loss: 1.3368 - val_accuracy: 0.5239\n",
      "Epoch 311/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9784 - accuracy: 0.6007 - val_loss: 1.3214 - val_accuracy: 0.5323\n",
      "Epoch 312/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9746 - accuracy: 0.5935 - val_loss: 1.3327 - val_accuracy: 0.5127\n",
      "Epoch 313/1000\n",
      "39/39 [==============================] - 3s 87ms/step - loss: 0.9731 - accuracy: 0.5959 - val_loss: 1.3110 - val_accuracy: 0.5436\n",
      "Epoch 314/1000\n",
      "39/39 [==============================] - 4s 108ms/step - loss: 0.9698 - accuracy: 0.5919 - val_loss: 1.3005 - val_accuracy: 0.5408\n",
      "Epoch 315/1000\n",
      "39/39 [==============================] - 4s 105ms/step - loss: 1.0101 - accuracy: 0.5786 - val_loss: 1.3118 - val_accuracy: 0.5023\n",
      "Epoch 316/1000\n",
      "39/39 [==============================] - 4s 104ms/step - loss: 0.9874 - accuracy: 0.5939 - val_loss: 1.3052 - val_accuracy: 0.5389\n",
      "Epoch 317/1000\n",
      "39/39 [==============================] - 3s 70ms/step - loss: 0.9832 - accuracy: 0.5955 - val_loss: 1.3265 - val_accuracy: 0.5258\n",
      "Epoch 318/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9901 - accuracy: 0.5838 - val_loss: 1.3103 - val_accuracy: 0.5098\n",
      "Epoch 319/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9890 - accuracy: 0.5999 - val_loss: 1.2995 - val_accuracy: 0.5361\n",
      "Epoch 320/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.9764 - accuracy: 0.5947 - val_loss: 1.3357 - val_accuracy: 0.5192\n",
      "Epoch 321/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9793 - accuracy: 0.5854 - val_loss: 1.2933 - val_accuracy: 0.5351\n",
      "Epoch 322/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9873 - accuracy: 0.5887 - val_loss: 1.3094 - val_accuracy: 0.5333\n",
      "Epoch 323/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9739 - accuracy: 0.5947 - val_loss: 1.2951 - val_accuracy: 0.5455\n",
      "Epoch 324/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9612 - accuracy: 0.5927 - val_loss: 1.3027 - val_accuracy: 0.5220\n",
      "Epoch 325/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9753 - accuracy: 0.6015 - val_loss: 1.2884 - val_accuracy: 0.5370\n",
      "Epoch 326/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9617 - accuracy: 0.6064 - val_loss: 1.3151 - val_accuracy: 0.5370\n",
      "Epoch 327/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9763 - accuracy: 0.5979 - val_loss: 1.3142 - val_accuracy: 0.5183\n",
      "Epoch 328/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9876 - accuracy: 0.5834 - val_loss: 1.3262 - val_accuracy: 0.5155\n",
      "Epoch 329/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9705 - accuracy: 0.5999 - val_loss: 1.3325 - val_accuracy: 0.5108\n",
      "Epoch 330/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9706 - accuracy: 0.5983 - val_loss: 1.3233 - val_accuracy: 0.5286\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9894 - accuracy: 0.5931 - val_loss: 1.3025 - val_accuracy: 0.5220\n",
      "Epoch 332/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9744 - accuracy: 0.5987 - val_loss: 1.3138 - val_accuracy: 0.5230\n",
      "Epoch 333/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9569 - accuracy: 0.6156 - val_loss: 1.3480 - val_accuracy: 0.5211\n",
      "Epoch 334/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9615 - accuracy: 0.6003 - val_loss: 1.3199 - val_accuracy: 0.5211\n",
      "Epoch 335/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.9639 - accuracy: 0.6027 - val_loss: 1.2896 - val_accuracy: 0.5164\n",
      "Epoch 336/1000\n",
      "39/39 [==============================] - 3s 74ms/step - loss: 0.9637 - accuracy: 0.5983 - val_loss: 1.3107 - val_accuracy: 0.5342\n",
      "Epoch 337/1000\n",
      "39/39 [==============================] - 4s 112ms/step - loss: 0.9692 - accuracy: 0.5971 - val_loss: 1.3182 - val_accuracy: 0.5342\n",
      "Epoch 338/1000\n",
      "39/39 [==============================] - 4s 109ms/step - loss: 0.9538 - accuracy: 0.6035 - val_loss: 1.3204 - val_accuracy: 0.5248\n",
      "Epoch 339/1000\n",
      "39/39 [==============================] - 4s 116ms/step - loss: 0.9372 - accuracy: 0.6132 - val_loss: 1.3026 - val_accuracy: 0.5089\n",
      "Epoch 340/1000\n",
      "39/39 [==============================] - 3s 65ms/step - loss: 0.9478 - accuracy: 0.6060 - val_loss: 1.3190 - val_accuracy: 0.5295\n",
      "Epoch 341/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9501 - accuracy: 0.6047 - val_loss: 1.2947 - val_accuracy: 0.5323\n",
      "Epoch 342/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 0.9595 - accuracy: 0.5955 - val_loss: 1.3423 - val_accuracy: 0.5211\n",
      "Epoch 343/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9622 - accuracy: 0.6080 - val_loss: 1.3427 - val_accuracy: 0.5351\n",
      "Epoch 344/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9544 - accuracy: 0.6043 - val_loss: 1.3556 - val_accuracy: 0.5033\n",
      "Epoch 345/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 0.9446 - accuracy: 0.6104 - val_loss: 1.3526 - val_accuracy: 0.5211\n",
      "Epoch 346/1000\n",
      "39/39 [==============================] - 2s 44ms/step - loss: 0.9809 - accuracy: 0.5983 - val_loss: 1.3429 - val_accuracy: 0.5080\n",
      "Epoch 347/1000\n",
      "39/39 [==============================] - 2s 48ms/step - loss: 0.9501 - accuracy: 0.6068 - val_loss: 1.3298 - val_accuracy: 0.5267\n",
      "Epoch 348/1000\n",
      "39/39 [==============================] - 2s 47ms/step - loss: 0.9378 - accuracy: 0.6168 - val_loss: 1.2965 - val_accuracy: 0.5370\n",
      "Epoch 349/1000\n",
      "39/39 [==============================] - 2s 45ms/step - loss: 0.9473 - accuracy: 0.6084 - val_loss: 1.3080 - val_accuracy: 0.5398\n",
      "Epoch 350/1000\n",
      "39/39 [==============================] - 2s 44ms/step - loss: 0.9476 - accuracy: 0.5947 - val_loss: 1.3077 - val_accuracy: 0.5183\n",
      "Epoch 351/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 0.9477 - accuracy: 0.6039 - val_loss: 1.3374 - val_accuracy: 0.5370\n",
      "Epoch 352/1000\n",
      "39/39 [==============================] - 2s 47ms/step - loss: 0.9551 - accuracy: 0.6160 - val_loss: 1.2978 - val_accuracy: 0.5389\n",
      "Epoch 353/1000\n",
      "39/39 [==============================] - 2s 46ms/step - loss: 0.9262 - accuracy: 0.6180 - val_loss: 1.2967 - val_accuracy: 0.5361\n",
      "Epoch 354/1000\n",
      "39/39 [==============================] - 2s 44ms/step - loss: 0.9472 - accuracy: 0.6096 - val_loss: 1.3161 - val_accuracy: 0.5276\n",
      "Epoch 355/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 0.9396 - accuracy: 0.6039 - val_loss: 1.3481 - val_accuracy: 0.5183\n",
      "Epoch 356/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 0.9477 - accuracy: 0.6007 - val_loss: 1.3064 - val_accuracy: 0.5351\n",
      "Epoch 357/1000\n",
      "39/39 [==============================] - 3s 82ms/step - loss: 0.9542 - accuracy: 0.6031 - val_loss: 1.3092 - val_accuracy: 0.5342\n",
      "Epoch 358/1000\n",
      "39/39 [==============================] - 5s 118ms/step - loss: 0.9291 - accuracy: 0.6168 - val_loss: 1.3299 - val_accuracy: 0.4986\n",
      "Epoch 359/1000\n",
      "39/39 [==============================] - 4s 104ms/step - loss: 0.9455 - accuracy: 0.6100 - val_loss: 1.2992 - val_accuracy: 0.5267\n",
      "Epoch 360/1000\n",
      "39/39 [==============================] - 4s 103ms/step - loss: 0.9327 - accuracy: 0.6031 - val_loss: 1.3194 - val_accuracy: 0.5398\n",
      "Epoch 361/1000\n",
      "39/39 [==============================] - 3s 70ms/step - loss: 0.9419 - accuracy: 0.6148 - val_loss: 1.3251 - val_accuracy: 0.5230\n",
      "Epoch 362/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9352 - accuracy: 0.6076 - val_loss: 1.2807 - val_accuracy: 0.5220\n",
      "Epoch 363/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9343 - accuracy: 0.6148 - val_loss: 1.3422 - val_accuracy: 0.5070\n",
      "Epoch 364/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9534 - accuracy: 0.5939 - val_loss: 1.3255 - val_accuracy: 0.5267\n",
      "Epoch 365/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9499 - accuracy: 0.6039 - val_loss: 1.2801 - val_accuracy: 0.5408\n",
      "Epoch 366/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9257 - accuracy: 0.6192 - val_loss: 1.2949 - val_accuracy: 0.5408\n",
      "Epoch 367/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9384 - accuracy: 0.6055 - val_loss: 1.2903 - val_accuracy: 0.5483\n",
      "Epoch 368/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 0.9227 - accuracy: 0.6136 - val_loss: 1.2955 - val_accuracy: 0.5398\n",
      "Epoch 369/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9240 - accuracy: 0.6060 - val_loss: 1.3135 - val_accuracy: 0.5295\n",
      "Epoch 370/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 0.9143 - accuracy: 0.6257 - val_loss: 1.3288 - val_accuracy: 0.5173\n",
      "Epoch 371/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9313 - accuracy: 0.6168 - val_loss: 1.3189 - val_accuracy: 0.5576\n",
      "Epoch 372/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9458 - accuracy: 0.6011 - val_loss: 1.3461 - val_accuracy: 0.5173\n",
      "Epoch 373/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9306 - accuracy: 0.6180 - val_loss: 1.2995 - val_accuracy: 0.5389\n",
      "Epoch 374/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9084 - accuracy: 0.6297 - val_loss: 1.3245 - val_accuracy: 0.5192\n",
      "Epoch 375/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 0.9293 - accuracy: 0.6128 - val_loss: 1.2976 - val_accuracy: 0.5539\n",
      "Epoch 376/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9223 - accuracy: 0.6160 - val_loss: 1.3200 - val_accuracy: 0.5314\n",
      "Epoch 377/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9196 - accuracy: 0.6180 - val_loss: 1.3153 - val_accuracy: 0.5436\n",
      "Epoch 378/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9458 - accuracy: 0.6035 - val_loss: 1.3090 - val_accuracy: 0.5398\n",
      "Epoch 379/1000\n",
      "39/39 [==============================] - 2s 42ms/step - loss: 0.9209 - accuracy: 0.6104 - val_loss: 1.3553 - val_accuracy: 0.5314\n",
      "Epoch 380/1000\n",
      "39/39 [==============================] - 4s 111ms/step - loss: 0.9119 - accuracy: 0.6301 - val_loss: 1.3154 - val_accuracy: 0.5408\n",
      "Epoch 381/1000\n",
      "39/39 [==============================] - 4s 105ms/step - loss: 0.9227 - accuracy: 0.6124 - val_loss: 1.3260 - val_accuracy: 0.5333\n",
      "Epoch 382/1000\n",
      "39/39 [==============================] - 4s 107ms/step - loss: 0.9196 - accuracy: 0.6136 - val_loss: 1.2936 - val_accuracy: 0.5455\n",
      "Epoch 383/1000\n",
      "39/39 [==============================] - 4s 108ms/step - loss: 0.9116 - accuracy: 0.6204 - val_loss: 1.3328 - val_accuracy: 0.5295\n",
      "Epoch 384/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9161 - accuracy: 0.6224 - val_loss: 1.3186 - val_accuracy: 0.5333\n",
      "Epoch 385/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9132 - accuracy: 0.6212 - val_loss: 1.3449 - val_accuracy: 0.5276\n",
      "Epoch 386/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9087 - accuracy: 0.6248 - val_loss: 1.3310 - val_accuracy: 0.5361\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9241 - accuracy: 0.6224 - val_loss: 1.3086 - val_accuracy: 0.5370\n",
      "Epoch 388/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9113 - accuracy: 0.6200 - val_loss: 1.3196 - val_accuracy: 0.5342\n",
      "Epoch 389/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9105 - accuracy: 0.6228 - val_loss: 1.3123 - val_accuracy: 0.5436\n",
      "Epoch 390/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9064 - accuracy: 0.6261 - val_loss: 1.3257 - val_accuracy: 0.5323\n",
      "Epoch 391/1000\n",
      "39/39 [==============================] - 2s 43ms/step - loss: 0.9025 - accuracy: 0.6236 - val_loss: 1.3234 - val_accuracy: 0.5426\n",
      "Epoch 392/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9023 - accuracy: 0.6152 - val_loss: 1.3352 - val_accuracy: 0.5361\n",
      "Epoch 393/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9106 - accuracy: 0.6224 - val_loss: 1.3327 - val_accuracy: 0.5333\n",
      "Epoch 394/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.8778 - accuracy: 0.6413 - val_loss: 1.3239 - val_accuracy: 0.5314\n",
      "Epoch 395/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9310 - accuracy: 0.6112 - val_loss: 1.3243 - val_accuracy: 0.5417\n",
      "Epoch 396/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9218 - accuracy: 0.6309 - val_loss: 1.3332 - val_accuracy: 0.5380\n",
      "Epoch 397/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9051 - accuracy: 0.6108 - val_loss: 1.3317 - val_accuracy: 0.5436\n",
      "Epoch 398/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9163 - accuracy: 0.6140 - val_loss: 1.3178 - val_accuracy: 0.5342\n",
      "Epoch 399/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.9054 - accuracy: 0.6212 - val_loss: 1.3176 - val_accuracy: 0.5530\n",
      "Epoch 400/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.8954 - accuracy: 0.6216 - val_loss: 1.3524 - val_accuracy: 0.5201\n",
      "Epoch 401/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9074 - accuracy: 0.6208 - val_loss: 1.3229 - val_accuracy: 0.5323\n",
      "Epoch 402/1000\n",
      "39/39 [==============================] - 4s 110ms/step - loss: 0.9121 - accuracy: 0.6281 - val_loss: 1.3019 - val_accuracy: 0.5511\n",
      "Epoch 403/1000\n",
      "39/39 [==============================] - 4s 96ms/step - loss: 0.8774 - accuracy: 0.6377 - val_loss: 1.3321 - val_accuracy: 0.5614\n",
      "Epoch 404/1000\n",
      "39/39 [==============================] - 4s 92ms/step - loss: 0.9077 - accuracy: 0.6277 - val_loss: 1.3622 - val_accuracy: 0.5211\n",
      "Epoch 405/1000\n",
      "39/39 [==============================] - 4s 97ms/step - loss: 0.8954 - accuracy: 0.6184 - val_loss: 1.3285 - val_accuracy: 0.5276\n",
      "Epoch 406/1000\n",
      "39/39 [==============================] - 2s 60ms/step - loss: 0.9007 - accuracy: 0.6244 - val_loss: 1.3487 - val_accuracy: 0.5380\n",
      "Epoch 407/1000\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.9177 - accuracy: 0.6104 - val_loss: 1.2875 - val_accuracy: 0.5436\n",
      "Epoch 408/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8894 - accuracy: 0.6365 - val_loss: 1.3654 - val_accuracy: 0.5258\n",
      "Epoch 409/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.8889 - accuracy: 0.6345 - val_loss: 1.3345 - val_accuracy: 0.5351\n",
      "Epoch 410/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.8957 - accuracy: 0.6265 - val_loss: 1.3498 - val_accuracy: 0.5473\n",
      "Epoch 411/1000\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.9044 - accuracy: 0.6172 - val_loss: 1.3291 - val_accuracy: 0.5342\n",
      "Epoch 412/1000\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.9247 - accuracy: 0.6068 - val_loss: 1.3520 - val_accuracy: 0.5248\n",
      "Epoch 413/1000\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.9032 - accuracy: 0.6257 - val_loss: 1.3163 - val_accuracy: 0.5455\n",
      "Epoch 414/1000\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.8828 - accuracy: 0.6297 - val_loss: 1.3388 - val_accuracy: 0.5483\n",
      "Epoch 415/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.9173 - accuracy: 0.6164 - val_loss: 1.3452 - val_accuracy: 0.5267\n",
      "Epoch 416/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.9070 - accuracy: 0.6277 - val_loss: 1.3473 - val_accuracy: 0.5295\n",
      "Epoch 417/1000\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.8942 - accuracy: 0.6273 - val_loss: 1.3212 - val_accuracy: 0.5473\n",
      "Epoch 418/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.9136 - accuracy: 0.6232 - val_loss: 1.3314 - val_accuracy: 0.5417\n",
      "Epoch 419/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8751 - accuracy: 0.6248 - val_loss: 1.3316 - val_accuracy: 0.5445\n",
      "Epoch 420/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8601 - accuracy: 0.6425 - val_loss: 1.3092 - val_accuracy: 0.5511\n",
      "Epoch 421/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8805 - accuracy: 0.6176 - val_loss: 1.3077 - val_accuracy: 0.5595\n",
      "Epoch 422/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8854 - accuracy: 0.6168 - val_loss: 1.3480 - val_accuracy: 0.5342\n",
      "Epoch 423/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8912 - accuracy: 0.6224 - val_loss: 1.3378 - val_accuracy: 0.5351\n",
      "Epoch 424/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.9048 - accuracy: 0.6204 - val_loss: 1.3196 - val_accuracy: 0.5558\n",
      "Epoch 425/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.8753 - accuracy: 0.6361 - val_loss: 1.3319 - val_accuracy: 0.5417\n",
      "Epoch 426/1000\n",
      "39/39 [==============================] - 3s 87ms/step - loss: 0.8900 - accuracy: 0.6305 - val_loss: 1.3084 - val_accuracy: 0.5604\n",
      "Epoch 427/1000\n",
      "39/39 [==============================] - 3s 87ms/step - loss: 0.8869 - accuracy: 0.6333 - val_loss: 1.3458 - val_accuracy: 0.5220\n",
      "Epoch 428/1000\n",
      "39/39 [==============================] - 3s 89ms/step - loss: 0.8785 - accuracy: 0.6317 - val_loss: 1.3165 - val_accuracy: 0.5445\n",
      "Epoch 429/1000\n",
      "39/39 [==============================] - 3s 87ms/step - loss: 0.8860 - accuracy: 0.6309 - val_loss: 1.3341 - val_accuracy: 0.5455\n",
      "Epoch 430/1000\n",
      "39/39 [==============================] - 3s 76ms/step - loss: 0.8959 - accuracy: 0.6240 - val_loss: 1.3136 - val_accuracy: 0.5689\n",
      "Epoch 431/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8587 - accuracy: 0.6446 - val_loss: 1.3506 - val_accuracy: 0.5323\n",
      "Epoch 432/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8911 - accuracy: 0.6281 - val_loss: 1.3322 - val_accuracy: 0.5295\n",
      "Epoch 433/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8809 - accuracy: 0.6265 - val_loss: 1.3242 - val_accuracy: 0.5483\n",
      "Epoch 434/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8716 - accuracy: 0.6281 - val_loss: 1.2902 - val_accuracy: 0.5511\n",
      "Epoch 435/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8818 - accuracy: 0.6361 - val_loss: 1.3653 - val_accuracy: 0.5558\n",
      "Epoch 436/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8786 - accuracy: 0.6220 - val_loss: 1.3103 - val_accuracy: 0.5530\n",
      "Epoch 437/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8823 - accuracy: 0.6228 - val_loss: 1.3422 - val_accuracy: 0.5426\n",
      "Epoch 438/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8609 - accuracy: 0.6437 - val_loss: 1.3416 - val_accuracy: 0.5267\n",
      "Epoch 439/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8756 - accuracy: 0.6289 - val_loss: 1.3451 - val_accuracy: 0.5445\n",
      "Epoch 440/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8729 - accuracy: 0.6345 - val_loss: 1.3134 - val_accuracy: 0.5342\n",
      "Epoch 441/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8608 - accuracy: 0.6389 - val_loss: 1.3352 - val_accuracy: 0.5445\n",
      "Epoch 442/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8866 - accuracy: 0.6172 - val_loss: 1.3080 - val_accuracy: 0.5370\n",
      "Epoch 443/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 36ms/step - loss: 0.8673 - accuracy: 0.6417 - val_loss: 1.3118 - val_accuracy: 0.5436\n",
      "Epoch 444/1000\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.8732 - accuracy: 0.6357 - val_loss: 1.3111 - val_accuracy: 0.5661\n",
      "Epoch 445/1000\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.8610 - accuracy: 0.6329 - val_loss: 1.3220 - val_accuracy: 0.5595\n",
      "Epoch 446/1000\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.8511 - accuracy: 0.6377 - val_loss: 1.3283 - val_accuracy: 0.5455\n",
      "Epoch 447/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8445 - accuracy: 0.6365 - val_loss: 1.3129 - val_accuracy: 0.5595\n",
      "Epoch 448/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8749 - accuracy: 0.6309 - val_loss: 1.3301 - val_accuracy: 0.5436\n",
      "Epoch 449/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8760 - accuracy: 0.6325 - val_loss: 1.3713 - val_accuracy: 0.5248\n",
      "Epoch 450/1000\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.8565 - accuracy: 0.6369 - val_loss: 1.3394 - val_accuracy: 0.5567\n",
      "Epoch 451/1000\n",
      "39/39 [==============================] - 3s 84ms/step - loss: 0.8606 - accuracy: 0.6357 - val_loss: 1.3106 - val_accuracy: 0.5455\n",
      "Epoch 452/1000\n",
      "39/39 [==============================] - 3s 85ms/step - loss: 0.8767 - accuracy: 0.6261 - val_loss: 1.3386 - val_accuracy: 0.5426\n",
      "Epoch 453/1000\n",
      "39/39 [==============================] - 3s 85ms/step - loss: 0.8944 - accuracy: 0.6337 - val_loss: 1.3144 - val_accuracy: 0.5567\n",
      "Epoch 454/1000\n",
      "39/39 [==============================] - 3s 85ms/step - loss: 0.8827 - accuracy: 0.6277 - val_loss: 1.3157 - val_accuracy: 0.5567\n",
      "Epoch 455/1000\n",
      "39/39 [==============================] - 3s 84ms/step - loss: 0.8525 - accuracy: 0.6345 - val_loss: 1.3064 - val_accuracy: 0.5398\n",
      "Epoch 456/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8680 - accuracy: 0.6377 - val_loss: 1.3069 - val_accuracy: 0.5595\n",
      "Epoch 457/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8714 - accuracy: 0.6377 - val_loss: 1.3472 - val_accuracy: 0.5408\n",
      "Epoch 458/1000\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.8561 - accuracy: 0.6433 - val_loss: 1.3070 - val_accuracy: 0.5595\n",
      "Epoch 459/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8627 - accuracy: 0.6433 - val_loss: 1.3696 - val_accuracy: 0.5370\n",
      "Epoch 460/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8877 - accuracy: 0.6353 - val_loss: 1.3190 - val_accuracy: 0.5455\n",
      "Epoch 461/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8655 - accuracy: 0.6486 - val_loss: 1.3149 - val_accuracy: 0.5483\n",
      "Epoch 462/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8679 - accuracy: 0.6321 - val_loss: 1.3377 - val_accuracy: 0.5361\n",
      "Epoch 463/1000\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.8672 - accuracy: 0.6357 - val_loss: 1.3531 - val_accuracy: 0.5455\n",
      "Epoch 464/1000\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.8390 - accuracy: 0.6510 - val_loss: 1.3559 - val_accuracy: 0.5426\n",
      "Epoch 465/1000\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.8524 - accuracy: 0.6478 - val_loss: 1.3415 - val_accuracy: 0.5595\n",
      "Validation Accuracy: 54.077%\n"
     ]
    }
   ],
   "source": [
    "y = Data_train.Emotion\n",
    "X = pd.DataFrame(Data_train.drop(['Emotion','User'], axis = 1))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 123)\n",
    "\n",
    "\n",
    "#Trying adam optimizer\n",
    "model = initModelGRU(X.shape[1], 7, 'softmax')\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    #validation_split = 0.3,\n",
    "    #validation_data = (X_val, y_val),\n",
    "    validation_data = (X_test, y_test),\n",
    "    epochs=1000,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=100,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Result of adam optimizer on test data\n",
    "model_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(\"Validation Accuracy: {:.3f}%\".format(model_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f77d41c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 7_features_train_test_std\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x0000022BFB237EE0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 16.580%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model.save('8_features_train_test')\n",
    "#56%\n",
    "\n",
    "# Plot the accuracy curve for training\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_accuracy'], color='r', label=\"Accuracy\")\n",
    "\n",
    "plt.title(\"Test accuracy\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34208b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 9)]               0         \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (None, 9, 1)             0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 9, 256)            198912    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 16135     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 215,047\n",
      "Trainable params: 215,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "38/38 [==============================] - 4s 47ms/step - loss: 1.9661 - accuracy: 0.1556 - val_loss: 1.9222 - val_accuracy: 0.1762\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.9319 - accuracy: 0.1835 - val_loss: 1.9217 - val_accuracy: 0.1820\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.9220 - accuracy: 0.1811 - val_loss: 1.9028 - val_accuracy: 0.2107\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.9161 - accuracy: 0.1942 - val_loss: 1.9073 - val_accuracy: 0.2165\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.9197 - accuracy: 0.1778 - val_loss: 1.9098 - val_accuracy: 0.2241\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.9153 - accuracy: 0.2074 - val_loss: 1.8978 - val_accuracy: 0.1935\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.9063 - accuracy: 0.1959 - val_loss: 1.8900 - val_accuracy: 0.2414\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.9046 - accuracy: 0.2008 - val_loss: 1.8857 - val_accuracy: 0.2280\n",
      "Epoch 9/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8964 - accuracy: 0.2115 - val_loss: 1.8606 - val_accuracy: 0.2682\n",
      "Epoch 10/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8970 - accuracy: 0.2049 - val_loss: 1.8765 - val_accuracy: 0.2222\n",
      "Epoch 11/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8959 - accuracy: 0.2025 - val_loss: 1.8642 - val_accuracy: 0.2759\n",
      "Epoch 12/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.8876 - accuracy: 0.2354 - val_loss: 1.8639 - val_accuracy: 0.2395\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.8827 - accuracy: 0.2280 - val_loss: 1.8542 - val_accuracy: 0.2510\n",
      "Epoch 14/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8719 - accuracy: 0.2255 - val_loss: 1.8634 - val_accuracy: 0.2490\n",
      "Epoch 15/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8747 - accuracy: 0.2337 - val_loss: 1.8859 - val_accuracy: 0.2126\n",
      "Epoch 16/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8710 - accuracy: 0.2494 - val_loss: 1.8212 - val_accuracy: 0.2682\n",
      "Epoch 17/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8537 - accuracy: 0.2502 - val_loss: 1.8272 - val_accuracy: 0.2414\n",
      "Epoch 18/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.8570 - accuracy: 0.2519 - val_loss: 1.8242 - val_accuracy: 0.2625\n",
      "Epoch 19/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8554 - accuracy: 0.2510 - val_loss: 1.8168 - val_accuracy: 0.3161\n",
      "Epoch 20/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8521 - accuracy: 0.2494 - val_loss: 1.8458 - val_accuracy: 0.2816\n",
      "Epoch 21/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.8397 - accuracy: 0.2486 - val_loss: 1.8150 - val_accuracy: 0.2778\n",
      "Epoch 22/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8284 - accuracy: 0.2724 - val_loss: 1.8165 - val_accuracy: 0.2931\n",
      "Epoch 23/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8334 - accuracy: 0.2576 - val_loss: 1.8035 - val_accuracy: 0.2816\n",
      "Epoch 24/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8292 - accuracy: 0.2626 - val_loss: 1.8061 - val_accuracy: 0.2720\n",
      "Epoch 25/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8171 - accuracy: 0.2642 - val_loss: 1.7945 - val_accuracy: 0.3027\n",
      "Epoch 26/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8026 - accuracy: 0.2840 - val_loss: 1.7890 - val_accuracy: 0.2701\n",
      "Epoch 27/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.7913 - accuracy: 0.2955 - val_loss: 1.7922 - val_accuracy: 0.2989\n",
      "Epoch 28/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.7942 - accuracy: 0.2856 - val_loss: 1.7721 - val_accuracy: 0.2778\n",
      "Epoch 29/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7994 - accuracy: 0.2733 - val_loss: 1.8004 - val_accuracy: 0.3046\n",
      "Epoch 30/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7787 - accuracy: 0.2922 - val_loss: 1.7713 - val_accuracy: 0.2950\n",
      "Epoch 31/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7845 - accuracy: 0.2765 - val_loss: 1.7789 - val_accuracy: 0.3372\n",
      "Epoch 32/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.7715 - accuracy: 0.2914 - val_loss: 1.7928 - val_accuracy: 0.2739\n",
      "Epoch 33/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7793 - accuracy: 0.2782 - val_loss: 1.7694 - val_accuracy: 0.2931\n",
      "Epoch 34/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7575 - accuracy: 0.3111 - val_loss: 1.7505 - val_accuracy: 0.2874\n",
      "Epoch 35/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7412 - accuracy: 0.2947 - val_loss: 1.7608 - val_accuracy: 0.3142\n",
      "Epoch 36/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7309 - accuracy: 0.3062 - val_loss: 1.7236 - val_accuracy: 0.2912\n",
      "Epoch 37/1000\n",
      "38/38 [==============================] - 1s 40ms/step - loss: 1.7269 - accuracy: 0.3062 - val_loss: 1.7549 - val_accuracy: 0.2893\n",
      "Epoch 38/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.7238 - accuracy: 0.3045 - val_loss: 1.7565 - val_accuracy: 0.2893\n",
      "Epoch 39/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.7044 - accuracy: 0.3095 - val_loss: 1.7531 - val_accuracy: 0.2605\n",
      "Epoch 40/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.7036 - accuracy: 0.3226 - val_loss: 1.7157 - val_accuracy: 0.3276\n",
      "Epoch 41/1000\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 1.6841 - accuracy: 0.3144 - val_loss: 1.6986 - val_accuracy: 0.3142\n",
      "Epoch 42/1000\n",
      "38/38 [==============================] - 2s 48ms/step - loss: 1.6689 - accuracy: 0.3300 - val_loss: 1.7188 - val_accuracy: 0.3276\n",
      "Epoch 43/1000\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 1.6689 - accuracy: 0.3185 - val_loss: 1.6751 - val_accuracy: 0.3525\n",
      "Epoch 44/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.6648 - accuracy: 0.3267 - val_loss: 1.6855 - val_accuracy: 0.3257\n",
      "Epoch 45/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.6372 - accuracy: 0.3366 - val_loss: 1.6817 - val_accuracy: 0.3276\n",
      "Epoch 46/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.6425 - accuracy: 0.3267 - val_loss: 1.6552 - val_accuracy: 0.3640\n",
      "Epoch 47/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.6398 - accuracy: 0.3317 - val_loss: 1.6644 - val_accuracy: 0.3391\n",
      "Epoch 48/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.6132 - accuracy: 0.3481 - val_loss: 1.6434 - val_accuracy: 0.3716\n",
      "Epoch 49/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.5937 - accuracy: 0.3597 - val_loss: 1.6387 - val_accuracy: 0.3391\n",
      "Epoch 50/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 36ms/step - loss: 1.5942 - accuracy: 0.3457 - val_loss: 1.6051 - val_accuracy: 0.3525\n",
      "Epoch 51/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.5897 - accuracy: 0.3449 - val_loss: 1.6380 - val_accuracy: 0.3429\n",
      "Epoch 52/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.5639 - accuracy: 0.3728 - val_loss: 1.5930 - val_accuracy: 0.3544\n",
      "Epoch 53/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.5433 - accuracy: 0.3720 - val_loss: 1.6207 - val_accuracy: 0.3640\n",
      "Epoch 54/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5675 - accuracy: 0.3663 - val_loss: 1.6187 - val_accuracy: 0.3602\n",
      "Epoch 55/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5494 - accuracy: 0.3770 - val_loss: 1.5902 - val_accuracy: 0.3755\n",
      "Epoch 56/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.5262 - accuracy: 0.3712 - val_loss: 1.5532 - val_accuracy: 0.3640\n",
      "Epoch 57/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5206 - accuracy: 0.3761 - val_loss: 1.5460 - val_accuracy: 0.4023\n",
      "Epoch 58/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5175 - accuracy: 0.4016 - val_loss: 1.5668 - val_accuracy: 0.3602\n",
      "Epoch 59/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5154 - accuracy: 0.3860 - val_loss: 1.5388 - val_accuracy: 0.3774\n",
      "Epoch 60/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5000 - accuracy: 0.3893 - val_loss: 1.5381 - val_accuracy: 0.3774\n",
      "Epoch 61/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4843 - accuracy: 0.4123 - val_loss: 1.5952 - val_accuracy: 0.3238\n",
      "Epoch 62/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4773 - accuracy: 0.3959 - val_loss: 1.5598 - val_accuracy: 0.3448\n",
      "Epoch 63/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4781 - accuracy: 0.4074 - val_loss: 1.4844 - val_accuracy: 0.4272\n",
      "Epoch 64/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4428 - accuracy: 0.3992 - val_loss: 1.5117 - val_accuracy: 0.4368\n",
      "Epoch 65/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4390 - accuracy: 0.3926 - val_loss: 1.5630 - val_accuracy: 0.3927\n",
      "Epoch 66/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4525 - accuracy: 0.3951 - val_loss: 1.5329 - val_accuracy: 0.3621\n",
      "Epoch 67/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4327 - accuracy: 0.4288 - val_loss: 1.5145 - val_accuracy: 0.3870\n",
      "Epoch 68/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4532 - accuracy: 0.3934 - val_loss: 1.4805 - val_accuracy: 0.4330\n",
      "Epoch 69/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4135 - accuracy: 0.4313 - val_loss: 1.4607 - val_accuracy: 0.4253\n",
      "Epoch 70/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4071 - accuracy: 0.4214 - val_loss: 1.5036 - val_accuracy: 0.4042\n",
      "Epoch 71/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4097 - accuracy: 0.4239 - val_loss: 1.4817 - val_accuracy: 0.4119\n",
      "Epoch 72/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4084 - accuracy: 0.4091 - val_loss: 1.5304 - val_accuracy: 0.3870\n",
      "Epoch 73/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.3759 - accuracy: 0.4535 - val_loss: 1.4497 - val_accuracy: 0.4138\n",
      "Epoch 74/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3731 - accuracy: 0.4362 - val_loss: 1.4643 - val_accuracy: 0.4330\n",
      "Epoch 75/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3753 - accuracy: 0.4576 - val_loss: 1.4655 - val_accuracy: 0.4368\n",
      "Epoch 76/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3693 - accuracy: 0.4502 - val_loss: 1.4518 - val_accuracy: 0.4425\n",
      "Epoch 77/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3566 - accuracy: 0.4436 - val_loss: 1.4169 - val_accuracy: 0.4176\n",
      "Epoch 78/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.3651 - accuracy: 0.4387 - val_loss: 1.4515 - val_accuracy: 0.4004\n",
      "Epoch 79/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.3593 - accuracy: 0.4543 - val_loss: 1.4112 - val_accuracy: 0.4579\n",
      "Epoch 80/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.3385 - accuracy: 0.4543 - val_loss: 1.4286 - val_accuracy: 0.4502\n",
      "Epoch 81/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3449 - accuracy: 0.4568 - val_loss: 1.4086 - val_accuracy: 0.4272\n",
      "Epoch 82/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3381 - accuracy: 0.4601 - val_loss: 1.4298 - val_accuracy: 0.4540\n",
      "Epoch 83/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.3181 - accuracy: 0.4708 - val_loss: 1.3983 - val_accuracy: 0.4655\n",
      "Epoch 84/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.3264 - accuracy: 0.4658 - val_loss: 1.4243 - val_accuracy: 0.4004\n",
      "Epoch 85/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.3292 - accuracy: 0.4543 - val_loss: 1.4357 - val_accuracy: 0.4310\n",
      "Epoch 86/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.2780 - accuracy: 0.4872 - val_loss: 1.3853 - val_accuracy: 0.4406\n",
      "Epoch 87/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2921 - accuracy: 0.4675 - val_loss: 1.4128 - val_accuracy: 0.4272\n",
      "Epoch 88/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2789 - accuracy: 0.4765 - val_loss: 1.4092 - val_accuracy: 0.4444\n",
      "Epoch 89/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.2640 - accuracy: 0.4947 - val_loss: 1.3904 - val_accuracy: 0.4732\n",
      "Epoch 90/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2964 - accuracy: 0.4642 - val_loss: 1.4073 - val_accuracy: 0.4655\n",
      "Epoch 91/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2739 - accuracy: 0.4782 - val_loss: 1.3893 - val_accuracy: 0.4425\n",
      "Epoch 92/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.2584 - accuracy: 0.4930 - val_loss: 1.4007 - val_accuracy: 0.4444\n",
      "Epoch 93/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2714 - accuracy: 0.4848 - val_loss: 1.3558 - val_accuracy: 0.4847\n",
      "Epoch 94/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2566 - accuracy: 0.4938 - val_loss: 1.3715 - val_accuracy: 0.4713\n",
      "Epoch 95/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.2834 - accuracy: 0.4757 - val_loss: 1.3602 - val_accuracy: 0.4770\n",
      "Epoch 96/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.2656 - accuracy: 0.4864 - val_loss: 1.3667 - val_accuracy: 0.4713\n",
      "Epoch 97/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.2624 - accuracy: 0.4905 - val_loss: 1.3592 - val_accuracy: 0.4483\n",
      "Epoch 98/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.2294 - accuracy: 0.4996 - val_loss: 1.3742 - val_accuracy: 0.4464\n",
      "Epoch 99/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.2351 - accuracy: 0.4971 - val_loss: 1.3108 - val_accuracy: 0.4962\n",
      "Epoch 100/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2187 - accuracy: 0.5045 - val_loss: 1.2828 - val_accuracy: 0.5172\n",
      "Epoch 101/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.2010 - accuracy: 0.5021 - val_loss: 1.3359 - val_accuracy: 0.4483\n",
      "Epoch 102/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2150 - accuracy: 0.5029 - val_loss: 1.3436 - val_accuracy: 0.4674\n",
      "Epoch 103/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.2199 - accuracy: 0.5226 - val_loss: 1.3288 - val_accuracy: 0.4981\n",
      "Epoch 104/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.2127 - accuracy: 0.5103 - val_loss: 1.3377 - val_accuracy: 0.4866\n",
      "Epoch 105/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.1954 - accuracy: 0.5119 - val_loss: 1.3275 - val_accuracy: 0.4713\n",
      "Epoch 106/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.1776 - accuracy: 0.5226 - val_loss: 1.3134 - val_accuracy: 0.5057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2008 - accuracy: 0.5053 - val_loss: 1.3129 - val_accuracy: 0.4866\n",
      "Epoch 108/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1968 - accuracy: 0.5251 - val_loss: 1.2973 - val_accuracy: 0.4789\n",
      "Epoch 109/1000\n",
      "38/38 [==============================] - 2s 57ms/step - loss: 1.1777 - accuracy: 0.5136 - val_loss: 1.3076 - val_accuracy: 0.5077\n",
      "Epoch 110/1000\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.1519 - accuracy: 0.5284 - val_loss: 1.3027 - val_accuracy: 0.5077\n",
      "Epoch 111/1000\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 1.1545 - accuracy: 0.5333 - val_loss: 1.3478 - val_accuracy: 0.5096\n",
      "Epoch 112/1000\n",
      "38/38 [==============================] - 3s 92ms/step - loss: 1.1566 - accuracy: 0.5202 - val_loss: 1.3114 - val_accuracy: 0.4981\n",
      "Epoch 113/1000\n",
      "38/38 [==============================] - 3s 84ms/step - loss: 1.1667 - accuracy: 0.5284 - val_loss: 1.2720 - val_accuracy: 0.5268\n",
      "Epoch 114/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.1552 - accuracy: 0.5350 - val_loss: 1.2924 - val_accuracy: 0.5268\n",
      "Epoch 115/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.1688 - accuracy: 0.5202 - val_loss: 1.2600 - val_accuracy: 0.5230\n",
      "Epoch 116/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1511 - accuracy: 0.5235 - val_loss: 1.2568 - val_accuracy: 0.5249\n",
      "Epoch 117/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1509 - accuracy: 0.5465 - val_loss: 1.2540 - val_accuracy: 0.5172\n",
      "Epoch 118/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1255 - accuracy: 0.5440 - val_loss: 1.3337 - val_accuracy: 0.5038\n",
      "Epoch 119/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.1638 - accuracy: 0.5243 - val_loss: 1.2599 - val_accuracy: 0.5192\n",
      "Epoch 120/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1287 - accuracy: 0.5440 - val_loss: 1.3064 - val_accuracy: 0.4904\n",
      "Epoch 121/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.1218 - accuracy: 0.5374 - val_loss: 1.2939 - val_accuracy: 0.4904\n",
      "Epoch 122/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.1298 - accuracy: 0.5391 - val_loss: 1.3516 - val_accuracy: 0.5000\n",
      "Epoch 123/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1211 - accuracy: 0.5547 - val_loss: 1.2625 - val_accuracy: 0.5268\n",
      "Epoch 124/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0960 - accuracy: 0.5613 - val_loss: 1.3190 - val_accuracy: 0.4904\n",
      "Epoch 125/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1141 - accuracy: 0.5547 - val_loss: 1.2439 - val_accuracy: 0.5441\n",
      "Epoch 126/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1070 - accuracy: 0.5440 - val_loss: 1.2560 - val_accuracy: 0.5192\n",
      "Epoch 127/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1127 - accuracy: 0.5424 - val_loss: 1.3472 - val_accuracy: 0.4962\n",
      "Epoch 128/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1242 - accuracy: 0.5597 - val_loss: 1.2408 - val_accuracy: 0.5460\n",
      "Epoch 129/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.0925 - accuracy: 0.5646 - val_loss: 1.3133 - val_accuracy: 0.5000\n",
      "Epoch 130/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1287 - accuracy: 0.5399 - val_loss: 1.2655 - val_accuracy: 0.5077\n",
      "Epoch 131/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.1264 - accuracy: 0.5284 - val_loss: 1.2549 - val_accuracy: 0.5498\n",
      "Epoch 132/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.1118 - accuracy: 0.5490 - val_loss: 1.2450 - val_accuracy: 0.5498\n",
      "Epoch 133/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.0891 - accuracy: 0.5588 - val_loss: 1.3179 - val_accuracy: 0.5153\n",
      "Epoch 134/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0706 - accuracy: 0.5539 - val_loss: 1.2552 - val_accuracy: 0.5402\n",
      "Epoch 135/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1007 - accuracy: 0.5547 - val_loss: 1.2381 - val_accuracy: 0.5268\n",
      "Epoch 136/1000\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 1.1005 - accuracy: 0.5473 - val_loss: 1.2956 - val_accuracy: 0.4828\n",
      "Epoch 137/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.0820 - accuracy: 0.5350 - val_loss: 1.2561 - val_accuracy: 0.5287\n",
      "Epoch 138/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0846 - accuracy: 0.5317 - val_loss: 1.2588 - val_accuracy: 0.5517\n",
      "Epoch 139/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.0544 - accuracy: 0.5770 - val_loss: 1.2545 - val_accuracy: 0.5211\n",
      "Epoch 140/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.0725 - accuracy: 0.5737 - val_loss: 1.2638 - val_accuracy: 0.5134\n",
      "Epoch 141/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0633 - accuracy: 0.5580 - val_loss: 1.2467 - val_accuracy: 0.5307\n",
      "Epoch 142/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0681 - accuracy: 0.5588 - val_loss: 1.2845 - val_accuracy: 0.5211\n",
      "Epoch 143/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.0552 - accuracy: 0.5506 - val_loss: 1.2927 - val_accuracy: 0.5230\n",
      "Epoch 144/1000\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 1.0753 - accuracy: 0.5490 - val_loss: 1.2338 - val_accuracy: 0.5479\n",
      "Epoch 145/1000\n",
      "38/38 [==============================] - 2s 43ms/step - loss: 1.0703 - accuracy: 0.5564 - val_loss: 1.2353 - val_accuracy: 0.5230\n",
      "Epoch 146/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.0432 - accuracy: 0.5687 - val_loss: 1.2340 - val_accuracy: 0.5460\n",
      "Epoch 147/1000\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 1.0201 - accuracy: 0.5638 - val_loss: 1.2059 - val_accuracy: 0.5364\n",
      "Epoch 148/1000\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 1.0312 - accuracy: 0.5794 - val_loss: 1.2329 - val_accuracy: 0.5326\n",
      "Epoch 149/1000\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 1.0429 - accuracy: 0.5794 - val_loss: 1.2605 - val_accuracy: 0.5307\n",
      "Epoch 150/1000\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 1.0575 - accuracy: 0.5605 - val_loss: 1.2892 - val_accuracy: 0.5230\n",
      "Epoch 151/1000\n",
      "38/38 [==============================] - 3s 82ms/step - loss: 1.0228 - accuracy: 0.5868 - val_loss: 1.2095 - val_accuracy: 0.5517\n",
      "Epoch 152/1000\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 1.0542 - accuracy: 0.5712 - val_loss: 1.2583 - val_accuracy: 0.5211\n",
      "Epoch 153/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.0466 - accuracy: 0.5621 - val_loss: 1.2808 - val_accuracy: 0.5268\n",
      "Epoch 154/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.0291 - accuracy: 0.5753 - val_loss: 1.2825 - val_accuracy: 0.5192\n",
      "Epoch 155/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0197 - accuracy: 0.5745 - val_loss: 1.2422 - val_accuracy: 0.5402\n",
      "Epoch 156/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0166 - accuracy: 0.5663 - val_loss: 1.2389 - val_accuracy: 0.5670\n",
      "Epoch 157/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.0266 - accuracy: 0.5770 - val_loss: 1.2478 - val_accuracy: 0.5172\n",
      "Epoch 158/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0267 - accuracy: 0.5613 - val_loss: 1.2382 - val_accuracy: 0.5460\n",
      "Epoch 159/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0198 - accuracy: 0.5737 - val_loss: 1.2647 - val_accuracy: 0.5287\n",
      "Epoch 160/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0273 - accuracy: 0.5802 - val_loss: 1.2397 - val_accuracy: 0.5345\n",
      "Epoch 161/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0164 - accuracy: 0.5819 - val_loss: 1.2616 - val_accuracy: 0.5268\n",
      "Epoch 162/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9815 - accuracy: 0.5951 - val_loss: 1.2715 - val_accuracy: 0.5479\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9969 - accuracy: 0.5753 - val_loss: 1.2420 - val_accuracy: 0.5556\n",
      "Epoch 164/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0304 - accuracy: 0.5728 - val_loss: 1.2265 - val_accuracy: 0.5441\n",
      "Epoch 165/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.0132 - accuracy: 0.5844 - val_loss: 1.2195 - val_accuracy: 0.5862\n",
      "Epoch 166/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0023 - accuracy: 0.5802 - val_loss: 1.2264 - val_accuracy: 0.5536\n",
      "Epoch 167/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.0126 - accuracy: 0.5737 - val_loss: 1.2459 - val_accuracy: 0.5077\n",
      "Epoch 168/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9591 - accuracy: 0.5926 - val_loss: 1.2415 - val_accuracy: 0.5517\n",
      "Epoch 169/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9744 - accuracy: 0.5893 - val_loss: 1.2400 - val_accuracy: 0.5556\n",
      "Epoch 170/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9802 - accuracy: 0.5901 - val_loss: 1.2125 - val_accuracy: 0.5651\n",
      "Epoch 171/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9986 - accuracy: 0.5860 - val_loss: 1.2370 - val_accuracy: 0.5728\n",
      "Epoch 172/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9966 - accuracy: 0.5695 - val_loss: 1.2548 - val_accuracy: 0.5479\n",
      "Epoch 173/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.0015 - accuracy: 0.5720 - val_loss: 1.2497 - val_accuracy: 0.5556\n",
      "Epoch 174/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.9670 - accuracy: 0.5877 - val_loss: 1.2200 - val_accuracy: 0.5613\n",
      "Epoch 175/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9572 - accuracy: 0.6099 - val_loss: 1.2546 - val_accuracy: 0.5613\n",
      "Epoch 176/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9871 - accuracy: 0.5827 - val_loss: 1.2441 - val_accuracy: 0.5536\n",
      "Epoch 177/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9680 - accuracy: 0.5959 - val_loss: 1.2285 - val_accuracy: 0.5785\n",
      "Epoch 178/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9736 - accuracy: 0.6049 - val_loss: 1.2644 - val_accuracy: 0.5613\n",
      "Epoch 179/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9641 - accuracy: 0.6016 - val_loss: 1.3206 - val_accuracy: 0.5498\n",
      "Epoch 180/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9605 - accuracy: 0.6091 - val_loss: 1.2341 - val_accuracy: 0.5747\n",
      "Epoch 181/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9496 - accuracy: 0.6033 - val_loss: 1.2518 - val_accuracy: 0.5747\n",
      "Epoch 182/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.9524 - accuracy: 0.6148 - val_loss: 1.2432 - val_accuracy: 0.5441\n",
      "Epoch 183/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.9716 - accuracy: 0.5835 - val_loss: 1.2157 - val_accuracy: 0.5651\n",
      "Epoch 184/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9385 - accuracy: 0.6156 - val_loss: 1.2059 - val_accuracy: 0.5785\n",
      "Epoch 185/1000\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.9583 - accuracy: 0.6140 - val_loss: 1.1834 - val_accuracy: 0.5728\n",
      "Epoch 186/1000\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 0.9726 - accuracy: 0.5918 - val_loss: 1.1975 - val_accuracy: 0.5709\n",
      "Epoch 187/1000\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.9400 - accuracy: 0.5909 - val_loss: 1.2023 - val_accuracy: 0.5613\n",
      "Epoch 188/1000\n",
      "38/38 [==============================] - 3s 83ms/step - loss: 0.9652 - accuracy: 0.5992 - val_loss: 1.2433 - val_accuracy: 0.5632\n",
      "Epoch 189/1000\n",
      "38/38 [==============================] - 4s 93ms/step - loss: 0.9928 - accuracy: 0.5852 - val_loss: 1.2802 - val_accuracy: 0.5383\n",
      "Epoch 190/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9612 - accuracy: 0.5819 - val_loss: 1.1950 - val_accuracy: 0.5766\n",
      "Epoch 191/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9697 - accuracy: 0.5901 - val_loss: 1.2398 - val_accuracy: 0.5441\n",
      "Epoch 192/1000\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.9453 - accuracy: 0.6033 - val_loss: 1.2272 - val_accuracy: 0.5709\n",
      "Epoch 193/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9606 - accuracy: 0.6173 - val_loss: 1.2493 - val_accuracy: 0.5805\n",
      "Epoch 194/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9383 - accuracy: 0.6049 - val_loss: 1.1945 - val_accuracy: 0.5632\n",
      "Epoch 195/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.9598 - accuracy: 0.5959 - val_loss: 1.2030 - val_accuracy: 0.5843\n",
      "Epoch 196/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.9407 - accuracy: 0.6049 - val_loss: 1.2183 - val_accuracy: 0.5900\n",
      "Epoch 197/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.9099 - accuracy: 0.6165 - val_loss: 1.1710 - val_accuracy: 0.5958\n",
      "Epoch 198/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9545 - accuracy: 0.6058 - val_loss: 1.2426 - val_accuracy: 0.5498\n",
      "Epoch 199/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.9410 - accuracy: 0.5959 - val_loss: 1.2218 - val_accuracy: 0.5556\n",
      "Epoch 200/1000\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.9250 - accuracy: 0.6058 - val_loss: 1.2301 - val_accuracy: 0.5651\n",
      "Epoch 201/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9173 - accuracy: 0.6247 - val_loss: 1.2187 - val_accuracy: 0.5843\n",
      "Epoch 202/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9334 - accuracy: 0.6099 - val_loss: 1.2843 - val_accuracy: 0.5421\n",
      "Epoch 203/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9277 - accuracy: 0.6140 - val_loss: 1.2395 - val_accuracy: 0.5613\n",
      "Epoch 204/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9284 - accuracy: 0.6082 - val_loss: 1.1955 - val_accuracy: 0.5728\n",
      "Epoch 205/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.9155 - accuracy: 0.6189 - val_loss: 1.2985 - val_accuracy: 0.5383\n",
      "Epoch 206/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9458 - accuracy: 0.6058 - val_loss: 1.1895 - val_accuracy: 0.5785\n",
      "Epoch 207/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8789 - accuracy: 0.6362 - val_loss: 1.1923 - val_accuracy: 0.5900\n",
      "Epoch 208/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9195 - accuracy: 0.6132 - val_loss: 1.2108 - val_accuracy: 0.5594\n",
      "Epoch 209/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9222 - accuracy: 0.6189 - val_loss: 1.2136 - val_accuracy: 0.5747\n",
      "Epoch 210/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8959 - accuracy: 0.6255 - val_loss: 1.1964 - val_accuracy: 0.5824\n",
      "Epoch 211/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9292 - accuracy: 0.6016 - val_loss: 1.1987 - val_accuracy: 0.5575\n",
      "Epoch 212/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9126 - accuracy: 0.6025 - val_loss: 1.2278 - val_accuracy: 0.5709\n",
      "Epoch 213/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9079 - accuracy: 0.6370 - val_loss: 1.2206 - val_accuracy: 0.5747\n",
      "Epoch 214/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8949 - accuracy: 0.6091 - val_loss: 1.1984 - val_accuracy: 0.5766\n",
      "Epoch 215/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8658 - accuracy: 0.6403 - val_loss: 1.2174 - val_accuracy: 0.5805\n",
      "Epoch 216/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8831 - accuracy: 0.6239 - val_loss: 1.2579 - val_accuracy: 0.5402\n",
      "Epoch 217/1000\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.9174 - accuracy: 0.6272 - val_loss: 1.2453 - val_accuracy: 0.5824\n",
      "Epoch 218/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9270 - accuracy: 0.6041 - val_loss: 1.2090 - val_accuracy: 0.5632\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8975 - accuracy: 0.6255 - val_loss: 1.1933 - val_accuracy: 0.6054\n",
      "Epoch 220/1000\n",
      "38/38 [==============================] - 2s 47ms/step - loss: 0.8827 - accuracy: 0.6362 - val_loss: 1.2186 - val_accuracy: 0.5747\n",
      "Epoch 221/1000\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 0.8770 - accuracy: 0.6370 - val_loss: 1.2194 - val_accuracy: 0.5690\n",
      "Epoch 222/1000\n",
      "15/38 [==========>...................] - ETA: 2s - loss: 0.8732 - accuracy: 0.6542"
     ]
    }
   ],
   "source": [
    "y_val = Data_val.Emotion\n",
    "X_val = pd.DataFrame(Data_val.drop(['Emotion', 'User'], axis = 1))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(X_val, y_val, test_size = 0.3, random_state = 123)\n",
    "\n",
    "\n",
    "#Trying adam optimizer\n",
    "modelVal = initModelGRU(X.shape[1], 7, 'softmax')\n",
    "modelVal.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "historyVal = modelVal.fit(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    validation_data = (X_test_val, y_test_val),\n",
    "    epochs=1000,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=100,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Result of adam optimizer on validation data\n",
    "model_acc = modelVal.evaluate(X_test_val, y_test_val, verbose=0)[1]\n",
    "print(\"Validation Accuracy: {:.3f}%\".format(model_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed81f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy curve for validation set\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(historyVal.history['val_accuracy'], color='r', label=\"Accuracy\")\n",
    "\n",
    "plt.title(\"Val accuracy\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b225588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict = model.predict(X_test)[0]\n",
    "# predict = [int(pre >= 0.5) for pre in predict]\n",
    "# print(predict)\n",
    "# y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e5e15a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
