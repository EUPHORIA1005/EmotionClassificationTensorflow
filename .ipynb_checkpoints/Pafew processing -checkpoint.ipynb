{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8778ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.signal import medfilt\n",
    "from scipy.signal import wiener\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "genders = ['male', 'female']\n",
    "labels = ['Happy', 'Surprise', 'Disgust', 'Angry', 'Fear', 'Sad', 'Neutral'] # 0-6, 7 classes\n",
    "\n",
    "def preprocess_data(dataPath, train):\n",
    "    if train:\n",
    "        path = os.path.join(dataPath, 'train')\n",
    "        output_dir = os.path.join(dataPath, 'train.csv')\n",
    "    else:\n",
    "        path = os.path.join(dataPath, 'val')\n",
    "        output_dir = os.path.join(dataPath, 'val.csv')\n",
    "    folders = glob.glob(os.path.join(path, '*'))\n",
    "    folders.sort()\n",
    "\n",
    "    with open(output_dir, 'a+') as csv_output_file:\n",
    "        fieldnames = ['User', 'Max', 'Min', 'Mean', 'Var', 'Mean Abs Diff', 'Mean Abs Second Diff', 'Emotion', 'Gender', 'Age'] # The features extracted\n",
    "        writer = csv.DictWriter(csv_output_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for dir in folders:\n",
    "            with open(os.path.join(dir, 'EDA.csv')) as csv_file:\n",
    "                csv_reader = csv.reader(csv_file)\n",
    "                line_count = 0\n",
    "                data = [] # all data for one person\n",
    "                time_stamp = [] # time stamp for each item\n",
    "\n",
    "                for row in csv_reader:\n",
    "                    if line_count == 0:\n",
    "                        start_time = float(row[0])\n",
    "                    elif line_count == 1:\n",
    "                        freq = float(row[0])\n",
    "                    elif line_count>2 :\n",
    "                        data.append(float(row[0]))\n",
    "                        time_stamp.append(start_time + float((line_count-2)/freq))\n",
    "                    line_count += 1\n",
    "\n",
    "                person_Max = max(data)\n",
    "                person_Min = min(data)\n",
    "                data = (data - np.average(data)) / (np.std(data))\n",
    "                #data = (np.array(data) - float(person_Min)) / (float(person_Max) - float(person_Min)) # normalised data for each person\n",
    "                #data = medfilt(data, 11) # median filter; can be substituted by your preprocessing methods\n",
    "                #data = wiener(data)\n",
    "                #data = savgol_filter(data, 11, 5)\n",
    "                \n",
    "                \n",
    "                log = open(os.path.join(dir, 'log.txt'), 'r')\n",
    "                log_count = 0\n",
    "                for line in log:\n",
    "                    if log_count == 0:\n",
    "                        user = line.split(';')[0].split(':')[-1]\n",
    "                        age = line.split(';')[1].split(':')[-1]\n",
    "                        gender = line.split(';')[2].split(':')[-1]\n",
    "                        gender = genders.index(gender.lower())\n",
    "                        log_count += 1\n",
    "                    elif log_count == 1:\n",
    "                        log_count += 1\n",
    "                    else:\n",
    "                        st = float(line.split(';')[1]) # start time of each video\n",
    "                        et = float(line.split(';')[3]) # end time of each video\n",
    "                        video_name = line.split(';')[2]\n",
    "                        if \"_\" in video_name:\n",
    "                            emotion_label = line.split(';')[2].split('.')[0][:-10] # emotion label of each video\n",
    "                        else:\n",
    "                            emotion_label = line.split(';')[2].split('.')[0][:-9]  # emotion label of each video\n",
    "                        emotion_label = labels.index(emotion_label)\n",
    "\n",
    "                        index = np.where(np.logical_and((np.array(time_stamp) >= st), (np.array(time_stamp) <= et)))\n",
    "                        data_list = data[index[0]]\n",
    "                        if len(data_list)== 0:\n",
    "                            break\n",
    "                        diff_list = [data_list[k+1]-data_list[k] for k in range(len(data_list)-1)]\n",
    "                        abs_diff_list = abs(np.array(diff_list))\n",
    "                        second_diff_list = [diff_list[k + 1] - diff_list[k] for k in range(len(diff_list) - 1)]\n",
    "                        abs_second_diff_list = abs(np.array(second_diff_list))\n",
    "                        writer.writerow({'User': user, 'Max': max(data_list), 'Min': min(data_list), 'Mean': np.mean(data_list), 'Var': np.var(data_list), 'Mean Abs Diff': np.mean(abs_diff_list), 'Mean Abs Second Diff': np.mean(abs_second_diff_list),'Emotion': emotion_label, 'Gender': gender, 'Age': age})\n",
    "                log.close()\n",
    "        csv_file.close()\n",
    "    csv_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8285489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('train.csv')\n",
    "preprocess_data('', train=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6ae3c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('val.csv')\n",
    "preprocess_data('', train=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c8d0773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Var</th>\n",
       "      <th>Mean Abs Diff</th>\n",
       "      <th>Mean Abs Second Diff</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.520489</td>\n",
       "      <td>-0.542106</td>\n",
       "      <td>-0.529405</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.004416</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.442954</td>\n",
       "      <td>-0.485496</td>\n",
       "      <td>-0.471871</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>0.614217</td>\n",
       "      <td>0.507834</td>\n",
       "      <td>0.558740</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.511215</td>\n",
       "      <td>-0.532292</td>\n",
       "      <td>-0.519594</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.504624</td>\n",
       "      <td>-0.522588</td>\n",
       "      <td>-0.515194</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.003052</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>2.273096</td>\n",
       "      <td>2.098047</td>\n",
       "      <td>2.183685</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>0.006794</td>\n",
       "      <td>0.004437</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.513287</td>\n",
       "      <td>-0.529233</td>\n",
       "      <td>-0.521472</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.003480</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.429913</td>\n",
       "      <td>-0.448014</td>\n",
       "      <td>-0.439103</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.510839</td>\n",
       "      <td>-0.529026</td>\n",
       "      <td>-0.520874</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.526523</td>\n",
       "      <td>-0.541121</td>\n",
       "      <td>-0.534539</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>1.403413</td>\n",
       "      <td>1.035899</td>\n",
       "      <td>1.179660</td>\n",
       "      <td>0.008842</td>\n",
       "      <td>0.012267</td>\n",
       "      <td>0.010535</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>0.051704</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.025427</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.534544</td>\n",
       "      <td>-0.544359</td>\n",
       "      <td>-0.538806</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.521477</td>\n",
       "      <td>-0.535377</td>\n",
       "      <td>-0.528569</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.517708</td>\n",
       "      <td>-0.533571</td>\n",
       "      <td>-0.524666</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.379641</td>\n",
       "      <td>-0.481713</td>\n",
       "      <td>-0.439345</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.003615</td>\n",
       "      <td>0.003459</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.532277</td>\n",
       "      <td>-0.549362</td>\n",
       "      <td>-0.541271</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.270155</td>\n",
       "      <td>-0.303399</td>\n",
       "      <td>-0.291147</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.510242</td>\n",
       "      <td>-0.533557</td>\n",
       "      <td>-0.518056</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>0.837883</td>\n",
       "      <td>0.673832</td>\n",
       "      <td>0.757739</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.391360</td>\n",
       "      <td>-0.416524</td>\n",
       "      <td>-0.401415</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.481492</td>\n",
       "      <td>-0.504084</td>\n",
       "      <td>-0.493642</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>0.004452</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.352142</td>\n",
       "      <td>-0.376540</td>\n",
       "      <td>-0.364509</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.455478</td>\n",
       "      <td>-0.478710</td>\n",
       "      <td>-0.467571</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.515706</td>\n",
       "      <td>-0.536156</td>\n",
       "      <td>-0.524367</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.451308</td>\n",
       "      <td>-0.463917</td>\n",
       "      <td>-0.457266</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.476418</td>\n",
       "      <td>-0.504707</td>\n",
       "      <td>-0.490873</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.539659</td>\n",
       "      <td>-0.555175</td>\n",
       "      <td>-0.547928</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.494450</td>\n",
       "      <td>-0.548987</td>\n",
       "      <td>-0.522355</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.007176</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>1.061742</td>\n",
       "      <td>0.880021</td>\n",
       "      <td>0.969990</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.415314</td>\n",
       "      <td>-0.457397</td>\n",
       "      <td>-0.435431</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.359663</td>\n",
       "      <td>-0.378153</td>\n",
       "      <td>-0.368322</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.435281</td>\n",
       "      <td>-0.457565</td>\n",
       "      <td>-0.444977</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.400760</td>\n",
       "      <td>-0.423712</td>\n",
       "      <td>-0.412139</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.538992</td>\n",
       "      <td>-0.559235</td>\n",
       "      <td>-0.545978</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>0.103086</td>\n",
       "      <td>0.072446</td>\n",
       "      <td>0.088148</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.520781</td>\n",
       "      <td>-0.543023</td>\n",
       "      <td>-0.534113</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.495865</td>\n",
       "      <td>-0.522073</td>\n",
       "      <td>-0.510172</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.498117</td>\n",
       "      <td>-0.519377</td>\n",
       "      <td>-0.505963</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.002670</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.421503</td>\n",
       "      <td>-0.459664</td>\n",
       "      <td>-0.445697</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.004513</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>1.972242</td>\n",
       "      <td>1.688894</td>\n",
       "      <td>1.831440</td>\n",
       "      <td>0.006610</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.526870</td>\n",
       "      <td>-0.552338</td>\n",
       "      <td>-0.538658</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>2.872077</td>\n",
       "      <td>2.462797</td>\n",
       "      <td>2.696284</td>\n",
       "      <td>0.015268</td>\n",
       "      <td>0.006533</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.463752</td>\n",
       "      <td>-0.501286</td>\n",
       "      <td>-0.489918</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.005744</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.496421</td>\n",
       "      <td>-0.516874</td>\n",
       "      <td>-0.506379</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.388677</td>\n",
       "      <td>-0.437794</td>\n",
       "      <td>-0.420017</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>0.387131</td>\n",
       "      <td>0.260451</td>\n",
       "      <td>0.317929</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.533724</td>\n",
       "      <td>-0.561389</td>\n",
       "      <td>-0.544691</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.436557</td>\n",
       "      <td>-0.462332</td>\n",
       "      <td>-0.450432</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Person_0</td>\n",
       "      <td>-0.431526</td>\n",
       "      <td>-0.448737</td>\n",
       "      <td>-0.441914</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        User       Max       Min      Mean       Var  Mean Abs Diff  \\\n",
       "61  Person_0 -0.520489 -0.542106 -0.529405  0.000037       0.004416   \n",
       "44  Person_0 -0.442954 -0.485496 -0.471871  0.000130       0.005481   \n",
       "8   Person_0  0.614217  0.507834  0.558740  0.000937       0.003178   \n",
       "56  Person_0 -0.511215 -0.532292 -0.519594  0.000027       0.003027   \n",
       "83  Person_0 -0.504624 -0.522588 -0.515194  0.000015       0.003052   \n",
       "1   Person_0  2.273096  2.098047  2.183685  0.002522       0.006794   \n",
       "58  Person_0 -0.513287 -0.529233 -0.521472  0.000015       0.002654   \n",
       "37  Person_0 -0.429913 -0.448014 -0.439103  0.000024       0.002823   \n",
       "59  Person_0 -0.510839 -0.529026 -0.520874  0.000016       0.002573   \n",
       "68  Person_0 -0.526523 -0.541121 -0.534539  0.000010       0.002851   \n",
       "4   Person_0  1.403413  1.035899  1.179660  0.008842       0.012267   \n",
       "14  Person_0  0.051704  0.000056  0.025427  0.000178       0.002280   \n",
       "69  Person_0 -0.534544 -0.544359 -0.538806  0.000008       0.002630   \n",
       "63  Person_0 -0.521477 -0.535377 -0.528569  0.000014       0.002729   \n",
       "64  Person_0 -0.517708 -0.533571 -0.524666  0.000014       0.002391   \n",
       "86  Person_0 -0.379641 -0.481713 -0.439345  0.001170       0.003615   \n",
       "75  Person_0 -0.532277 -0.549362 -0.541271  0.000017       0.002710   \n",
       "20  Person_0 -0.270155 -0.303399 -0.291147  0.000060       0.002479   \n",
       "55  Person_0 -0.510242 -0.533557 -0.518056  0.000023       0.003092   \n",
       "7   Person_0  0.837883  0.673832  0.757739  0.002319       0.003151   \n",
       "29  Person_0 -0.391360 -0.416524 -0.401415  0.000040       0.002984   \n",
       "91  Person_0 -0.481492 -0.504084 -0.493642  0.000050       0.004336   \n",
       "25  Person_0 -0.352142 -0.376540 -0.364509  0.000034       0.003296   \n",
       "42  Person_0 -0.455478 -0.478710 -0.467571  0.000028       0.002994   \n",
       "57  Person_0 -0.515706 -0.536156 -0.524367  0.000028       0.003499   \n",
       "40  Person_0 -0.451308 -0.463917 -0.457266  0.000009       0.002288   \n",
       "47  Person_0 -0.476418 -0.504707 -0.490873  0.000046       0.003065   \n",
       "79  Person_0 -0.539659 -0.555175 -0.547928  0.000014       0.002133   \n",
       "62  Person_0 -0.494450 -0.548987 -0.522355  0.000158       0.007176   \n",
       "6   Person_0  1.061742  0.880021  0.969990  0.002702       0.004150   \n",
       "35  Person_0 -0.415314 -0.457397 -0.435431  0.000068       0.003518   \n",
       "26  Person_0 -0.359663 -0.378153 -0.368322  0.000015       0.002303   \n",
       "33  Person_0 -0.435281 -0.457565 -0.444977  0.000027       0.003304   \n",
       "30  Person_0 -0.400760 -0.423712 -0.412139  0.000030       0.003895   \n",
       "76  Person_0 -0.538992 -0.559235 -0.545978  0.000033       0.003391   \n",
       "13  Person_0  0.103086  0.072446  0.088148  0.000081       0.002773   \n",
       "67  Person_0 -0.520781 -0.543023 -0.534113  0.000029       0.003054   \n",
       "51  Person_0 -0.495865 -0.522073 -0.510172  0.000041       0.003711   \n",
       "84  Person_0 -0.498117 -0.519377 -0.505963  0.000030       0.002740   \n",
       "39  Person_0 -0.421503 -0.459664 -0.445697  0.000062       0.004513   \n",
       "2   Person_0  1.972242  1.688894  1.831440  0.006610       0.006473   \n",
       "73  Person_0 -0.526870 -0.552338 -0.538658  0.000032       0.002775   \n",
       "0   Person_0  2.872077  2.462797  2.696284  0.015268       0.006533   \n",
       "87  Person_0 -0.463752 -0.501286 -0.489918  0.000099       0.005744   \n",
       "50  Person_0 -0.496421 -0.516874 -0.506379  0.000020       0.002978   \n",
       "31  Person_0 -0.388677 -0.437794 -0.420017  0.000133       0.005242   \n",
       "10  Person_0  0.387131  0.260451  0.317929  0.001175       0.003123   \n",
       "72  Person_0 -0.533724 -0.561389 -0.544691  0.000046       0.003846   \n",
       "34  Person_0 -0.436557 -0.462332 -0.450432  0.000030       0.003626   \n",
       "38  Person_0 -0.431526 -0.448737 -0.441914  0.000018       0.002356   \n",
       "\n",
       "    Mean Abs Second Diff  Emotion  Gender  Age  \n",
       "61              0.004821        4       0   28  \n",
       "44              0.006220        0       0   28  \n",
       "8               0.003463        5       0   28  \n",
       "56              0.003915        4       0   28  \n",
       "83              0.003992        3       0   28  \n",
       "1               0.004437        5       0   28  \n",
       "58              0.003480        4       0   28  \n",
       "37              0.003688        2       0   28  \n",
       "59              0.002702        4       0   28  \n",
       "68              0.004375        1       0   28  \n",
       "4               0.010535        5       0   28  \n",
       "14              0.003028        6       0   28  \n",
       "69              0.004491        1       0   28  \n",
       "63              0.003043        4       0   28  \n",
       "64              0.003314        4       0   28  \n",
       "86              0.003459        3       0   28  \n",
       "75              0.003998        1       0   28  \n",
       "20              0.002634        6       0   28  \n",
       "55              0.003816        0       0   28  \n",
       "7               0.003200        5       0   28  \n",
       "29              0.003685        2       0   28  \n",
       "91              0.004452        3       0   28  \n",
       "25              0.004106        6       0   28  \n",
       "42              0.004037        0       0   28  \n",
       "57              0.004929        4       0   28  \n",
       "40              0.003305        0       0   28  \n",
       "47              0.003246        0       0   28  \n",
       "79              0.002831        1       0   28  \n",
       "62              0.008724        4       0   28  \n",
       "6               0.003635        5       0   28  \n",
       "35              0.003870        2       0   28  \n",
       "26              0.002513        6       0   28  \n",
       "33              0.003841        2       0   28  \n",
       "30              0.004154        2       0   28  \n",
       "76              0.004004        1       0   28  \n",
       "13              0.003982        6       0   28  \n",
       "67              0.003836        4       0   28  \n",
       "51              0.003807        0       0   28  \n",
       "84              0.002670        3       0   28  \n",
       "39              0.005736        2       0   28  \n",
       "2               0.006037        5       0   28  \n",
       "73              0.004011        1       0   28  \n",
       "0               0.004450        5       0   28  \n",
       "87              0.005883        3       0   28  \n",
       "50              0.003326        0       0   28  \n",
       "31              0.005926        2       0   28  \n",
       "10              0.002800        5       0   28  \n",
       "72              0.005267        1       0   28  \n",
       "34              0.004762        2       0   28  \n",
       "38              0.002937        2       0   28  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "Data_train = pd.read_csv(\"train.csv\", sep = \",\")\n",
    "Data_train = shuffle(Data_train)\n",
    "Data_train[Data_train.User == \"Person_0\"].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "209a1104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Var</th>\n",
       "      <th>Mean Abs Diff</th>\n",
       "      <th>Mean Abs Second Diff</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-0.298912</td>\n",
       "      <td>-0.411740</td>\n",
       "      <td>-0.350427</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.017288</td>\n",
       "      <td>0.019670</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Person_17</td>\n",
       "      <td>0.649883</td>\n",
       "      <td>0.443783</td>\n",
       "      <td>0.541930</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.027221</td>\n",
       "      <td>0.027067</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>Person_37</td>\n",
       "      <td>1.120447</td>\n",
       "      <td>0.816078</td>\n",
       "      <td>0.908536</td>\n",
       "      <td>0.004488</td>\n",
       "      <td>0.014959</td>\n",
       "      <td>0.007501</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>Person_3</td>\n",
       "      <td>0.889679</td>\n",
       "      <td>0.733044</td>\n",
       "      <td>0.798659</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Person_10</td>\n",
       "      <td>0.933430</td>\n",
       "      <td>0.847810</td>\n",
       "      <td>0.899279</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.016184</td>\n",
       "      <td>0.018249</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           User       Max       Min      Mean       Var  Mean Abs Diff  \\\n",
       "676   Person_25 -0.298912 -0.411740 -0.350427  0.000699       0.017288   \n",
       "244   Person_17  0.649883  0.443783  0.541930  0.001719       0.027221   \n",
       "1407  Person_37  1.120447  0.816078  0.908536  0.004488       0.014959   \n",
       "1040   Person_3  0.889679  0.733044  0.798659  0.003195       0.011070   \n",
       "37    Person_10  0.933430  0.847810  0.899279  0.000442       0.016184   \n",
       "\n",
       "      Mean Abs Second Diff  Emotion  Gender  Age  \n",
       "676               0.019670        2       0   23  \n",
       "244               0.027067        6       1   29  \n",
       "1407              0.007501        3       0   21  \n",
       "1040              0.007167        1       0   22  \n",
       "37                0.018249        4       0   26  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_val = pd.read_csv(\"val.csv\")\n",
    "Data_val = shuffle(Data_val)\n",
    "Data_val.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca097b4",
   "metadata": {},
   "source": [
    "# Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "22e78213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import seaborn as sns\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(16, 10))\n",
    "# plt.plot(np.arange(0, 1000, 1), Data_train.Mean.iloc[:1000], scaley = 100)\n",
    "# plt.title(\"Mean variations\")\n",
    "# plt.legend([\"y = mean common variation\"])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9f27eba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #Max\tMin\tMean\tVar\tMean Abs Diff\tMean Abs Second Diff\tEmotion\n",
    "\n",
    "# sns.set(rc = {'figure.figsize':(16, 10)})\n",
    "# sns.set_theme(style=\"darkgrid\")\n",
    "# sns.scatterplot(data = Data_train, x = \"Mean\", y = Data_train.index, hue = \"Emotion\", palette = \"tab10\", x_bins= 150)\n",
    "# #sns.lineplot(data = Data_train.iloc[:1500], x = Data_train.Mean.iloc[:1500], y = np.arange(0, 1500, 1), hue = \"Emotion\", palette = \"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81e60458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User                    0\n",
       "Max                     0\n",
       "Min                     0\n",
       "Mean                    0\n",
       "Var                     0\n",
       "Mean Abs Diff           0\n",
       "Mean Abs Second Diff    0\n",
       "Emotion                 0\n",
       "Gender                  0\n",
       "Age                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a21b89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    699\n",
       "6    676\n",
       "3    475\n",
       "5    472\n",
       "2    436\n",
       "4    434\n",
       "1    362\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_train.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a95ae",
   "metadata": {},
   "source": [
    "####  Data is distributed normally. No NaN values. Sad and happy emotions have more samples than others -> might have to equalize value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7072b73",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "08962cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def initModel(shape, outputUnits, outputActivation) -> tf.keras.Model:\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    inputs = tf.keras.Input(shape = (shape))\n",
    "    expand = tf.expand_dims(inputs, axis = 2)\n",
    "\n",
    "    gru = tf.keras.layers.GRU(256, return_sequences = True)(expand)\n",
    "    flatten = tf.keras.layers.Flatten()(gru)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(outputUnits, activation = outputActivation)(flatten)\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9176b7a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (None, 8, 1)             0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 8, 256)            198912    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 14343     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,255\n",
      "Trainable params: 213,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 4s 37ms/step - loss: 1.9196 - accuracy: 0.1986 - val_loss: 1.9919 - val_accuracy: 0.1531\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 1.9137 - accuracy: 0.2003 - val_loss: 1.9850 - val_accuracy: 0.1445\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 1.9174 - accuracy: 0.1911 - val_loss: 1.9924 - val_accuracy: 0.1629\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 1.9084 - accuracy: 0.2079 - val_loss: 1.9952 - val_accuracy: 0.1537\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 1.9044 - accuracy: 0.2046 - val_loss: 1.9695 - val_accuracy: 0.1623\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 1.8985 - accuracy: 0.2161 - val_loss: 1.9648 - val_accuracy: 0.1779\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 1.8973 - accuracy: 0.2119 - val_loss: 1.9858 - val_accuracy: 0.1629\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 1.8963 - accuracy: 0.2093 - val_loss: 1.9981 - val_accuracy: 0.1658\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 1.8953 - accuracy: 0.2085 - val_loss: 1.9773 - val_accuracy: 0.1681\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 1.8960 - accuracy: 0.2096 - val_loss: 1.9798 - val_accuracy: 0.1618\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 1.8918 - accuracy: 0.2155 - val_loss: 1.9876 - val_accuracy: 0.1537\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 1.8888 - accuracy: 0.2206 - val_loss: 1.9780 - val_accuracy: 0.1808\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 1.8850 - accuracy: 0.2158 - val_loss: 1.9586 - val_accuracy: 0.1802\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 1.8870 - accuracy: 0.2060 - val_loss: 1.9689 - val_accuracy: 0.1785\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 1.8769 - accuracy: 0.2209 - val_loss: 1.9955 - val_accuracy: 0.1687\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 1.8770 - accuracy: 0.2183 - val_loss: 1.9833 - val_accuracy: 0.1577\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 1.8782 - accuracy: 0.2195 - val_loss: 2.0046 - val_accuracy: 0.1687\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 1.8731 - accuracy: 0.2257 - val_loss: 1.9859 - val_accuracy: 0.1652\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 1.8708 - accuracy: 0.2138 - val_loss: 1.9955 - val_accuracy: 0.1503\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 1s 25ms/step - loss: 1.8662 - accuracy: 0.2167 - val_loss: 2.0040 - val_accuracy: 0.1664\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 1.8657 - accuracy: 0.2237 - val_loss: 1.9980 - val_accuracy: 0.1629\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 1.8619 - accuracy: 0.2245 - val_loss: 2.0335 - val_accuracy: 0.1560\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 1.8546 - accuracy: 0.2285 - val_loss: 2.0201 - val_accuracy: 0.1785\n",
      "Validation Accuracy: 18.020%\n"
     ]
    }
   ],
   "source": [
    "y = Data_train.Emotion\n",
    "X = pd.DataFrame(Data_train.drop(['Emotion', 'User'], axis = 1))\n",
    "\n",
    "y_val = Data_val.Emotion\n",
    "X_val = pd.DataFrame(Data_val.drop(['Emotion', 'User'], axis = 1))\n",
    "\n",
    "#Trying adam optimizer\n",
    "model = initModel(X.shape[1], 7, 'softmax')\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X,\n",
    "    y,\n",
    "    #validation_split = 0.3,\n",
    "    validation_data = (X_val, y_val),\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Result of adam optimizer\n",
    "model_acc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "print(\"Validation Accuracy: {:.3f}%\".format(model_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f77d41c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the accuracy curve for training\n",
    "# plt.plot(history.history['accuracy'], color='r', label=\"Accuracy\")\n",
    "\n",
    "# plt.title(\"Accuracy\")\n",
    "# plt.xlabel(\"Number of Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b225588a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16870311, 0.07657745, 0.10712576, ..., 0.10079721, 0.16205086,\n",
       "        0.2170536 ],\n",
       "       [0.17407425, 0.10037328, 0.14372985, ..., 0.1219712 , 0.11192211,\n",
       "        0.1996162 ],\n",
       "       [0.10674707, 0.16207322, 0.16804105, ..., 0.1292181 , 0.13845596,\n",
       "        0.1594871 ],\n",
       "       ...,\n",
       "       [0.09274311, 0.1725051 , 0.16431177, ..., 0.12184849, 0.17576635,\n",
       "        0.11873264],\n",
       "       [0.06886141, 0.22534494, 0.19483313, ..., 0.11931857, 0.1287762 ,\n",
       "        0.11487933],\n",
       "       [0.05693928, 0.22031088, 0.15792762, ..., 0.10903908, 0.16173814,\n",
       "        0.0992789 ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f803dc",
   "metadata": {},
   "source": [
    "### Creating valence column\n",
    "#### Emotion is valence (1) on surprise, neutral and happy; otherwise valence is 0 (disgust, angry, fear, sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "996e79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = ['Happy', 'Surprise', 'Disgust', 'Angry', 'Fear', 'Sad', 'Neutral']\n",
    "def getValence(row) -> int:\n",
    "    if row['Emotion'] == 0 or row['Emotion'] == 1 or row['Emotion'] == 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "Data_train['Valence'] = Data_train.apply(lambda row: getValence(row), axis = 1)\n",
    "Data_val['Valence'] = Data_val.apply(lambda row: getValence(row), axis = 1)\n",
    "\n",
    "y = Data_train.Emotion\n",
    "X = pd.DataFrame(Data_train.drop(['Emotion', 'User'], axis = 1))\n",
    "\n",
    "y_val = Data_val.Emotion\n",
    "X_val = pd.DataFrame(Data_val.drop(['Emotion', 'User'], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "781f20ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 9)]               0         \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (None, 9, 1)             0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 9, 256)            198912    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 16135     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 215,047\n",
      "Trainable params: 215,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 5s 25ms/step - loss: 1.8492 - accuracy: 0.2372 - val_loss: 1.7225 - val_accuracy: 0.3086\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 2s 22ms/step - loss: 1.4611 - accuracy: 0.3334 - val_loss: 1.3874 - val_accuracy: 0.2884\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.2623 - accuracy: 0.3562 - val_loss: 1.3186 - val_accuracy: 0.2861\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.2406 - accuracy: 0.3436 - val_loss: 1.3586 - val_accuracy: 0.2786\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.2287 - accuracy: 0.3568 - val_loss: 1.3186 - val_accuracy: 0.2809\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.2305 - accuracy: 0.3534 - val_loss: 1.3215 - val_accuracy: 0.2735\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.2190 - accuracy: 0.3658 - val_loss: 1.3189 - val_accuracy: 0.2827\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.2102 - accuracy: 0.3621 - val_loss: 1.3340 - val_accuracy: 0.2694\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 2s 21ms/step - loss: 1.2061 - accuracy: 0.3694 - val_loss: 1.3474 - val_accuracy: 0.2712\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.1994 - accuracy: 0.3703 - val_loss: 1.2928 - val_accuracy: 0.3103\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 2s 19ms/step - loss: 1.1979 - accuracy: 0.3714 - val_loss: 1.3394 - val_accuracy: 0.3069\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.1921 - accuracy: 0.3717 - val_loss: 1.3607 - val_accuracy: 0.2804\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.1957 - accuracy: 0.3821 - val_loss: 1.3094 - val_accuracy: 0.3138\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 2s 19ms/step - loss: 1.1885 - accuracy: 0.3765 - val_loss: 1.3432 - val_accuracy: 0.2930\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.1801 - accuracy: 0.3959 - val_loss: 1.3699 - val_accuracy: 0.2769\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.1815 - accuracy: 0.3889 - val_loss: 1.3792 - val_accuracy: 0.2890\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 2s 21ms/step - loss: 1.1768 - accuracy: 0.3965 - val_loss: 1.3928 - val_accuracy: 0.2637\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.1734 - accuracy: 0.3889 - val_loss: 1.3599 - val_accuracy: 0.2838\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.1695 - accuracy: 0.4021 - val_loss: 1.3409 - val_accuracy: 0.2890\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 4s 35ms/step - loss: 1.1741 - accuracy: 0.3998 - val_loss: 1.3748 - val_accuracy: 0.2844\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 5s 48ms/step - loss: 1.1657 - accuracy: 0.3959 - val_loss: 1.3801 - val_accuracy: 0.2545\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 5s 46ms/step - loss: 1.1703 - accuracy: 0.4018 - val_loss: 1.3570 - val_accuracy: 0.2671\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 4s 36ms/step - loss: 1.1608 - accuracy: 0.4077 - val_loss: 1.3906 - val_accuracy: 0.2832\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.1629 - accuracy: 0.4069 - val_loss: 1.3725 - val_accuracy: 0.2614\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 2s 19ms/step - loss: 1.1606 - accuracy: 0.4094 - val_loss: 1.3754 - val_accuracy: 0.2850\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 2s 21ms/step - loss: 1.1567 - accuracy: 0.4097 - val_loss: 1.3950 - val_accuracy: 0.2654\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.1532 - accuracy: 0.4178 - val_loss: 1.4003 - val_accuracy: 0.2677\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.1562 - accuracy: 0.4178 - val_loss: 1.3856 - val_accuracy: 0.2412\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.1478 - accuracy: 0.4204 - val_loss: 1.3919 - val_accuracy: 0.2568\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 2s 20ms/step - loss: 1.1414 - accuracy: 0.4347 - val_loss: 1.4415 - val_accuracy: 0.2700\n",
      "Validation Accuracy: 31.031%\n"
     ]
    }
   ],
   "source": [
    "model = initModel(X.shape[1], 7, 'softmax')\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X,\n",
    "    y,\n",
    "    #validation_split = 0.2,\n",
    "    validation_data = (X_val, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=20,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Result of adam optimizer\n",
    "model_acc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "print(\"Validation Accuracy: {:.3f}%\".format(model_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd1ec3b",
   "metadata": {},
   "source": [
    "### With valence given accuracy rose significantly (To 30.2%). Now will predict valence from initial data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "570f62c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_train['Valence'] = Data_train.apply(lambda row: getValence(row), axis = 1)\n",
    "Data_val['Valence'] = Data_val.apply(lambda row: getValence(row), axis = 1)\n",
    "\n",
    "y_valence = np.asarray(Data_train.Valence).astype('float32')\n",
    "y = Data_train.Emotion\n",
    "X = pd.DataFrame(Data_train.drop(['Valence', 'Emotion', 'User'], axis = 1, inplace = False))\n",
    "\n",
    "y_val_valence = np.asarray(Data_val.Valence).astype('float32')\n",
    "y_val = Data_val.Emotion\n",
    "X_val = pd.DataFrame(Data_val.drop(['Valence', 'Emotion', 'User'], axis = 1, inplace = False))\n",
    "\n",
    "y_valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1fd7c8e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 72        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 8)                32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 4)                16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 137\n",
      "Non-trainable params: 24\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 2s 4ms/step - loss: 0.7530 - accuracy: 0.5135 - val_loss: 0.7608 - val_accuracy: 0.5273\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.7191 - accuracy: 0.5149 - val_loss: 0.7045 - val_accuracy: 0.5250\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.5355 - val_loss: 0.7465 - val_accuracy: 0.4859\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5298 - val_loss: 0.7174 - val_accuracy: 0.5089\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5250 - val_loss: 0.7030 - val_accuracy: 0.5400\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5281 - val_loss: 0.6930 - val_accuracy: 0.5492\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5273 - val_loss: 0.7063 - val_accuracy: 0.4899\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5290 - val_loss: 0.7050 - val_accuracy: 0.4928\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5301 - val_loss: 0.7116 - val_accuracy: 0.4830\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5256 - val_loss: 0.7067 - val_accuracy: 0.4945\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5172 - val_loss: 0.6879 - val_accuracy: 0.5774\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.5217 - val_loss: 0.6909 - val_accuracy: 0.5509\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5447 - val_loss: 0.6924 - val_accuracy: 0.5521\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5250 - val_loss: 0.6963 - val_accuracy: 0.5325\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5391 - val_loss: 0.6868 - val_accuracy: 0.5533\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 0s 3ms/step - loss: 0.6837 - accuracy: 0.5329 - val_loss: 0.7006 - val_accuracy: 0.4876\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5380 - val_loss: 0.6911 - val_accuracy: 0.5060\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5324 - val_loss: 0.6948 - val_accuracy: 0.5325\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5433 - val_loss: 0.6972 - val_accuracy: 0.4940\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5360 - val_loss: 0.6871 - val_accuracy: 0.5717\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.5383 - val_loss: 0.6856 - val_accuracy: 0.5671\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.5442 - val_loss: 0.6890 - val_accuracy: 0.5354\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5321 - val_loss: 0.7032 - val_accuracy: 0.5153\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.5383 - val_loss: 0.6975 - val_accuracy: 0.5193\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5369 - val_loss: 0.6895 - val_accuracy: 0.5348\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5422 - val_loss: 0.6911 - val_accuracy: 0.5429\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5450 - val_loss: 0.6972 - val_accuracy: 0.5164\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5445 - val_loss: 0.6912 - val_accuracy: 0.5435\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5481 - val_loss: 0.6905 - val_accuracy: 0.5492\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.5290 - val_loss: 0.6888 - val_accuracy: 0.5596\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5312 - val_loss: 0.6962 - val_accuracy: 0.5026\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5329 - val_loss: 0.6933 - val_accuracy: 0.5291\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5388 - val_loss: 0.7072 - val_accuracy: 0.4991\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5428 - val_loss: 0.6943 - val_accuracy: 0.5245\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5484 - val_loss: 0.6958 - val_accuracy: 0.5181\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5352 - val_loss: 0.7028 - val_accuracy: 0.4974\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5450 - val_loss: 0.6951 - val_accuracy: 0.5331\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5408 - val_loss: 0.7075 - val_accuracy: 0.5043\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.5355 - val_loss: 0.6927 - val_accuracy: 0.5435\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5391 - val_loss: 0.6884 - val_accuracy: 0.5567\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5428 - val_loss: 0.7041 - val_accuracy: 0.5083\n",
      "Test Accuracy: 56.707%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "tf.keras.backend.clear_session()\n",
    "valenceModel = tf.keras.models.Sequential()\n",
    "\n",
    "valenceModel.add(Dense(8, input_dim = X.shape[1], activation = 'relu'))\n",
    "valenceModel.add(tf.keras.layers.BatchNormalization())\n",
    "valenceModel.add(Dense(4, activation = 'relu'))\n",
    "valenceModel.add(tf.keras.layers.BatchNormalization())\n",
    "valenceModel.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "valenceModel.summary()\n",
    "\n",
    "\n",
    "valenceModel.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = valenceModel.fit(\n",
    "    X,\n",
    "    y_valence,\n",
    "    validation_data = (X_val, y_val_valence),\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=20,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Result of adam optimizer\n",
    "model_acc = valenceModel.evaluate(X_val, y_val_valence, verbose=0)[1]\n",
    "print(\"Test Accuracy: {:.3f}%\".format(model_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c28f0fc",
   "metadata": {},
   "source": [
    "values = model.predict(X_val)\n",
    "values = [int(value >= 0.5) for value in values]\n",
    "print('accuracy: ', accuracy_score(y_val_valence, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dccbb5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51483446],\n",
       "       [0.49076444],\n",
       "       [0.47748485],\n",
       "       ...,\n",
       "       [0.28791887],\n",
       "       [0.40569466],\n",
       "       [0.2453596 ]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valence = valenceModel.predict(X)\n",
    "y_val_valence = valenceModel.predict(X_val)\n",
    "y_valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c4ca28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71befd00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12d815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e5e15a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
