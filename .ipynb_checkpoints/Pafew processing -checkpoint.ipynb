{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8778ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.signal import medfilt\n",
    "from scipy.signal import wiener\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "genders = ['male', 'female']\n",
    "labels = ['Happy', 'Surprise', 'Disgust', 'Angry', 'Fear', 'Sad', 'Neutral'] # 0-6, 7 classes\n",
    "\n",
    "def preprocess_data(dataPath, train):\n",
    "    if train:\n",
    "        path = os.path.join(dataPath, 'train')\n",
    "        output_dir = os.path.join(dataPath, 'train.csv')\n",
    "    else:\n",
    "        path = os.path.join(dataPath, 'val')\n",
    "        output_dir = os.path.join(dataPath, 'val.csv')\n",
    "    folders = glob.glob(os.path.join(path, '*'))\n",
    "    folders.sort()\n",
    "\n",
    "    with open(output_dir, 'a+') as csv_output_file:\n",
    "        fieldnames = ['User', 'Person_min', 'Max', 'Min', 'Mean', 'Var', 'Mean Abs Diff', 'Mean Abs Second Diff', 'Emotion', 'Gender', 'Age'] # The features extracted\n",
    "        writer = csv.DictWriter(csv_output_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for dir in folders:\n",
    "            with open(os.path.join(dir, 'EDA.csv')) as csv_file:\n",
    "                csv_reader = csv.reader(csv_file)\n",
    "                line_count = 0\n",
    "                data = [] # all data for one person\n",
    "                time_stamp = [] # time stamp for each item\n",
    "\n",
    "                for row in csv_reader:\n",
    "                    if line_count == 0:\n",
    "                        start_time = float(row[0])\n",
    "                    elif line_count == 1:\n",
    "                        freq = float(row[0])\n",
    "                    elif line_count>2 :\n",
    "                        data.append(float(row[0]))\n",
    "                        time_stamp.append(start_time + float((line_count-2)/freq))\n",
    "                    line_count += 1\n",
    "\n",
    "                #person_Max = max(data)\n",
    "                #person_Min = min(data)\n",
    "                data = (data - np.average(data)) / (np.std(data)) # standartization filter\n",
    "                #data = (np.array(data) - float(person_Min)) / (float(person_Max) - float(person_Min)) # normalised data for each person\n",
    "                #data = medfilt(data, 11) # median filter; can be substituted by your preprocessing methods\n",
    "                #data = wiener(data)\n",
    "                #data = savgol_filter(data, 11, 5)\n",
    "                person_Max = max(data)\n",
    "                person_Min = min(data)\n",
    "                \n",
    "            \n",
    "                log = open(os.path.join(dir, 'log.txt'), 'r')\n",
    "                log_count = 0\n",
    "                for line in log:\n",
    "                    if log_count == 0:\n",
    "                        user = line.split(';')[0].split(':')[-1]\n",
    "                        age = line.split(';')[1].split(':')[-1]\n",
    "                        gender = line.split(';')[2].split(':')[-1]\n",
    "                        gender = genders.index(gender.lower())\n",
    "                        log_count += 1\n",
    "                    elif log_count == 1:\n",
    "                        log_count += 1\n",
    "                    else:\n",
    "                        st = float(line.split(';')[1]) # start time of each video\n",
    "                        et = float(line.split(';')[3]) # end time of each video\n",
    "                        video_name = line.split(';')[2]\n",
    "                        if \"_\" in video_name:\n",
    "                            emotion_label = line.split(';')[2].split('.')[0][:-10] # emotion label of each video\n",
    "                        else:\n",
    "                            emotion_label = line.split(';')[2].split('.')[0][:-9]  # emotion label of each video\n",
    "                        emotion_label = labels.index(emotion_label)\n",
    "\n",
    "                        index = np.where(np.logical_and((np.array(time_stamp) >= st), (np.array(time_stamp) <= et)))\n",
    "                        data_list = data[index[0]]\n",
    "                        if len(data_list)== 0:\n",
    "                            break\n",
    "                        diff_list = [data_list[k+1]-data_list[k] for k in range(len(data_list)-1)]\n",
    "                        abs_diff_list = abs(np.array(diff_list))\n",
    "                        second_diff_list = [diff_list[k + 1] - diff_list[k] for k in range(len(diff_list) - 1)]\n",
    "                        abs_second_diff_list = abs(np.array(second_diff_list))\n",
    "                        writer.writerow({'User': user, 'Person_min': person_Min,  'Max': max(data_list), 'Min': min(data_list), 'Mean': np.mean(data_list), 'Var': np.var(data_list), 'Mean Abs Diff': np.mean(abs_diff_list), 'Mean Abs Second Diff': np.mean(abs_second_diff_list),'Emotion': emotion_label, 'Gender': gender, 'Age': age})\n",
    "                log.close()\n",
    "        csv_file.close()\n",
    "    csv_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "8285489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and reading dat\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "os.remove('train.csv')\n",
    "preprocess_data('', train=1)\n",
    "os.remove('val.csv')\n",
    "preprocess_data('', train=0)\n",
    "\n",
    "\n",
    "Data_train = pd.read_csv(\"train.csv\", sep = \",\")\n",
    "Data_train = shuffle(Data_train)\n",
    "#Data_train[Data_train.User == \"Person_25\"].head(10)\n",
    "#Data_train.head(20)\n",
    "\n",
    "Data_val = pd.read_csv(\"val.csv\")\n",
    "Data_val = shuffle(Data_val)\n",
    "#Data_val[Data_val.User == \"Person_25\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca097b4",
   "metadata": {},
   "source": [
    "# Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "22e78213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import seaborn as sns\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(16, 10))\n",
    "# plt.plot(np.arange(0, 1000, 1), Data_train.Mean.iloc[:1000], scaley = 100)\n",
    "# plt.title(\"Mean variations\")\n",
    "# plt.legend([\"y = mean common variation\"])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e9f27eba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #Max\tMin\tMean\tVar\tMean Abs Diff\tMean Abs Second Diff\tEmotion\n",
    "\n",
    "# sns.set(rc = {'figure.figsize':(16, 10)})\n",
    "# sns.set_theme(style=\"darkgrid\")\n",
    "# sns.scatterplot(data = Data_train, x = \"Mean\", y = Data_train.index, hue = \"Emotion\", palette = \"tab10\", x_bins= 150)\n",
    "# #sns.lineplot(data = Data_train.iloc[:1500], x = Data_train.Mean.iloc[:1500], y = np.arange(0, 1500, 1), hue = \"Emotion\", palette = \"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "81e60458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9a21b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data_train.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "909a835f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Person_min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Var</th>\n",
       "      <th>Mean Abs Diff</th>\n",
       "      <th>Mean Abs Second Diff</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>1.033149</td>\n",
       "      <td>0.823431</td>\n",
       "      <td>0.950573</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.054121</td>\n",
       "      <td>0.097869</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.487914</td>\n",
       "      <td>0.320140</td>\n",
       "      <td>0.398556</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.053383</td>\n",
       "      <td>0.081890</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>1.788103</td>\n",
       "      <td>1.117037</td>\n",
       "      <td>1.217700</td>\n",
       "      <td>0.015339</td>\n",
       "      <td>0.103109</td>\n",
       "      <td>0.204242</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.362083</td>\n",
       "      <td>0.194309</td>\n",
       "      <td>0.306158</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.056324</td>\n",
       "      <td>0.098691</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.529858</td>\n",
       "      <td>0.362083</td>\n",
       "      <td>0.439979</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.052430</td>\n",
       "      <td>0.088302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.739544</td>\n",
       "      <td>0.613745</td>\n",
       "      <td>0.678141</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.035713</td>\n",
       "      <td>0.061276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.445971</td>\n",
       "      <td>0.194309</td>\n",
       "      <td>0.364180</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>0.081680</td>\n",
       "      <td>0.123501</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.362083</td>\n",
       "      <td>0.152365</td>\n",
       "      <td>0.276642</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>0.062916</td>\n",
       "      <td>0.104020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.057353</td>\n",
       "      <td>-0.225095</td>\n",
       "      <td>-0.138676</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.056343</td>\n",
       "      <td>0.101445</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.781487</td>\n",
       "      <td>0.655689</td>\n",
       "      <td>0.733953</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.038943</td>\n",
       "      <td>0.074203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.781487</td>\n",
       "      <td>0.571802</td>\n",
       "      <td>0.694258</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.054158</td>\n",
       "      <td>0.085688</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>1.284811</td>\n",
       "      <td>1.075093</td>\n",
       "      <td>1.203920</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.068353</td>\n",
       "      <td>0.124218</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>1.117037</td>\n",
       "      <td>0.907318</td>\n",
       "      <td>1.014084</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.053928</td>\n",
       "      <td>0.085985</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.529858</td>\n",
       "      <td>-0.099297</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.011698</td>\n",
       "      <td>0.083887</td>\n",
       "      <td>0.152240</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.476757</td>\n",
       "      <td>-0.728419</td>\n",
       "      <td>-0.576271</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>0.054527</td>\n",
       "      <td>0.099295</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           User  Person_min       Max       Min      Mean       Var  \\\n",
       "1038  Person_25   -3.161054  1.033149  0.823431  0.950573  0.002252   \n",
       "1017  Person_25   -3.161054  0.487914  0.320140  0.398556  0.001729   \n",
       "1055  Person_25   -3.161054  1.788103  1.117037  1.217700  0.015339   \n",
       "1013  Person_25   -3.161054  0.362083  0.194309  0.306158  0.002150   \n",
       "1019  Person_25   -3.161054  0.529858  0.362083  0.439979  0.001891   \n",
       "1029  Person_25   -3.161054  0.739544  0.613745  0.678141  0.001191   \n",
       "1015  Person_25   -3.161054  0.445971  0.194309  0.364180  0.004306   \n",
       "1012  Person_25   -3.161054  0.362083  0.152365  0.276642  0.002408   \n",
       "998   Person_25   -3.161054 -0.057353 -0.225095 -0.138676  0.001805   \n",
       "1033  Person_25   -3.161054  0.781487  0.655689  0.733953  0.001376   \n",
       "1031  Person_25   -3.161054  0.781487  0.571802  0.694258  0.002239   \n",
       "1056  Person_25   -3.161054  1.284811  1.075093  1.203920  0.002756   \n",
       "1042  Person_25   -3.161054  1.117037  0.907318  1.014084  0.002036   \n",
       "1002  Person_25   -3.161054  0.529858 -0.099297  0.000500  0.011698   \n",
       "989   Person_25   -3.161054 -0.476757 -0.728419 -0.576271  0.003171   \n",
       "\n",
       "      Mean Abs Diff  Mean Abs Second Diff  Emotion  Gender  Age  \n",
       "1038       0.054121              0.097869        5       0   23  \n",
       "1017       0.053383              0.081890        1       0   23  \n",
       "1055       0.103109              0.204242        4       0   23  \n",
       "1013       0.056324              0.098691        1       0   23  \n",
       "1019       0.052430              0.088302        0       0   23  \n",
       "1029       0.035713              0.061276        0       0   23  \n",
       "1015       0.081680              0.123501        1       0   23  \n",
       "1012       0.062916              0.104020        1       0   23  \n",
       "998        0.056343              0.101445        6       0   23  \n",
       "1033       0.038943              0.074203        0       0   23  \n",
       "1031       0.054158              0.085688        0       0   23  \n",
       "1056       0.068353              0.124218        4       0   23  \n",
       "1042       0.053928              0.085985        5       0   23  \n",
       "1002       0.083887              0.152240        6       0   23  \n",
       "989        0.054527              0.099295        2       0   23  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_train[Data_train.User == \"Person_25\"].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "66ea7f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Person_min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Var</th>\n",
       "      <th>Mean Abs Diff</th>\n",
       "      <th>Mean Abs Second Diff</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>1.494497</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>0.842232</td>\n",
       "      <td>0.017541</td>\n",
       "      <td>0.088379</td>\n",
       "      <td>0.167770</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.308983</td>\n",
       "      <td>-0.560645</td>\n",
       "      <td>-0.384804</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.058721</td>\n",
       "      <td>0.096121</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.865375</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.052430</td>\n",
       "      <td>0.090510</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.949262</td>\n",
       "      <td>0.781487</td>\n",
       "      <td>0.874493</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.059102</td>\n",
       "      <td>0.087882</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.865375</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>0.783955</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.039322</td>\n",
       "      <td>0.067110</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.350926</td>\n",
       "      <td>-0.476757</td>\n",
       "      <td>-0.409106</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.055925</td>\n",
       "      <td>0.095458</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.823431</td>\n",
       "      <td>0.655689</td>\n",
       "      <td>0.756704</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.045935</td>\n",
       "      <td>0.079690</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.907318</td>\n",
       "      <td>0.739544</td>\n",
       "      <td>0.853038</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.068158</td>\n",
       "      <td>0.123035</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.907318</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>0.813444</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.060818</td>\n",
       "      <td>0.105963</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.907318</td>\n",
       "      <td>0.739544</td>\n",
       "      <td>0.834870</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.051930</td>\n",
       "      <td>0.096470</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.949262</td>\n",
       "      <td>0.739544</td>\n",
       "      <td>0.861727</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.055289</td>\n",
       "      <td>0.103861</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.823431</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>0.767506</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.039322</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>-0.308983</td>\n",
       "      <td>-0.476757</td>\n",
       "      <td>-0.384915</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.055925</td>\n",
       "      <td>0.089130</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.865375</td>\n",
       "      <td>0.655689</td>\n",
       "      <td>0.754458</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.056240</td>\n",
       "      <td>0.105342</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>Person_25</td>\n",
       "      <td>-3.161054</td>\n",
       "      <td>0.907318</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>0.828091</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.051813</td>\n",
       "      <td>0.094373</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          User  Person_min       Max       Min      Mean       Var  \\\n",
       "685  Person_25   -3.161054  1.494497  0.697600  0.842232  0.017541   \n",
       "675  Person_25   -3.161054 -0.308983 -0.560645 -0.384804  0.002980   \n",
       "683  Person_25   -3.161054  0.865375  0.697600  0.817439  0.001723   \n",
       "687  Person_25   -3.161054  0.949262  0.781487  0.874493  0.002747   \n",
       "680  Person_25   -3.161054  0.865375  0.697600  0.783955  0.001753   \n",
       "672  Person_25   -3.161054 -0.350926 -0.476757 -0.409106  0.001893   \n",
       "677  Person_25   -3.161054  0.823431  0.655689  0.756704  0.001864   \n",
       "686  Person_25   -3.161054  0.907318  0.739544  0.853038  0.002849   \n",
       "681  Person_25   -3.161054  0.907318  0.697600  0.813444  0.002497   \n",
       "682  Person_25   -3.161054  0.907318  0.739544  0.834870  0.001788   \n",
       "688  Person_25   -3.161054  0.949262  0.739544  0.861727  0.002128   \n",
       "678  Person_25   -3.161054  0.823431  0.697600  0.767506  0.001137   \n",
       "673  Person_25   -3.161054 -0.308983 -0.476757 -0.384915  0.001969   \n",
       "679  Person_25   -3.161054  0.865375  0.655689  0.754458  0.002514   \n",
       "684  Person_25   -3.161054  0.907318  0.697600  0.828091  0.002519   \n",
       "\n",
       "     Mean Abs Diff  Mean Abs Second Diff  Emotion  Gender  Age  \n",
       "685       0.088379              0.167770        3       0   23  \n",
       "675       0.058721              0.096121        2       0   23  \n",
       "683       0.052430              0.090510        3       0   23  \n",
       "687       0.059102              0.087882        3       0   23  \n",
       "680       0.039322              0.067110        3       0   23  \n",
       "672       0.055925              0.095458        2       0   23  \n",
       "677       0.045935              0.079690        3       0   23  \n",
       "686       0.068158              0.123035        3       0   23  \n",
       "681       0.060818              0.105963        3       0   23  \n",
       "682       0.051930              0.096470        3       0   23  \n",
       "688       0.055289              0.103861        3       0   23  \n",
       "678       0.039322              0.066298        3       0   23  \n",
       "673       0.055925              0.089130        2       0   23  \n",
       "679       0.056240              0.105342        3       0   23  \n",
       "684       0.051813              0.094373        3       0   23  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_val[Data_val.User == \"Person_25\"].head(15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a95ae",
   "metadata": {},
   "source": [
    "####  Data is distributed normally. No NaN values. Sad and happy emotions have more samples than others -> might have to equalize value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8456c276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3554, 11) (1737, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5291, 11)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging val and train data\n",
    "print(Data_train.shape, Data_val.shape)\n",
    "Data_train = pd.merge(Data_train, Data_val, how = 'outer')\n",
    "Data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccfda27",
   "metadata": {},
   "source": [
    "### Valence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "40fca75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positive: surprise, happy, neutral\n",
    "#Negative: else\n",
    "# labels = ['Happy', 'Surprise', 'Disgust', 'Angry', 'Fear', 'Sad', 'Neutral'] # 0-6, 7 classes\n",
    "\n",
    "def getValence(row) -> int:\n",
    "        if row['Emotion'] == 0 or row['Emotion'] == 1 or row['Emotion'] == 6:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "Data_train['Valence'] = Data_train.apply(lambda row: getValence(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ee478ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence acc score:  0.7726700251889169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>K-Neighbors Classifier</th>\n",
       "      <td>0.571159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.484887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.557935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             score\n",
       "K-Neighbors Classifier    0.571159\n",
       "Decision Tree Classifier  0.484887\n",
       "Random Forest Classifier  0.557935"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "y = Data_train.Emotion\n",
    "z = Data_train.Valence\n",
    "X = pd.DataFrame(Data_train.drop(['Emotion','User', 'Valence'], axis = 1))\n",
    "\n",
    "models = [ KNeighborsClassifier(n_neighbors= 7), DecisionTreeClassifier(), RandomForestClassifier()]\n",
    "model_names = ['K-Neighbors Classifier', 'Decision Tree Classifier', 'Random Forest Classifier']\n",
    "scores = np.zeros([len(models), 1])\n",
    "\n",
    "#X_train = pd.concat([X_train, pd.DataFrame(clf.predict(X_train), columns = ['Valence'])], axis = 1)\n",
    "    #X_test = pd.concat([X_test, pd.DataFrame(clf.predict(X_test), columns = ['Valence'])], axis = 1)\n",
    "    #clf = m.fit(X_train, y_train)\n",
    "#for i, m in enumerate(models):\n",
    "#    X_train, X_test, y_train, y_test, z_train, z_test = train_test_split(X, y, z, test_size = 0.3, random_state = 123)\n",
    "#    clf =  m.fit(X_train, z_train)\n",
    "#    scores[i] = clf.score(X_test, y_test)\n",
    "#    print(clf.predict(X_train))\n",
    "\n",
    "#scores = pd.DataFrame(scores, columns=['score'], index=model_names)\n",
    "#scores\n",
    "\n",
    "X_train, X_test, z_train, z_test = train_test_split(X, z, test_size = 0.3, random_state = 123)\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, z_train)\n",
    "\n",
    "z_pred = clf.predict(X)\n",
    "X = pd.concat([X, pd.DataFrame(data = z_pred, columns = ['Valence'])], axis = 1)\n",
    "print(\"Valence acc score: \", clf.score(X_test, z_test))\n",
    "\n",
    "for i, m in enumerate(models):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 123)\n",
    "    clf =  m.fit(X_train, y_train)\n",
    "    scores[i] = clf.score(X_test, y_test)\n",
    "    \n",
    "scores = pd.DataFrame(scores, columns=['score'], index=model_names)\n",
    "scores\n",
    "\n",
    "\n",
    "# K-Neighbors Classifier\t0.584383\n",
    "# Decision Tree Classifier\t0.493703\n",
    "# Random Forest Classifier\t0.568010"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7072b73",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "08962cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, ReLU\n",
    "from tensorflow.keras.regularizers import L1, L2, L1L2\n",
    "\n",
    "def initModelBasic(shape, outputUnits) -> tf.keras.Model:\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(tf.keras.Input(shape = (shape)))\n",
    "    \n",
    "    model.add(Dense(16, activation = 'linear'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    \n",
    "    model.add(Dense(16, activation = 'linear'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    \n",
    "    model.add(Dense(outputUnits, activation = 'softmax'))\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "def initModelValence(shape, outputUnits) -> tf.keras.Model:\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(tf.keras.Input(shape = shape))\n",
    "    \n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(ReLU())\n",
    "    \n",
    "    model.add(Dense(32, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(ReLU())\n",
    "    \n",
    "    model.add(Dense(outputUnits, activation = 'sigmoid'))\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a8366d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                640       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,137\n",
      "Trainable params: 2,945\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/600\n",
      "116/116 [==============================] - 1s 4ms/step - loss: 0.7057 - binary_accuracy: 0.5296 - val_loss: 0.7040 - val_binary_accuracy: 0.5239\n",
      "Epoch 2/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6908 - binary_accuracy: 0.5382 - val_loss: 0.6964 - val_binary_accuracy: 0.5485\n",
      "Epoch 3/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6857 - binary_accuracy: 0.5496 - val_loss: 0.6902 - val_binary_accuracy: 0.5781\n",
      "Epoch 4/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6837 - binary_accuracy: 0.5558 - val_loss: 0.7244 - val_binary_accuracy: 0.5258\n",
      "Epoch 5/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6821 - binary_accuracy: 0.5614 - val_loss: 0.6997 - val_binary_accuracy: 0.5491\n",
      "Epoch 6/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6777 - binary_accuracy: 0.5733 - val_loss: 0.7040 - val_binary_accuracy: 0.5686\n",
      "Epoch 7/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6790 - binary_accuracy: 0.5590 - val_loss: 0.7203 - val_binary_accuracy: 0.4824\n",
      "Epoch 8/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6795 - binary_accuracy: 0.5598 - val_loss: 0.7023 - val_binary_accuracy: 0.5724\n",
      "Epoch 9/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6783 - binary_accuracy: 0.5644 - val_loss: 0.7128 - val_binary_accuracy: 0.4931\n",
      "Epoch 10/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6773 - binary_accuracy: 0.5620 - val_loss: 0.7088 - val_binary_accuracy: 0.5529\n",
      "Epoch 11/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6766 - binary_accuracy: 0.5636 - val_loss: 0.7106 - val_binary_accuracy: 0.5277\n",
      "Epoch 12/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6777 - binary_accuracy: 0.5644 - val_loss: 0.7107 - val_binary_accuracy: 0.5019\n",
      "Epoch 13/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6721 - binary_accuracy: 0.5798 - val_loss: 0.7269 - val_binary_accuracy: 0.5025\n",
      "Epoch 14/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6772 - binary_accuracy: 0.5604 - val_loss: 0.6974 - val_binary_accuracy: 0.5529\n",
      "Epoch 15/600\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6725 - binary_accuracy: 0.5798 - val_loss: 0.7007 - val_binary_accuracy: 0.5258\n",
      "Epoch 16/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6740 - binary_accuracy: 0.5790 - val_loss: 0.7275 - val_binary_accuracy: 0.4830\n",
      "Epoch 17/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6749 - binary_accuracy: 0.5717 - val_loss: 0.7055 - val_binary_accuracy: 0.5296\n",
      "Epoch 18/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6718 - binary_accuracy: 0.5709 - val_loss: 0.7146 - val_binary_accuracy: 0.5151\n",
      "Epoch 19/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6684 - binary_accuracy: 0.5712 - val_loss: 0.7090 - val_binary_accuracy: 0.5139\n",
      "Epoch 20/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6727 - binary_accuracy: 0.5714 - val_loss: 0.7077 - val_binary_accuracy: 0.5548\n",
      "Epoch 21/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6688 - binary_accuracy: 0.5871 - val_loss: 0.7177 - val_binary_accuracy: 0.5220\n",
      "Epoch 22/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6703 - binary_accuracy: 0.5752 - val_loss: 0.7110 - val_binary_accuracy: 0.5290\n",
      "Epoch 23/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6716 - binary_accuracy: 0.5817 - val_loss: 0.7436 - val_binary_accuracy: 0.4698\n",
      "Epoch 24/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6722 - binary_accuracy: 0.5712 - val_loss: 0.7382 - val_binary_accuracy: 0.5031\n",
      "Epoch 25/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6654 - binary_accuracy: 0.5920 - val_loss: 0.7133 - val_binary_accuracy: 0.5107\n",
      "Epoch 26/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6700 - binary_accuracy: 0.5879 - val_loss: 0.7436 - val_binary_accuracy: 0.4647\n",
      "Epoch 27/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6662 - binary_accuracy: 0.5920 - val_loss: 0.7218 - val_binary_accuracy: 0.5082\n",
      "Epoch 28/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6691 - binary_accuracy: 0.5849 - val_loss: 0.7597 - val_binary_accuracy: 0.5214\n",
      "Epoch 29/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6652 - binary_accuracy: 0.5903 - val_loss: 0.7438 - val_binary_accuracy: 0.5126\n",
      "Epoch 30/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6650 - binary_accuracy: 0.5849 - val_loss: 0.7262 - val_binary_accuracy: 0.4975\n",
      "Epoch 31/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6594 - binary_accuracy: 0.5925 - val_loss: 0.7264 - val_binary_accuracy: 0.4906\n",
      "Epoch 32/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6613 - binary_accuracy: 0.5955 - val_loss: 0.7322 - val_binary_accuracy: 0.5120\n",
      "Epoch 33/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6619 - binary_accuracy: 0.5922 - val_loss: 0.7060 - val_binary_accuracy: 0.5491\n",
      "Epoch 34/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6553 - binary_accuracy: 0.6028 - val_loss: 0.7311 - val_binary_accuracy: 0.5214\n",
      "Epoch 35/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6649 - binary_accuracy: 0.5979 - val_loss: 0.7477 - val_binary_accuracy: 0.4805\n",
      "Epoch 36/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6587 - binary_accuracy: 0.6044 - val_loss: 0.7328 - val_binary_accuracy: 0.4874\n",
      "Epoch 37/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6566 - binary_accuracy: 0.6071 - val_loss: 0.7888 - val_binary_accuracy: 0.4503\n",
      "Epoch 38/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6587 - binary_accuracy: 0.6071 - val_loss: 0.7609 - val_binary_accuracy: 0.4622\n",
      "Epoch 39/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6605 - binary_accuracy: 0.5930 - val_loss: 0.7414 - val_binary_accuracy: 0.4553\n",
      "Epoch 40/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6552 - binary_accuracy: 0.5974 - val_loss: 0.8222 - val_binary_accuracy: 0.4301\n",
      "Epoch 41/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6553 - binary_accuracy: 0.6038 - val_loss: 0.7208 - val_binary_accuracy: 0.5239\n",
      "Epoch 42/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6568 - binary_accuracy: 0.6055 - val_loss: 0.7617 - val_binary_accuracy: 0.4345\n",
      "Epoch 43/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6551 - binary_accuracy: 0.6065 - val_loss: 0.7571 - val_binary_accuracy: 0.4698\n",
      "Epoch 44/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6555 - binary_accuracy: 0.6052 - val_loss: 0.7676 - val_binary_accuracy: 0.4509\n",
      "Epoch 45/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6565 - binary_accuracy: 0.5971 - val_loss: 0.7299 - val_binary_accuracy: 0.4723\n",
      "Epoch 46/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6559 - binary_accuracy: 0.6014 - val_loss: 0.7701 - val_binary_accuracy: 0.4559\n",
      "Epoch 47/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6573 - binary_accuracy: 0.6030 - val_loss: 0.8169 - val_binary_accuracy: 0.4773\n",
      "Epoch 48/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6557 - binary_accuracy: 0.6033 - val_loss: 0.7820 - val_binary_accuracy: 0.4427\n",
      "Epoch 49/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6580 - binary_accuracy: 0.6073 - val_loss: 0.7073 - val_binary_accuracy: 0.5031\n",
      "Epoch 50/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6560 - binary_accuracy: 0.5998 - val_loss: 0.7357 - val_binary_accuracy: 0.5000\n",
      "Epoch 51/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6502 - binary_accuracy: 0.6122 - val_loss: 0.7492 - val_binary_accuracy: 0.5038\n",
      "Epoch 52/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6529 - binary_accuracy: 0.6117 - val_loss: 0.7465 - val_binary_accuracy: 0.5069\n",
      "Epoch 53/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6573 - binary_accuracy: 0.6049 - val_loss: 0.7543 - val_binary_accuracy: 0.4591\n",
      "Epoch 54/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6514 - binary_accuracy: 0.6073 - val_loss: 0.7774 - val_binary_accuracy: 0.4320\n",
      "Epoch 55/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6504 - binary_accuracy: 0.6173 - val_loss: 0.7326 - val_binary_accuracy: 0.5233\n",
      "Epoch 56/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6524 - binary_accuracy: 0.6073 - val_loss: 0.7827 - val_binary_accuracy: 0.4597\n",
      "Epoch 57/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6544 - binary_accuracy: 0.6071 - val_loss: 0.7857 - val_binary_accuracy: 0.4395\n",
      "Epoch 58/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6490 - binary_accuracy: 0.6238 - val_loss: 0.7478 - val_binary_accuracy: 0.4855\n",
      "Epoch 59/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6470 - binary_accuracy: 0.6192 - val_loss: 0.7535 - val_binary_accuracy: 0.4666\n",
      "Epoch 60/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6473 - binary_accuracy: 0.6173 - val_loss: 0.7114 - val_binary_accuracy: 0.5189\n",
      "Epoch 61/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6471 - binary_accuracy: 0.6235 - val_loss: 0.7466 - val_binary_accuracy: 0.4729\n",
      "Epoch 62/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6524 - binary_accuracy: 0.6154 - val_loss: 0.7238 - val_binary_accuracy: 0.5264\n",
      "Epoch 63/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6499 - binary_accuracy: 0.6192 - val_loss: 0.7232 - val_binary_accuracy: 0.4679\n",
      "Epoch 64/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6443 - binary_accuracy: 0.6171 - val_loss: 0.7529 - val_binary_accuracy: 0.4553\n",
      "Epoch 65/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6470 - binary_accuracy: 0.6238 - val_loss: 0.7205 - val_binary_accuracy: 0.5202\n",
      "Epoch 66/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6480 - binary_accuracy: 0.6125 - val_loss: 0.7308 - val_binary_accuracy: 0.5447\n",
      "Epoch 67/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6470 - binary_accuracy: 0.6211 - val_loss: 0.7245 - val_binary_accuracy: 0.4836\n",
      "Epoch 68/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6440 - binary_accuracy: 0.6230 - val_loss: 0.7553 - val_binary_accuracy: 0.5113\n",
      "Epoch 69/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6460 - binary_accuracy: 0.6257 - val_loss: 0.7543 - val_binary_accuracy: 0.4824\n",
      "Epoch 70/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6479 - binary_accuracy: 0.6163 - val_loss: 0.7481 - val_binary_accuracy: 0.4528\n",
      "Epoch 71/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6496 - binary_accuracy: 0.6109 - val_loss: 0.7220 - val_binary_accuracy: 0.5296\n",
      "Epoch 72/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6418 - binary_accuracy: 0.6252 - val_loss: 0.7428 - val_binary_accuracy: 0.5076\n",
      "Epoch 73/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6440 - binary_accuracy: 0.6235 - val_loss: 0.7665 - val_binary_accuracy: 0.4465\n",
      "Epoch 74/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6390 - binary_accuracy: 0.6287 - val_loss: 0.7787 - val_binary_accuracy: 0.4484\n",
      "Epoch 75/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6479 - binary_accuracy: 0.6200 - val_loss: 0.7706 - val_binary_accuracy: 0.5120\n",
      "Epoch 76/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6470 - binary_accuracy: 0.6211 - val_loss: 0.7704 - val_binary_accuracy: 0.4610\n",
      "Epoch 77/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6393 - binary_accuracy: 0.6327 - val_loss: 0.7453 - val_binary_accuracy: 0.4912\n",
      "Epoch 78/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6353 - binary_accuracy: 0.6349 - val_loss: 0.7765 - val_binary_accuracy: 0.4849\n",
      "Epoch 79/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6439 - binary_accuracy: 0.6111 - val_loss: 0.7628 - val_binary_accuracy: 0.5013\n",
      "Epoch 80/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6431 - binary_accuracy: 0.6292 - val_loss: 0.7526 - val_binary_accuracy: 0.5113\n",
      "Epoch 81/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6359 - binary_accuracy: 0.6327 - val_loss: 0.7862 - val_binary_accuracy: 0.4490\n",
      "Epoch 82/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6347 - binary_accuracy: 0.6346 - val_loss: 0.7541 - val_binary_accuracy: 0.4710\n",
      "Epoch 83/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6358 - binary_accuracy: 0.6395 - val_loss: 0.7875 - val_binary_accuracy: 0.4912\n",
      "Epoch 84/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6366 - binary_accuracy: 0.6327 - val_loss: 0.7406 - val_binary_accuracy: 0.4924\n",
      "Epoch 85/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6363 - binary_accuracy: 0.6303 - val_loss: 0.7256 - val_binary_accuracy: 0.5258\n",
      "Epoch 86/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6343 - binary_accuracy: 0.6273 - val_loss: 0.7835 - val_binary_accuracy: 0.4528\n",
      "Epoch 87/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6415 - binary_accuracy: 0.6306 - val_loss: 0.8042 - val_binary_accuracy: 0.4679\n",
      "Epoch 88/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6346 - binary_accuracy: 0.6319 - val_loss: 0.7704 - val_binary_accuracy: 0.4798\n",
      "Epoch 89/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6387 - binary_accuracy: 0.6249 - val_loss: 0.8005 - val_binary_accuracy: 0.4055\n",
      "Epoch 90/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6345 - binary_accuracy: 0.6319 - val_loss: 0.7268 - val_binary_accuracy: 0.5277\n",
      "Epoch 91/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6343 - binary_accuracy: 0.6360 - val_loss: 0.7717 - val_binary_accuracy: 0.4339\n",
      "Epoch 92/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6314 - binary_accuracy: 0.6460 - val_loss: 0.7603 - val_binary_accuracy: 0.4861\n",
      "Epoch 93/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6352 - binary_accuracy: 0.6352 - val_loss: 0.7405 - val_binary_accuracy: 0.5031\n",
      "Epoch 94/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6319 - binary_accuracy: 0.6403 - val_loss: 0.7545 - val_binary_accuracy: 0.4647\n",
      "Epoch 95/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6391 - binary_accuracy: 0.6284 - val_loss: 0.7527 - val_binary_accuracy: 0.4931\n",
      "Epoch 96/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6306 - binary_accuracy: 0.6406 - val_loss: 0.7696 - val_binary_accuracy: 0.4855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6291 - binary_accuracy: 0.6408 - val_loss: 0.8089 - val_binary_accuracy: 0.4679\n",
      "Epoch 98/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6316 - binary_accuracy: 0.6403 - val_loss: 0.7767 - val_binary_accuracy: 0.5013\n",
      "Epoch 99/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6337 - binary_accuracy: 0.6379 - val_loss: 0.7968 - val_binary_accuracy: 0.4377\n",
      "Epoch 100/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6351 - binary_accuracy: 0.6379 - val_loss: 0.7541 - val_binary_accuracy: 0.4912\n",
      "Epoch 101/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6312 - binary_accuracy: 0.6352 - val_loss: 0.7419 - val_binary_accuracy: 0.5258\n",
      "Epoch 102/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6334 - binary_accuracy: 0.6352 - val_loss: 0.7396 - val_binary_accuracy: 0.5076\n",
      "Epoch 103/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6288 - binary_accuracy: 0.6414 - val_loss: 0.8104 - val_binary_accuracy: 0.4748\n",
      "Epoch 104/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6328 - binary_accuracy: 0.6314 - val_loss: 0.7958 - val_binary_accuracy: 0.5088\n",
      "Epoch 105/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6278 - binary_accuracy: 0.6395 - val_loss: 0.7739 - val_binary_accuracy: 0.4830\n",
      "Epoch 106/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6273 - binary_accuracy: 0.6416 - val_loss: 0.7892 - val_binary_accuracy: 0.4465\n",
      "Epoch 107/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6321 - binary_accuracy: 0.6384 - val_loss: 0.7906 - val_binary_accuracy: 0.4534\n",
      "Epoch 108/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6380 - binary_accuracy: 0.6295 - val_loss: 0.7733 - val_binary_accuracy: 0.5164\n",
      "Epoch 109/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6330 - binary_accuracy: 0.6311 - val_loss: 0.8046 - val_binary_accuracy: 0.4351\n",
      "Epoch 110/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6331 - binary_accuracy: 0.6384 - val_loss: 0.7692 - val_binary_accuracy: 0.4780\n",
      "Epoch 111/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6296 - binary_accuracy: 0.6457 - val_loss: 0.7781 - val_binary_accuracy: 0.5025\n",
      "Epoch 112/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6297 - binary_accuracy: 0.6349 - val_loss: 0.7907 - val_binary_accuracy: 0.4364\n",
      "Epoch 113/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6314 - binary_accuracy: 0.6338 - val_loss: 0.7575 - val_binary_accuracy: 0.5107\n",
      "Epoch 114/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6301 - binary_accuracy: 0.6506 - val_loss: 0.8006 - val_binary_accuracy: 0.4622\n",
      "Epoch 115/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6235 - binary_accuracy: 0.6476 - val_loss: 0.7851 - val_binary_accuracy: 0.4673\n",
      "Epoch 116/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6280 - binary_accuracy: 0.6314 - val_loss: 0.7806 - val_binary_accuracy: 0.4874\n",
      "Epoch 117/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6257 - binary_accuracy: 0.6433 - val_loss: 0.7688 - val_binary_accuracy: 0.4742\n",
      "Epoch 118/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6245 - binary_accuracy: 0.6441 - val_loss: 0.7613 - val_binary_accuracy: 0.5006\n",
      "Epoch 119/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6278 - binary_accuracy: 0.6452 - val_loss: 0.8287 - val_binary_accuracy: 0.4849\n",
      "Epoch 120/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6256 - binary_accuracy: 0.6473 - val_loss: 0.8281 - val_binary_accuracy: 0.4962\n",
      "Epoch 121/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6261 - binary_accuracy: 0.6508 - val_loss: 0.7794 - val_binary_accuracy: 0.4736\n",
      "Epoch 122/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6306 - binary_accuracy: 0.6371 - val_loss: 0.7773 - val_binary_accuracy: 0.5126\n",
      "Epoch 123/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6250 - binary_accuracy: 0.6560 - val_loss: 0.7815 - val_binary_accuracy: 0.4969\n",
      "Epoch 124/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6256 - binary_accuracy: 0.6419 - val_loss: 0.7708 - val_binary_accuracy: 0.4742\n",
      "Epoch 125/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6316 - binary_accuracy: 0.6506 - val_loss: 0.7676 - val_binary_accuracy: 0.4868\n",
      "Epoch 126/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6273 - binary_accuracy: 0.6446 - val_loss: 0.8797 - val_binary_accuracy: 0.5082\n",
      "Epoch 127/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6251 - binary_accuracy: 0.6506 - val_loss: 0.7581 - val_binary_accuracy: 0.4918\n",
      "Epoch 128/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6287 - binary_accuracy: 0.6457 - val_loss: 0.7431 - val_binary_accuracy: 0.5057\n",
      "Epoch 129/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6221 - binary_accuracy: 0.6508 - val_loss: 0.7958 - val_binary_accuracy: 0.4811\n",
      "Epoch 130/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6226 - binary_accuracy: 0.6438 - val_loss: 0.7867 - val_binary_accuracy: 0.4893\n",
      "Epoch 131/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6222 - binary_accuracy: 0.6527 - val_loss: 0.7614 - val_binary_accuracy: 0.5120\n",
      "Epoch 132/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6242 - binary_accuracy: 0.6465 - val_loss: 0.7742 - val_binary_accuracy: 0.4836\n",
      "Epoch 133/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6277 - binary_accuracy: 0.6414 - val_loss: 0.7984 - val_binary_accuracy: 0.4402\n",
      "Epoch 134/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6236 - binary_accuracy: 0.6452 - val_loss: 0.7835 - val_binary_accuracy: 0.5094\n",
      "Epoch 135/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6225 - binary_accuracy: 0.6497 - val_loss: 0.7725 - val_binary_accuracy: 0.4931\n",
      "Epoch 136/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6211 - binary_accuracy: 0.6422 - val_loss: 0.8063 - val_binary_accuracy: 0.4616\n",
      "Epoch 137/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6301 - binary_accuracy: 0.6489 - val_loss: 0.7763 - val_binary_accuracy: 0.4742\n",
      "Epoch 138/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6262 - binary_accuracy: 0.6441 - val_loss: 0.7655 - val_binary_accuracy: 0.5271\n",
      "Epoch 139/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6243 - binary_accuracy: 0.6443 - val_loss: 0.7657 - val_binary_accuracy: 0.4975\n",
      "Epoch 140/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6164 - binary_accuracy: 0.6595 - val_loss: 0.7804 - val_binary_accuracy: 0.5050\n",
      "Epoch 141/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6274 - binary_accuracy: 0.6389 - val_loss: 0.7845 - val_binary_accuracy: 0.5031\n",
      "Epoch 142/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6219 - binary_accuracy: 0.6479 - val_loss: 0.7732 - val_binary_accuracy: 0.4767\n",
      "Epoch 143/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6226 - binary_accuracy: 0.6438 - val_loss: 0.8047 - val_binary_accuracy: 0.4710\n",
      "Epoch 144/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6278 - binary_accuracy: 0.6398 - val_loss: 0.8012 - val_binary_accuracy: 0.4748\n",
      "Epoch 145/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6232 - binary_accuracy: 0.6430 - val_loss: 0.8224 - val_binary_accuracy: 0.4868\n",
      "Epoch 146/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6288 - binary_accuracy: 0.6365 - val_loss: 0.7992 - val_binary_accuracy: 0.4660\n",
      "Epoch 147/600\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6235 - binary_accuracy: 0.6462 - val_loss: 0.7603 - val_binary_accuracy: 0.5145\n",
      "Epoch 148/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6213 - binary_accuracy: 0.6530 - val_loss: 0.7806 - val_binary_accuracy: 0.4956\n",
      "Epoch 149/600\n",
      " 55/116 [=============>................] - ETA: 0s - loss: 0.6206 - binary_accuracy: 0.6597"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5936/366822637.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m historyValence = modelValence.fit(\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Get target variables: emotion and valence\n",
    "z = Data_train.Valence\n",
    "y = Data_train.Emotion\n",
    "X = pd.DataFrame(Data_train.drop(['Emotion','User', 'Valence'], axis = 1))\n",
    "\n",
    "#find valence\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "modelValence = initModelValence(X.shape[1], 1)\n",
    "modelValence.compile(\n",
    "    optimizer= 'adam',\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=[ 'binary_accuracy']\n",
    ")\n",
    "\n",
    "historyValence = modelValence.fit(\n",
    "    X,\n",
    "    z,\n",
    "    validation_split = 0.3,\n",
    "    #validation_data = (X_val, y_val),\n",
    "    #validation_data = (X_test, y_test),\n",
    "    epochs=600,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_binary_accuracy',\n",
    "            patience=150,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_acc = modelValence.evaluate(X, z, verbose=0)[1]\n",
    "print(\"Accuracy of the valence model: {:.3f}%\".format(model_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed53984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Get target variables: emotion and valence\n",
    "z = Data_train.Valence\n",
    "y = Data_train.Emotion\n",
    "X = pd.DataFrame(Data_train.drop(['Emotion','User', 'Valence'], axis = 1))\n",
    "\n",
    "#find valence\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "modelValence = initModelValence(X.shape[1], 2)\n",
    "modelValence.compile(\n",
    "    optimizer= 'adam',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=[ 'sparse_categorical_accuracy']\n",
    ")\n",
    "\n",
    "historyValence = modelValence.fit(\n",
    "    X,\n",
    "    z,\n",
    "    validation_split = 0.3,\n",
    "    #validation_data = (X_val, y_val),\n",
    "    #validation_data = (X_test, y_test),\n",
    "    epochs=600,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_sparse_categorical_accuracy',\n",
    "            patience=75,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_acc = modelValence.evaluate(X, z, verbose=0)[1]\n",
    "print(\"Accuracy of the valence model: {:.3f}%\".format(model_acc * 100))\n",
    "\n",
    "Data_valence = modelValence.predict(X)\n",
    "Data_valence = [(np.argmax(pre)) for pre in Data_valence]\n",
    "#print(Data_valence, z)\n",
    "\n",
    "X = pd.concat([X, pd.DataFrame(Data_valence, columns = ['Valence'])], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 123)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 123)\n",
    "\n",
    "\n",
    "\n",
    "model = initModelBasic(X.shape[1], 7)\n",
    "model.compile(\n",
    "    optimizer= 'adam',\n",
    "    loss='sparse_categorical_crossentropy', # sparse because using integer labels for emotions (not OHE)\n",
    "    metrics=[ 'sparse_categorical_accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    #validation_split = 0.3,\n",
    "    #validation_data = (X_val, y_val),\n",
    "    validation_data = (X_test, y_test),\n",
    "    epochs=600,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_sparse_categorical_accuracy',\n",
    "            patience=75,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Result on test data\n",
    "model_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(\"Accuracy of the model on test set: {:.3f}%\".format(model_acc * 100))\n",
    "\n",
    "#Result on val data\n",
    "model_acc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "print(\"Accuracy of the model on validation set: {:.3f}%\".format(model_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9176b7a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                176       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16)               64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 695\n",
      "Trainable params: 631\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1200\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 2.0209 - sparse_categorical_accuracy: 0.1750 - val_loss: 2.1103 - val_sparse_categorical_accuracy: 0.1845\n",
      "Epoch 2/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.8264 - sparse_categorical_accuracy: 0.2329 - val_loss: 1.8348 - val_sparse_categorical_accuracy: 0.1669\n",
      "Epoch 3/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.6125 - sparse_categorical_accuracy: 0.3139 - val_loss: 2.5472 - val_sparse_categorical_accuracy: 0.1429\n",
      "Epoch 4/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.4232 - sparse_categorical_accuracy: 0.3343 - val_loss: 1.9076 - val_sparse_categorical_accuracy: 0.1757\n",
      "Epoch 5/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.3425 - sparse_categorical_accuracy: 0.3478 - val_loss: 1.2872 - val_sparse_categorical_accuracy: 0.3268\n",
      "Epoch 6/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.3072 - sparse_categorical_accuracy: 0.3604 - val_loss: 1.2700 - val_sparse_categorical_accuracy: 0.3508\n",
      "Epoch 7/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2912 - sparse_categorical_accuracy: 0.3643 - val_loss: 1.2639 - val_sparse_categorical_accuracy: 0.3634\n",
      "Epoch 8/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2744 - sparse_categorical_accuracy: 0.3664 - val_loss: 1.2614 - val_sparse_categorical_accuracy: 0.3627\n",
      "Epoch 9/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2637 - sparse_categorical_accuracy: 0.3736 - val_loss: 1.2492 - val_sparse_categorical_accuracy: 0.3873\n",
      "Epoch 10/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2571 - sparse_categorical_accuracy: 0.3779 - val_loss: 1.2635 - val_sparse_categorical_accuracy: 0.3766\n",
      "Epoch 11/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2534 - sparse_categorical_accuracy: 0.3733 - val_loss: 1.2523 - val_sparse_categorical_accuracy: 0.3866\n",
      "Epoch 12/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2503 - sparse_categorical_accuracy: 0.3800 - val_loss: 1.2458 - val_sparse_categorical_accuracy: 0.3722\n",
      "Epoch 13/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2451 - sparse_categorical_accuracy: 0.3812 - val_loss: 1.2450 - val_sparse_categorical_accuracy: 0.3810\n",
      "Epoch 14/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2436 - sparse_categorical_accuracy: 0.3803 - val_loss: 1.2453 - val_sparse_categorical_accuracy: 0.3728\n",
      "Epoch 15/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.2372 - sparse_categorical_accuracy: 0.3869 - val_loss: 1.2451 - val_sparse_categorical_accuracy: 0.3759\n",
      "Epoch 16/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2351 - sparse_categorical_accuracy: 0.3833 - val_loss: 1.2385 - val_sparse_categorical_accuracy: 0.3829\n",
      "Epoch 17/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2344 - sparse_categorical_accuracy: 0.3935 - val_loss: 1.2359 - val_sparse_categorical_accuracy: 0.3948\n",
      "Epoch 18/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2307 - sparse_categorical_accuracy: 0.3926 - val_loss: 1.2358 - val_sparse_categorical_accuracy: 0.3734\n",
      "Epoch 19/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2293 - sparse_categorical_accuracy: 0.3920 - val_loss: 1.2271 - val_sparse_categorical_accuracy: 0.3804\n",
      "Epoch 20/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2294 - sparse_categorical_accuracy: 0.3860 - val_loss: 1.2333 - val_sparse_categorical_accuracy: 0.3860\n",
      "Epoch 21/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2231 - sparse_categorical_accuracy: 0.3866 - val_loss: 1.2214 - val_sparse_categorical_accuracy: 0.3961\n",
      "Epoch 22/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2255 - sparse_categorical_accuracy: 0.3884 - val_loss: 1.2171 - val_sparse_categorical_accuracy: 0.3929\n",
      "Epoch 23/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2185 - sparse_categorical_accuracy: 0.4034 - val_loss: 1.2165 - val_sparse_categorical_accuracy: 0.4024\n",
      "Epoch 24/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2185 - sparse_categorical_accuracy: 0.3914 - val_loss: 1.2216 - val_sparse_categorical_accuracy: 0.3835\n",
      "Epoch 25/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2169 - sparse_categorical_accuracy: 0.4022 - val_loss: 1.2227 - val_sparse_categorical_accuracy: 0.3961\n",
      "Epoch 26/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2207 - sparse_categorical_accuracy: 0.3917 - val_loss: 1.2242 - val_sparse_categorical_accuracy: 0.3917\n",
      "Epoch 27/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.2164 - sparse_categorical_accuracy: 0.3959 - val_loss: 1.2259 - val_sparse_categorical_accuracy: 0.4087\n",
      "Epoch 28/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2132 - sparse_categorical_accuracy: 0.3983 - val_loss: 1.2208 - val_sparse_categorical_accuracy: 0.3879\n",
      "Epoch 29/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2115 - sparse_categorical_accuracy: 0.3992 - val_loss: 1.2201 - val_sparse_categorical_accuracy: 0.3860\n",
      "Epoch 30/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2142 - sparse_categorical_accuracy: 0.3902 - val_loss: 1.2247 - val_sparse_categorical_accuracy: 0.3948\n",
      "Epoch 31/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2131 - sparse_categorical_accuracy: 0.4019 - val_loss: 1.2120 - val_sparse_categorical_accuracy: 0.3980\n",
      "Epoch 32/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2094 - sparse_categorical_accuracy: 0.4058 - val_loss: 1.2168 - val_sparse_categorical_accuracy: 0.4043\n",
      "Epoch 33/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2077 - sparse_categorical_accuracy: 0.4067 - val_loss: 1.2130 - val_sparse_categorical_accuracy: 0.4037\n",
      "Epoch 34/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2094 - sparse_categorical_accuracy: 0.4007 - val_loss: 1.2369 - val_sparse_categorical_accuracy: 0.3923\n",
      "Epoch 35/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2058 - sparse_categorical_accuracy: 0.4010 - val_loss: 1.2134 - val_sparse_categorical_accuracy: 0.3841\n",
      "Epoch 36/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2115 - sparse_categorical_accuracy: 0.4004 - val_loss: 1.2147 - val_sparse_categorical_accuracy: 0.3904\n",
      "Epoch 37/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2168 - sparse_categorical_accuracy: 0.3953 - val_loss: 1.2127 - val_sparse_categorical_accuracy: 0.3885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.2024 - sparse_categorical_accuracy: 0.4079 - val_loss: 1.2105 - val_sparse_categorical_accuracy: 0.4150\n",
      "Epoch 39/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1984 - sparse_categorical_accuracy: 0.4049 - val_loss: 1.2094 - val_sparse_categorical_accuracy: 0.4030\n",
      "Epoch 40/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2020 - sparse_categorical_accuracy: 0.4127 - val_loss: 1.2099 - val_sparse_categorical_accuracy: 0.4074\n",
      "Epoch 41/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.2027 - sparse_categorical_accuracy: 0.4043 - val_loss: 1.2172 - val_sparse_categorical_accuracy: 0.4018\n",
      "Epoch 42/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1981 - sparse_categorical_accuracy: 0.4064 - val_loss: 1.2068 - val_sparse_categorical_accuracy: 0.4125\n",
      "Epoch 43/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1989 - sparse_categorical_accuracy: 0.4043 - val_loss: 1.2059 - val_sparse_categorical_accuracy: 0.4087\n",
      "Epoch 44/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1974 - sparse_categorical_accuracy: 0.4070 - val_loss: 1.2148 - val_sparse_categorical_accuracy: 0.4106\n",
      "Epoch 45/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1975 - sparse_categorical_accuracy: 0.4175 - val_loss: 1.2060 - val_sparse_categorical_accuracy: 0.4181\n",
      "Epoch 46/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1977 - sparse_categorical_accuracy: 0.4103 - val_loss: 1.2159 - val_sparse_categorical_accuracy: 0.4005\n",
      "Epoch 47/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1898 - sparse_categorical_accuracy: 0.4235 - val_loss: 1.2069 - val_sparse_categorical_accuracy: 0.4137\n",
      "Epoch 48/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.2004 - sparse_categorical_accuracy: 0.4088 - val_loss: 1.2098 - val_sparse_categorical_accuracy: 0.3961\n",
      "Epoch 49/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1979 - sparse_categorical_accuracy: 0.4151 - val_loss: 1.2155 - val_sparse_categorical_accuracy: 0.3999\n",
      "Epoch 50/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1981 - sparse_categorical_accuracy: 0.4130 - val_loss: 1.2073 - val_sparse_categorical_accuracy: 0.3980\n",
      "Epoch 51/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1936 - sparse_categorical_accuracy: 0.4172 - val_loss: 1.2094 - val_sparse_categorical_accuracy: 0.4181\n",
      "Epoch 52/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1874 - sparse_categorical_accuracy: 0.4226 - val_loss: 1.2088 - val_sparse_categorical_accuracy: 0.3992\n",
      "Epoch 53/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1873 - sparse_categorical_accuracy: 0.4124 - val_loss: 1.2065 - val_sparse_categorical_accuracy: 0.4074\n",
      "Epoch 54/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1894 - sparse_categorical_accuracy: 0.4178 - val_loss: 1.2128 - val_sparse_categorical_accuracy: 0.4005\n",
      "Epoch 55/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1894 - sparse_categorical_accuracy: 0.4142 - val_loss: 1.2045 - val_sparse_categorical_accuracy: 0.4219\n",
      "Epoch 56/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1905 - sparse_categorical_accuracy: 0.4157 - val_loss: 1.2003 - val_sparse_categorical_accuracy: 0.4106\n",
      "Epoch 57/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1914 - sparse_categorical_accuracy: 0.4172 - val_loss: 1.2047 - val_sparse_categorical_accuracy: 0.4030\n",
      "Epoch 58/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1920 - sparse_categorical_accuracy: 0.4127 - val_loss: 1.2323 - val_sparse_categorical_accuracy: 0.3974\n",
      "Epoch 59/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1861 - sparse_categorical_accuracy: 0.4184 - val_loss: 1.2056 - val_sparse_categorical_accuracy: 0.4162\n",
      "Epoch 60/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1908 - sparse_categorical_accuracy: 0.4133 - val_loss: 1.2200 - val_sparse_categorical_accuracy: 0.3866\n",
      "Epoch 61/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1822 - sparse_categorical_accuracy: 0.4241 - val_loss: 1.2091 - val_sparse_categorical_accuracy: 0.4074\n",
      "Epoch 62/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1876 - sparse_categorical_accuracy: 0.4148 - val_loss: 1.1993 - val_sparse_categorical_accuracy: 0.4118\n",
      "Epoch 63/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1822 - sparse_categorical_accuracy: 0.4226 - val_loss: 1.2070 - val_sparse_categorical_accuracy: 0.4037\n",
      "Epoch 64/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1788 - sparse_categorical_accuracy: 0.4286 - val_loss: 1.1983 - val_sparse_categorical_accuracy: 0.4213\n",
      "Epoch 65/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1843 - sparse_categorical_accuracy: 0.4199 - val_loss: 1.2190 - val_sparse_categorical_accuracy: 0.3911\n",
      "Epoch 66/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1851 - sparse_categorical_accuracy: 0.4208 - val_loss: 1.2005 - val_sparse_categorical_accuracy: 0.4118\n",
      "Epoch 67/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1811 - sparse_categorical_accuracy: 0.4223 - val_loss: 1.1991 - val_sparse_categorical_accuracy: 0.4087\n",
      "Epoch 68/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1816 - sparse_categorical_accuracy: 0.4274 - val_loss: 1.2166 - val_sparse_categorical_accuracy: 0.3866\n",
      "Epoch 69/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1844 - sparse_categorical_accuracy: 0.4181 - val_loss: 1.2040 - val_sparse_categorical_accuracy: 0.4156\n",
      "Epoch 70/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1749 - sparse_categorical_accuracy: 0.4319 - val_loss: 1.2075 - val_sparse_categorical_accuracy: 0.4062\n",
      "Epoch 71/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1776 - sparse_categorical_accuracy: 0.4232 - val_loss: 1.1994 - val_sparse_categorical_accuracy: 0.3948\n",
      "Epoch 72/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1802 - sparse_categorical_accuracy: 0.4277 - val_loss: 1.2022 - val_sparse_categorical_accuracy: 0.4074\n",
      "Epoch 73/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1740 - sparse_categorical_accuracy: 0.4247 - val_loss: 1.1994 - val_sparse_categorical_accuracy: 0.4005\n",
      "Epoch 74/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1707 - sparse_categorical_accuracy: 0.4319 - val_loss: 1.2007 - val_sparse_categorical_accuracy: 0.4106\n",
      "Epoch 75/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1795 - sparse_categorical_accuracy: 0.4232 - val_loss: 1.1960 - val_sparse_categorical_accuracy: 0.4018\n",
      "Epoch 76/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1749 - sparse_categorical_accuracy: 0.4223 - val_loss: 1.1951 - val_sparse_categorical_accuracy: 0.4150\n",
      "Epoch 77/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1734 - sparse_categorical_accuracy: 0.4337 - val_loss: 1.1933 - val_sparse_categorical_accuracy: 0.4244\n",
      "Epoch 78/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1807 - sparse_categorical_accuracy: 0.4202 - val_loss: 1.1864 - val_sparse_categorical_accuracy: 0.4156\n",
      "Epoch 79/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1773 - sparse_categorical_accuracy: 0.4310 - val_loss: 1.1962 - val_sparse_categorical_accuracy: 0.4005\n",
      "Epoch 80/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1728 - sparse_categorical_accuracy: 0.4283 - val_loss: 1.1831 - val_sparse_categorical_accuracy: 0.4162\n",
      "Epoch 81/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1760 - sparse_categorical_accuracy: 0.4328 - val_loss: 1.1850 - val_sparse_categorical_accuracy: 0.4270\n",
      "Epoch 82/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1754 - sparse_categorical_accuracy: 0.4268 - val_loss: 1.2100 - val_sparse_categorical_accuracy: 0.4081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1717 - sparse_categorical_accuracy: 0.4244 - val_loss: 1.1861 - val_sparse_categorical_accuracy: 0.4301\n",
      "Epoch 84/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1702 - sparse_categorical_accuracy: 0.4343 - val_loss: 1.1959 - val_sparse_categorical_accuracy: 0.4263\n",
      "Epoch 85/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1719 - sparse_categorical_accuracy: 0.4253 - val_loss: 1.2021 - val_sparse_categorical_accuracy: 0.4106\n",
      "Epoch 86/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1692 - sparse_categorical_accuracy: 0.4343 - val_loss: 1.1822 - val_sparse_categorical_accuracy: 0.4395\n",
      "Epoch 87/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1728 - sparse_categorical_accuracy: 0.4337 - val_loss: 1.1787 - val_sparse_categorical_accuracy: 0.4181\n",
      "Epoch 88/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1693 - sparse_categorical_accuracy: 0.4409 - val_loss: 1.1939 - val_sparse_categorical_accuracy: 0.4219\n",
      "Epoch 89/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1764 - sparse_categorical_accuracy: 0.4379 - val_loss: 1.1940 - val_sparse_categorical_accuracy: 0.4225\n",
      "Epoch 90/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1718 - sparse_categorical_accuracy: 0.4397 - val_loss: 1.2020 - val_sparse_categorical_accuracy: 0.4037\n",
      "Epoch 91/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1633 - sparse_categorical_accuracy: 0.4337 - val_loss: 1.1989 - val_sparse_categorical_accuracy: 0.4018\n",
      "Epoch 92/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1695 - sparse_categorical_accuracy: 0.4205 - val_loss: 1.1797 - val_sparse_categorical_accuracy: 0.4282\n",
      "Epoch 93/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1665 - sparse_categorical_accuracy: 0.4388 - val_loss: 1.1950 - val_sparse_categorical_accuracy: 0.4219\n",
      "Epoch 94/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1721 - sparse_categorical_accuracy: 0.4304 - val_loss: 1.2001 - val_sparse_categorical_accuracy: 0.4081\n",
      "Epoch 95/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1711 - sparse_categorical_accuracy: 0.4307 - val_loss: 1.1783 - val_sparse_categorical_accuracy: 0.4125\n",
      "Epoch 96/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1615 - sparse_categorical_accuracy: 0.4403 - val_loss: 1.1811 - val_sparse_categorical_accuracy: 0.4301\n",
      "Epoch 97/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1671 - sparse_categorical_accuracy: 0.4316 - val_loss: 1.1808 - val_sparse_categorical_accuracy: 0.4276\n",
      "Epoch 98/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1653 - sparse_categorical_accuracy: 0.4370 - val_loss: 1.1879 - val_sparse_categorical_accuracy: 0.4068\n",
      "Epoch 99/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1685 - sparse_categorical_accuracy: 0.4292 - val_loss: 1.1791 - val_sparse_categorical_accuracy: 0.4301\n",
      "Epoch 100/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1615 - sparse_categorical_accuracy: 0.4406 - val_loss: 1.1925 - val_sparse_categorical_accuracy: 0.4081\n",
      "Epoch 101/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1655 - sparse_categorical_accuracy: 0.4424 - val_loss: 1.1910 - val_sparse_categorical_accuracy: 0.4232\n",
      "Epoch 102/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1642 - sparse_categorical_accuracy: 0.4274 - val_loss: 1.1740 - val_sparse_categorical_accuracy: 0.4364\n",
      "Epoch 103/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1576 - sparse_categorical_accuracy: 0.4367 - val_loss: 1.1755 - val_sparse_categorical_accuracy: 0.4446\n",
      "Epoch 104/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1659 - sparse_categorical_accuracy: 0.4409 - val_loss: 1.1884 - val_sparse_categorical_accuracy: 0.4099\n",
      "Epoch 105/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1610 - sparse_categorical_accuracy: 0.4406 - val_loss: 1.2033 - val_sparse_categorical_accuracy: 0.4106\n",
      "Epoch 106/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1589 - sparse_categorical_accuracy: 0.4445 - val_loss: 1.1766 - val_sparse_categorical_accuracy: 0.4332\n",
      "Epoch 107/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1656 - sparse_categorical_accuracy: 0.4373 - val_loss: 1.1738 - val_sparse_categorical_accuracy: 0.4131\n",
      "Epoch 108/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1620 - sparse_categorical_accuracy: 0.4376 - val_loss: 1.1803 - val_sparse_categorical_accuracy: 0.4351\n",
      "Epoch 109/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1656 - sparse_categorical_accuracy: 0.4469 - val_loss: 1.1887 - val_sparse_categorical_accuracy: 0.4244\n",
      "Epoch 110/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1608 - sparse_categorical_accuracy: 0.4337 - val_loss: 1.1684 - val_sparse_categorical_accuracy: 0.4395\n",
      "Epoch 111/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1593 - sparse_categorical_accuracy: 0.4373 - val_loss: 1.1700 - val_sparse_categorical_accuracy: 0.4225\n",
      "Epoch 112/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1606 - sparse_categorical_accuracy: 0.4346 - val_loss: 1.1724 - val_sparse_categorical_accuracy: 0.4314\n",
      "Epoch 113/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1696 - sparse_categorical_accuracy: 0.4181 - val_loss: 1.1855 - val_sparse_categorical_accuracy: 0.4106\n",
      "Epoch 114/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1578 - sparse_categorical_accuracy: 0.4382 - val_loss: 1.1733 - val_sparse_categorical_accuracy: 0.4257\n",
      "Epoch 115/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1634 - sparse_categorical_accuracy: 0.4307 - val_loss: 1.1932 - val_sparse_categorical_accuracy: 0.4225\n",
      "Epoch 116/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1688 - sparse_categorical_accuracy: 0.4265 - val_loss: 1.1787 - val_sparse_categorical_accuracy: 0.4288\n",
      "Epoch 117/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1590 - sparse_categorical_accuracy: 0.4334 - val_loss: 1.1840 - val_sparse_categorical_accuracy: 0.4276\n",
      "Epoch 118/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1478 - sparse_categorical_accuracy: 0.4493 - val_loss: 1.1714 - val_sparse_categorical_accuracy: 0.4358\n",
      "Epoch 119/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1544 - sparse_categorical_accuracy: 0.4484 - val_loss: 1.1975 - val_sparse_categorical_accuracy: 0.4169\n",
      "Epoch 120/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1522 - sparse_categorical_accuracy: 0.4490 - val_loss: 1.1678 - val_sparse_categorical_accuracy: 0.4414\n",
      "Epoch 121/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1523 - sparse_categorical_accuracy: 0.4319 - val_loss: 1.1655 - val_sparse_categorical_accuracy: 0.4465\n",
      "Epoch 122/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1587 - sparse_categorical_accuracy: 0.4370 - val_loss: 1.1770 - val_sparse_categorical_accuracy: 0.4395\n",
      "Epoch 123/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1530 - sparse_categorical_accuracy: 0.4421 - val_loss: 1.2212 - val_sparse_categorical_accuracy: 0.4005\n",
      "Epoch 124/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1621 - sparse_categorical_accuracy: 0.4358 - val_loss: 1.1903 - val_sparse_categorical_accuracy: 0.4181\n",
      "Epoch 125/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1540 - sparse_categorical_accuracy: 0.4445 - val_loss: 1.1905 - val_sparse_categorical_accuracy: 0.4106\n",
      "Epoch 126/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1560 - sparse_categorical_accuracy: 0.4382 - val_loss: 1.1706 - val_sparse_categorical_accuracy: 0.4458\n",
      "Epoch 127/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1512 - sparse_categorical_accuracy: 0.4493 - val_loss: 1.1540 - val_sparse_categorical_accuracy: 0.4490\n",
      "Epoch 128/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1622 - sparse_categorical_accuracy: 0.4418 - val_loss: 1.1630 - val_sparse_categorical_accuracy: 0.4339\n",
      "Epoch 129/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1575 - sparse_categorical_accuracy: 0.4442 - val_loss: 1.1630 - val_sparse_categorical_accuracy: 0.4207\n",
      "Epoch 130/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1530 - sparse_categorical_accuracy: 0.4397 - val_loss: 1.1781 - val_sparse_categorical_accuracy: 0.4181\n",
      "Epoch 131/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1579 - sparse_categorical_accuracy: 0.4466 - val_loss: 1.1693 - val_sparse_categorical_accuracy: 0.4452\n",
      "Epoch 132/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1520 - sparse_categorical_accuracy: 0.4646 - val_loss: 1.1672 - val_sparse_categorical_accuracy: 0.4377\n",
      "Epoch 133/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1477 - sparse_categorical_accuracy: 0.4499 - val_loss: 1.1830 - val_sparse_categorical_accuracy: 0.4288\n",
      "Epoch 134/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1544 - sparse_categorical_accuracy: 0.4370 - val_loss: 1.1893 - val_sparse_categorical_accuracy: 0.4213\n",
      "Epoch 135/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1479 - sparse_categorical_accuracy: 0.4457 - val_loss: 1.1633 - val_sparse_categorical_accuracy: 0.4484\n",
      "Epoch 136/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1627 - sparse_categorical_accuracy: 0.4532 - val_loss: 1.1677 - val_sparse_categorical_accuracy: 0.4358\n",
      "Epoch 137/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1506 - sparse_categorical_accuracy: 0.4466 - val_loss: 1.1660 - val_sparse_categorical_accuracy: 0.4402\n",
      "Epoch 138/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1493 - sparse_categorical_accuracy: 0.4499 - val_loss: 1.1674 - val_sparse_categorical_accuracy: 0.4364\n",
      "Epoch 139/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1458 - sparse_categorical_accuracy: 0.4478 - val_loss: 1.1734 - val_sparse_categorical_accuracy: 0.4276\n",
      "Epoch 140/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1457 - sparse_categorical_accuracy: 0.4409 - val_loss: 1.1620 - val_sparse_categorical_accuracy: 0.4521\n",
      "Epoch 141/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1525 - sparse_categorical_accuracy: 0.4430 - val_loss: 1.1576 - val_sparse_categorical_accuracy: 0.4427\n",
      "Epoch 142/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1517 - sparse_categorical_accuracy: 0.4487 - val_loss: 1.1658 - val_sparse_categorical_accuracy: 0.4238\n",
      "Epoch 143/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1562 - sparse_categorical_accuracy: 0.4412 - val_loss: 1.1862 - val_sparse_categorical_accuracy: 0.4200\n",
      "Epoch 144/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1602 - sparse_categorical_accuracy: 0.4385 - val_loss: 1.1609 - val_sparse_categorical_accuracy: 0.4326\n",
      "Epoch 145/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1540 - sparse_categorical_accuracy: 0.4418 - val_loss: 1.1857 - val_sparse_categorical_accuracy: 0.4200\n",
      "Epoch 146/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1483 - sparse_categorical_accuracy: 0.4454 - val_loss: 1.1626 - val_sparse_categorical_accuracy: 0.4446\n",
      "Epoch 147/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1438 - sparse_categorical_accuracy: 0.4499 - val_loss: 1.1910 - val_sparse_categorical_accuracy: 0.4270\n",
      "Epoch 148/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1489 - sparse_categorical_accuracy: 0.4553 - val_loss: 1.1630 - val_sparse_categorical_accuracy: 0.4332\n",
      "Epoch 149/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1423 - sparse_categorical_accuracy: 0.4493 - val_loss: 1.1744 - val_sparse_categorical_accuracy: 0.4345\n",
      "Epoch 150/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1469 - sparse_categorical_accuracy: 0.4508 - val_loss: 1.1574 - val_sparse_categorical_accuracy: 0.4521\n",
      "Epoch 151/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1494 - sparse_categorical_accuracy: 0.4328 - val_loss: 1.1660 - val_sparse_categorical_accuracy: 0.4503\n",
      "Epoch 152/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1425 - sparse_categorical_accuracy: 0.4547 - val_loss: 1.1769 - val_sparse_categorical_accuracy: 0.4484\n",
      "Epoch 153/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1465 - sparse_categorical_accuracy: 0.4547 - val_loss: 1.1634 - val_sparse_categorical_accuracy: 0.4433\n",
      "Epoch 154/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1451 - sparse_categorical_accuracy: 0.4460 - val_loss: 1.1764 - val_sparse_categorical_accuracy: 0.4263\n",
      "Epoch 155/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1457 - sparse_categorical_accuracy: 0.4493 - val_loss: 1.1532 - val_sparse_categorical_accuracy: 0.4465\n",
      "Epoch 156/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1456 - sparse_categorical_accuracy: 0.4550 - val_loss: 1.1679 - val_sparse_categorical_accuracy: 0.4440\n",
      "Epoch 157/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1360 - sparse_categorical_accuracy: 0.4595 - val_loss: 1.1944 - val_sparse_categorical_accuracy: 0.4200\n",
      "Epoch 158/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1387 - sparse_categorical_accuracy: 0.4418 - val_loss: 1.1660 - val_sparse_categorical_accuracy: 0.4383\n",
      "Epoch 159/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1480 - sparse_categorical_accuracy: 0.4469 - val_loss: 1.1622 - val_sparse_categorical_accuracy: 0.4458\n",
      "Epoch 160/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1452 - sparse_categorical_accuracy: 0.4505 - val_loss: 1.1779 - val_sparse_categorical_accuracy: 0.4351\n",
      "Epoch 161/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1482 - sparse_categorical_accuracy: 0.4460 - val_loss: 1.1716 - val_sparse_categorical_accuracy: 0.4276\n",
      "Epoch 162/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1493 - sparse_categorical_accuracy: 0.4400 - val_loss: 1.1545 - val_sparse_categorical_accuracy: 0.4528\n",
      "Epoch 163/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1418 - sparse_categorical_accuracy: 0.4559 - val_loss: 1.1627 - val_sparse_categorical_accuracy: 0.4383\n",
      "Epoch 164/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1447 - sparse_categorical_accuracy: 0.4511 - val_loss: 1.1473 - val_sparse_categorical_accuracy: 0.4408\n",
      "Epoch 165/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1438 - sparse_categorical_accuracy: 0.4466 - val_loss: 1.1629 - val_sparse_categorical_accuracy: 0.4358\n",
      "Epoch 166/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1452 - sparse_categorical_accuracy: 0.4484 - val_loss: 1.1436 - val_sparse_categorical_accuracy: 0.4477\n",
      "Epoch 167/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1328 - sparse_categorical_accuracy: 0.4601 - val_loss: 1.1558 - val_sparse_categorical_accuracy: 0.4458\n",
      "Epoch 168/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1351 - sparse_categorical_accuracy: 0.4487 - val_loss: 1.1592 - val_sparse_categorical_accuracy: 0.4465\n",
      "Epoch 169/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1488 - sparse_categorical_accuracy: 0.4526 - val_loss: 1.1593 - val_sparse_categorical_accuracy: 0.4414\n",
      "Epoch 170/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1384 - sparse_categorical_accuracy: 0.4505 - val_loss: 1.1567 - val_sparse_categorical_accuracy: 0.4477\n",
      "Epoch 171/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1473 - sparse_categorical_accuracy: 0.4496 - val_loss: 1.1487 - val_sparse_categorical_accuracy: 0.4603\n",
      "Epoch 172/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1393 - sparse_categorical_accuracy: 0.4538 - val_loss: 1.1438 - val_sparse_categorical_accuracy: 0.4521\n",
      "Epoch 173/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1388 - sparse_categorical_accuracy: 0.4562 - val_loss: 1.1742 - val_sparse_categorical_accuracy: 0.4270\n",
      "Epoch 174/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1583 - sparse_categorical_accuracy: 0.4454 - val_loss: 1.1553 - val_sparse_categorical_accuracy: 0.4370\n",
      "Epoch 175/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1427 - sparse_categorical_accuracy: 0.4553 - val_loss: 1.1451 - val_sparse_categorical_accuracy: 0.4547\n",
      "Epoch 176/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1504 - sparse_categorical_accuracy: 0.4442 - val_loss: 1.1446 - val_sparse_categorical_accuracy: 0.4515\n",
      "Epoch 177/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1465 - sparse_categorical_accuracy: 0.4481 - val_loss: 1.1678 - val_sparse_categorical_accuracy: 0.4503\n",
      "Epoch 178/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1404 - sparse_categorical_accuracy: 0.4523 - val_loss: 1.1476 - val_sparse_categorical_accuracy: 0.4503\n",
      "Epoch 179/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1462 - sparse_categorical_accuracy: 0.4469 - val_loss: 1.1582 - val_sparse_categorical_accuracy: 0.4345\n",
      "Epoch 180/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1449 - sparse_categorical_accuracy: 0.4523 - val_loss: 1.1388 - val_sparse_categorical_accuracy: 0.4761\n",
      "Epoch 181/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1391 - sparse_categorical_accuracy: 0.4490 - val_loss: 1.1614 - val_sparse_categorical_accuracy: 0.4572\n",
      "Epoch 182/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1359 - sparse_categorical_accuracy: 0.4505 - val_loss: 1.1420 - val_sparse_categorical_accuracy: 0.4389\n",
      "Epoch 183/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1450 - sparse_categorical_accuracy: 0.4604 - val_loss: 1.1675 - val_sparse_categorical_accuracy: 0.4345\n",
      "Epoch 184/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1496 - sparse_categorical_accuracy: 0.4505 - val_loss: 1.1600 - val_sparse_categorical_accuracy: 0.4358\n",
      "Epoch 185/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1451 - sparse_categorical_accuracy: 0.4517 - val_loss: 1.1418 - val_sparse_categorical_accuracy: 0.4515\n",
      "Epoch 186/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1404 - sparse_categorical_accuracy: 0.4523 - val_loss: 1.1664 - val_sparse_categorical_accuracy: 0.4446\n",
      "Epoch 187/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1402 - sparse_categorical_accuracy: 0.4514 - val_loss: 1.1368 - val_sparse_categorical_accuracy: 0.4534\n",
      "Epoch 188/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1445 - sparse_categorical_accuracy: 0.4508 - val_loss: 1.1519 - val_sparse_categorical_accuracy: 0.4534\n",
      "Epoch 189/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1439 - sparse_categorical_accuracy: 0.4670 - val_loss: 1.1847 - val_sparse_categorical_accuracy: 0.4118\n",
      "Epoch 190/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1421 - sparse_categorical_accuracy: 0.4538 - val_loss: 1.1450 - val_sparse_categorical_accuracy: 0.4578\n",
      "Epoch 191/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1438 - sparse_categorical_accuracy: 0.4550 - val_loss: 1.1569 - val_sparse_categorical_accuracy: 0.4578\n",
      "Epoch 192/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1366 - sparse_categorical_accuracy: 0.4586 - val_loss: 1.1453 - val_sparse_categorical_accuracy: 0.4395\n",
      "Epoch 193/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1405 - sparse_categorical_accuracy: 0.4538 - val_loss: 1.1473 - val_sparse_categorical_accuracy: 0.4559\n",
      "Epoch 194/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1353 - sparse_categorical_accuracy: 0.4538 - val_loss: 1.1487 - val_sparse_categorical_accuracy: 0.4572\n",
      "Epoch 195/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1413 - sparse_categorical_accuracy: 0.4538 - val_loss: 1.1933 - val_sparse_categorical_accuracy: 0.4440\n",
      "Epoch 196/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1449 - sparse_categorical_accuracy: 0.4553 - val_loss: 1.1473 - val_sparse_categorical_accuracy: 0.4496\n",
      "Epoch 197/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1394 - sparse_categorical_accuracy: 0.4544 - val_loss: 1.1455 - val_sparse_categorical_accuracy: 0.4414\n",
      "Epoch 198/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1303 - sparse_categorical_accuracy: 0.4649 - val_loss: 1.1368 - val_sparse_categorical_accuracy: 0.4547\n",
      "Epoch 199/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1358 - sparse_categorical_accuracy: 0.4577 - val_loss: 1.1450 - val_sparse_categorical_accuracy: 0.4584\n",
      "Epoch 200/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1349 - sparse_categorical_accuracy: 0.4640 - val_loss: 1.1507 - val_sparse_categorical_accuracy: 0.4565\n",
      "Epoch 201/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1319 - sparse_categorical_accuracy: 0.4556 - val_loss: 1.1503 - val_sparse_categorical_accuracy: 0.4534\n",
      "Epoch 202/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1368 - sparse_categorical_accuracy: 0.4535 - val_loss: 1.1462 - val_sparse_categorical_accuracy: 0.4540\n",
      "Epoch 203/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1361 - sparse_categorical_accuracy: 0.4523 - val_loss: 1.1469 - val_sparse_categorical_accuracy: 0.4433\n",
      "Epoch 204/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1359 - sparse_categorical_accuracy: 0.4526 - val_loss: 1.1314 - val_sparse_categorical_accuracy: 0.4616\n",
      "Epoch 205/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1418 - sparse_categorical_accuracy: 0.4529 - val_loss: 1.1514 - val_sparse_categorical_accuracy: 0.4440\n",
      "Epoch 206/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1374 - sparse_categorical_accuracy: 0.4454 - val_loss: 1.1438 - val_sparse_categorical_accuracy: 0.4377\n",
      "Epoch 207/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1326 - sparse_categorical_accuracy: 0.4634 - val_loss: 1.1546 - val_sparse_categorical_accuracy: 0.4578\n",
      "Epoch 208/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1412 - sparse_categorical_accuracy: 0.4514 - val_loss: 1.1907 - val_sparse_categorical_accuracy: 0.4295\n",
      "Epoch 209/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1382 - sparse_categorical_accuracy: 0.4550 - val_loss: 1.1295 - val_sparse_categorical_accuracy: 0.4471\n",
      "Epoch 210/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1339 - sparse_categorical_accuracy: 0.4562 - val_loss: 1.1457 - val_sparse_categorical_accuracy: 0.4521\n",
      "Epoch 211/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1385 - sparse_categorical_accuracy: 0.4556 - val_loss: 1.1403 - val_sparse_categorical_accuracy: 0.4490\n",
      "Epoch 212/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1423 - sparse_categorical_accuracy: 0.4577 - val_loss: 1.1454 - val_sparse_categorical_accuracy: 0.4477\n",
      "Epoch 213/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1398 - sparse_categorical_accuracy: 0.4649 - val_loss: 1.1496 - val_sparse_categorical_accuracy: 0.4377\n",
      "Epoch 214/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1359 - sparse_categorical_accuracy: 0.4562 - val_loss: 1.1487 - val_sparse_categorical_accuracy: 0.4345\n",
      "Epoch 215/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1397 - sparse_categorical_accuracy: 0.4565 - val_loss: 1.1387 - val_sparse_categorical_accuracy: 0.4446\n",
      "Epoch 216/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1358 - sparse_categorical_accuracy: 0.4553 - val_loss: 1.1469 - val_sparse_categorical_accuracy: 0.4276\n",
      "Epoch 217/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1327 - sparse_categorical_accuracy: 0.4565 - val_loss: 1.1413 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 218/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1220 - sparse_categorical_accuracy: 0.4727 - val_loss: 1.1430 - val_sparse_categorical_accuracy: 0.4565\n",
      "Epoch 219/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1384 - sparse_categorical_accuracy: 0.4574 - val_loss: 1.1582 - val_sparse_categorical_accuracy: 0.4326\n",
      "Epoch 220/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1393 - sparse_categorical_accuracy: 0.4622 - val_loss: 1.1743 - val_sparse_categorical_accuracy: 0.4427\n",
      "Epoch 221/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1342 - sparse_categorical_accuracy: 0.4589 - val_loss: 1.1314 - val_sparse_categorical_accuracy: 0.4610\n",
      "Epoch 222/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1379 - sparse_categorical_accuracy: 0.4547 - val_loss: 1.1353 - val_sparse_categorical_accuracy: 0.4773\n",
      "Epoch 223/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1413 - sparse_categorical_accuracy: 0.4643 - val_loss: 1.1383 - val_sparse_categorical_accuracy: 0.4515\n",
      "Epoch 224/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1295 - sparse_categorical_accuracy: 0.4646 - val_loss: 1.1423 - val_sparse_categorical_accuracy: 0.4503\n",
      "Epoch 225/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1296 - sparse_categorical_accuracy: 0.4655 - val_loss: 1.1437 - val_sparse_categorical_accuracy: 0.4383\n",
      "Epoch 226/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1301 - sparse_categorical_accuracy: 0.4601 - val_loss: 1.1487 - val_sparse_categorical_accuracy: 0.4515\n",
      "Epoch 227/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1278 - sparse_categorical_accuracy: 0.4637 - val_loss: 1.1616 - val_sparse_categorical_accuracy: 0.4389\n",
      "Epoch 228/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1312 - sparse_categorical_accuracy: 0.4568 - val_loss: 1.1526 - val_sparse_categorical_accuracy: 0.4421\n",
      "Epoch 229/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1377 - sparse_categorical_accuracy: 0.4568 - val_loss: 1.1377 - val_sparse_categorical_accuracy: 0.4603\n",
      "Epoch 230/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1302 - sparse_categorical_accuracy: 0.4586 - val_loss: 1.1349 - val_sparse_categorical_accuracy: 0.4572\n",
      "Epoch 231/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1273 - sparse_categorical_accuracy: 0.4616 - val_loss: 1.1566 - val_sparse_categorical_accuracy: 0.4389\n",
      "Epoch 232/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1314 - sparse_categorical_accuracy: 0.4532 - val_loss: 1.1476 - val_sparse_categorical_accuracy: 0.4490\n",
      "Epoch 233/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1388 - sparse_categorical_accuracy: 0.4601 - val_loss: 1.1480 - val_sparse_categorical_accuracy: 0.4465\n",
      "Epoch 234/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1373 - sparse_categorical_accuracy: 0.4535 - val_loss: 1.1257 - val_sparse_categorical_accuracy: 0.4654\n",
      "Epoch 235/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1328 - sparse_categorical_accuracy: 0.4610 - val_loss: 1.1767 - val_sparse_categorical_accuracy: 0.4452\n",
      "Epoch 236/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1319 - sparse_categorical_accuracy: 0.4595 - val_loss: 1.1534 - val_sparse_categorical_accuracy: 0.4490\n",
      "Epoch 237/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1313 - sparse_categorical_accuracy: 0.4601 - val_loss: 1.1357 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 238/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1323 - sparse_categorical_accuracy: 0.4595 - val_loss: 1.1357 - val_sparse_categorical_accuracy: 0.4534\n",
      "Epoch 239/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1315 - sparse_categorical_accuracy: 0.4550 - val_loss: 1.1345 - val_sparse_categorical_accuracy: 0.4553\n",
      "Epoch 240/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1212 - sparse_categorical_accuracy: 0.4724 - val_loss: 1.1331 - val_sparse_categorical_accuracy: 0.4654\n",
      "Epoch 241/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1275 - sparse_categorical_accuracy: 0.4667 - val_loss: 1.1380 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 242/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1297 - sparse_categorical_accuracy: 0.4688 - val_loss: 1.1714 - val_sparse_categorical_accuracy: 0.4433\n",
      "Epoch 243/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1354 - sparse_categorical_accuracy: 0.4514 - val_loss: 1.1517 - val_sparse_categorical_accuracy: 0.4591\n",
      "Epoch 244/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1364 - sparse_categorical_accuracy: 0.4541 - val_loss: 1.1318 - val_sparse_categorical_accuracy: 0.4528\n",
      "Epoch 245/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1310 - sparse_categorical_accuracy: 0.4571 - val_loss: 1.1564 - val_sparse_categorical_accuracy: 0.4389\n",
      "Epoch 246/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1258 - sparse_categorical_accuracy: 0.4649 - val_loss: 1.1430 - val_sparse_categorical_accuracy: 0.4421\n",
      "Epoch 247/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1338 - sparse_categorical_accuracy: 0.4673 - val_loss: 1.1234 - val_sparse_categorical_accuracy: 0.4628\n",
      "Epoch 248/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1289 - sparse_categorical_accuracy: 0.4625 - val_loss: 1.1342 - val_sparse_categorical_accuracy: 0.4427\n",
      "Epoch 249/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1286 - sparse_categorical_accuracy: 0.4700 - val_loss: 1.1567 - val_sparse_categorical_accuracy: 0.4414\n",
      "Epoch 250/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1259 - sparse_categorical_accuracy: 0.4628 - val_loss: 1.1261 - val_sparse_categorical_accuracy: 0.4616\n",
      "Epoch 251/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1259 - sparse_categorical_accuracy: 0.4721 - val_loss: 1.1369 - val_sparse_categorical_accuracy: 0.4679\n",
      "Epoch 252/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1257 - sparse_categorical_accuracy: 0.4688 - val_loss: 1.1348 - val_sparse_categorical_accuracy: 0.4610\n",
      "Epoch 253/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1258 - sparse_categorical_accuracy: 0.4733 - val_loss: 1.1364 - val_sparse_categorical_accuracy: 0.4584\n",
      "Epoch 254/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1296 - sparse_categorical_accuracy: 0.4670 - val_loss: 1.1335 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 255/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1347 - sparse_categorical_accuracy: 0.4628 - val_loss: 1.1269 - val_sparse_categorical_accuracy: 0.4767\n",
      "Epoch 256/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1275 - sparse_categorical_accuracy: 0.4682 - val_loss: 1.1527 - val_sparse_categorical_accuracy: 0.4370\n",
      "Epoch 257/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1214 - sparse_categorical_accuracy: 0.4778 - val_loss: 1.1321 - val_sparse_categorical_accuracy: 0.4647\n",
      "Epoch 258/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1256 - sparse_categorical_accuracy: 0.4688 - val_loss: 1.1489 - val_sparse_categorical_accuracy: 0.4496\n",
      "Epoch 259/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1299 - sparse_categorical_accuracy: 0.4631 - val_loss: 1.1278 - val_sparse_categorical_accuracy: 0.4578\n",
      "Epoch 260/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1252 - sparse_categorical_accuracy: 0.4649 - val_loss: 1.1361 - val_sparse_categorical_accuracy: 0.4673\n",
      "Epoch 261/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1242 - sparse_categorical_accuracy: 0.4748 - val_loss: 1.1742 - val_sparse_categorical_accuracy: 0.4402\n",
      "Epoch 262/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1101 - sparse_categorical_accuracy: 0.4676 - val_loss: 1.1467 - val_sparse_categorical_accuracy: 0.4458\n",
      "Epoch 263/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1184 - sparse_categorical_accuracy: 0.4700 - val_loss: 1.1371 - val_sparse_categorical_accuracy: 0.4597\n",
      "Epoch 264/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1277 - sparse_categorical_accuracy: 0.4595 - val_loss: 1.1426 - val_sparse_categorical_accuracy: 0.4307\n",
      "Epoch 265/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1252 - sparse_categorical_accuracy: 0.4679 - val_loss: 1.1526 - val_sparse_categorical_accuracy: 0.4591\n",
      "Epoch 266/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1224 - sparse_categorical_accuracy: 0.4538 - val_loss: 1.1231 - val_sparse_categorical_accuracy: 0.4691\n",
      "Epoch 267/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1261 - sparse_categorical_accuracy: 0.4634 - val_loss: 1.1337 - val_sparse_categorical_accuracy: 0.4597\n",
      "Epoch 268/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1201 - sparse_categorical_accuracy: 0.4637 - val_loss: 1.1420 - val_sparse_categorical_accuracy: 0.4616\n",
      "Epoch 269/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1257 - sparse_categorical_accuracy: 0.4568 - val_loss: 1.1962 - val_sparse_categorical_accuracy: 0.4389\n",
      "Epoch 270/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1249 - sparse_categorical_accuracy: 0.4709 - val_loss: 1.1714 - val_sparse_categorical_accuracy: 0.4421\n",
      "Epoch 271/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1272 - sparse_categorical_accuracy: 0.4595 - val_loss: 1.1850 - val_sparse_categorical_accuracy: 0.4383\n",
      "Epoch 272/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1242 - sparse_categorical_accuracy: 0.4679 - val_loss: 1.1678 - val_sparse_categorical_accuracy: 0.4389\n",
      "Epoch 273/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1292 - sparse_categorical_accuracy: 0.4571 - val_loss: 1.1377 - val_sparse_categorical_accuracy: 0.4591\n",
      "Epoch 274/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1260 - sparse_categorical_accuracy: 0.4592 - val_loss: 1.1213 - val_sparse_categorical_accuracy: 0.4691\n",
      "Epoch 275/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1253 - sparse_categorical_accuracy: 0.4652 - val_loss: 1.1248 - val_sparse_categorical_accuracy: 0.4736\n",
      "Epoch 276/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1172 - sparse_categorical_accuracy: 0.4595 - val_loss: 1.1423 - val_sparse_categorical_accuracy: 0.4515\n",
      "Epoch 277/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1220 - sparse_categorical_accuracy: 0.4616 - val_loss: 1.1398 - val_sparse_categorical_accuracy: 0.4414\n",
      "Epoch 278/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1304 - sparse_categorical_accuracy: 0.4619 - val_loss: 1.1316 - val_sparse_categorical_accuracy: 0.4610\n",
      "Epoch 279/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1271 - sparse_categorical_accuracy: 0.4610 - val_loss: 1.1477 - val_sparse_categorical_accuracy: 0.4666\n",
      "Epoch 280/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1139 - sparse_categorical_accuracy: 0.4637 - val_loss: 1.1527 - val_sparse_categorical_accuracy: 0.4578\n",
      "Epoch 281/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1372 - sparse_categorical_accuracy: 0.4556 - val_loss: 1.1256 - val_sparse_categorical_accuracy: 0.4698\n",
      "Epoch 282/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1342 - sparse_categorical_accuracy: 0.4586 - val_loss: 1.1369 - val_sparse_categorical_accuracy: 0.4414\n",
      "Epoch 283/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1281 - sparse_categorical_accuracy: 0.4751 - val_loss: 1.1577 - val_sparse_categorical_accuracy: 0.4421\n",
      "Epoch 284/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1259 - sparse_categorical_accuracy: 0.4613 - val_loss: 1.1192 - val_sparse_categorical_accuracy: 0.4540\n",
      "Epoch 285/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1235 - sparse_categorical_accuracy: 0.4655 - val_loss: 1.1290 - val_sparse_categorical_accuracy: 0.4610\n",
      "Epoch 286/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1217 - sparse_categorical_accuracy: 0.4583 - val_loss: 1.1264 - val_sparse_categorical_accuracy: 0.4591\n",
      "Epoch 287/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1221 - sparse_categorical_accuracy: 0.4655 - val_loss: 1.1405 - val_sparse_categorical_accuracy: 0.4477\n",
      "Epoch 288/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1241 - sparse_categorical_accuracy: 0.4682 - val_loss: 1.1565 - val_sparse_categorical_accuracy: 0.4490\n",
      "Epoch 289/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1329 - sparse_categorical_accuracy: 0.4604 - val_loss: 1.1316 - val_sparse_categorical_accuracy: 0.4887\n",
      "Epoch 290/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1211 - sparse_categorical_accuracy: 0.4757 - val_loss: 1.1319 - val_sparse_categorical_accuracy: 0.4717\n",
      "Epoch 291/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1188 - sparse_categorical_accuracy: 0.4685 - val_loss: 1.1413 - val_sparse_categorical_accuracy: 0.4345\n",
      "Epoch 292/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1329 - sparse_categorical_accuracy: 0.4667 - val_loss: 1.1376 - val_sparse_categorical_accuracy: 0.4641\n",
      "Epoch 293/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1247 - sparse_categorical_accuracy: 0.4715 - val_loss: 1.1531 - val_sparse_categorical_accuracy: 0.4314\n",
      "Epoch 294/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1229 - sparse_categorical_accuracy: 0.4613 - val_loss: 1.1321 - val_sparse_categorical_accuracy: 0.4622\n",
      "Epoch 295/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1230 - sparse_categorical_accuracy: 0.4628 - val_loss: 1.1367 - val_sparse_categorical_accuracy: 0.4584\n",
      "Epoch 296/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1161 - sparse_categorical_accuracy: 0.4670 - val_loss: 1.1201 - val_sparse_categorical_accuracy: 0.4666\n",
      "Epoch 297/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1211 - sparse_categorical_accuracy: 0.4694 - val_loss: 1.1554 - val_sparse_categorical_accuracy: 0.4364\n",
      "Epoch 298/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1352 - sparse_categorical_accuracy: 0.4595 - val_loss: 1.1275 - val_sparse_categorical_accuracy: 0.4553\n",
      "Epoch 299/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1183 - sparse_categorical_accuracy: 0.4733 - val_loss: 1.1145 - val_sparse_categorical_accuracy: 0.4698\n",
      "Epoch 300/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1223 - sparse_categorical_accuracy: 0.4604 - val_loss: 1.1169 - val_sparse_categorical_accuracy: 0.4805\n",
      "Epoch 301/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1252 - sparse_categorical_accuracy: 0.4619 - val_loss: 1.1219 - val_sparse_categorical_accuracy: 0.4780\n",
      "Epoch 302/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1219 - sparse_categorical_accuracy: 0.4640 - val_loss: 1.1396 - val_sparse_categorical_accuracy: 0.4503\n",
      "Epoch 303/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1217 - sparse_categorical_accuracy: 0.4610 - val_loss: 1.2150 - val_sparse_categorical_accuracy: 0.4169\n",
      "Epoch 304/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1229 - sparse_categorical_accuracy: 0.4724 - val_loss: 1.1194 - val_sparse_categorical_accuracy: 0.4767\n",
      "Epoch 305/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1209 - sparse_categorical_accuracy: 0.4631 - val_loss: 1.1338 - val_sparse_categorical_accuracy: 0.4591\n",
      "Epoch 306/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1254 - sparse_categorical_accuracy: 0.4610 - val_loss: 1.1637 - val_sparse_categorical_accuracy: 0.4547\n",
      "Epoch 307/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1330 - sparse_categorical_accuracy: 0.4673 - val_loss: 1.1614 - val_sparse_categorical_accuracy: 0.4521\n",
      "Epoch 308/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1390 - sparse_categorical_accuracy: 0.4553 - val_loss: 1.1628 - val_sparse_categorical_accuracy: 0.4370\n",
      "Epoch 309/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1243 - sparse_categorical_accuracy: 0.4622 - val_loss: 1.1484 - val_sparse_categorical_accuracy: 0.4427\n",
      "Epoch 310/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1233 - sparse_categorical_accuracy: 0.4673 - val_loss: 1.1358 - val_sparse_categorical_accuracy: 0.4559\n",
      "Epoch 311/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1265 - sparse_categorical_accuracy: 0.4580 - val_loss: 1.1358 - val_sparse_categorical_accuracy: 0.4465\n",
      "Epoch 312/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1306 - sparse_categorical_accuracy: 0.4616 - val_loss: 1.1330 - val_sparse_categorical_accuracy: 0.4610\n",
      "Epoch 313/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1330 - sparse_categorical_accuracy: 0.4601 - val_loss: 1.1493 - val_sparse_categorical_accuracy: 0.4408\n",
      "Epoch 314/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1333 - sparse_categorical_accuracy: 0.4562 - val_loss: 1.1204 - val_sparse_categorical_accuracy: 0.4578\n",
      "Epoch 315/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1222 - sparse_categorical_accuracy: 0.4730 - val_loss: 1.1396 - val_sparse_categorical_accuracy: 0.4578\n",
      "Epoch 316/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1201 - sparse_categorical_accuracy: 0.4700 - val_loss: 1.1228 - val_sparse_categorical_accuracy: 0.4572\n",
      "Epoch 317/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1197 - sparse_categorical_accuracy: 0.4679 - val_loss: 1.1307 - val_sparse_categorical_accuracy: 0.4591\n",
      "Epoch 318/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1155 - sparse_categorical_accuracy: 0.4691 - val_loss: 1.1214 - val_sparse_categorical_accuracy: 0.4490\n",
      "Epoch 319/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1231 - sparse_categorical_accuracy: 0.4745 - val_loss: 1.1357 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 320/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1211 - sparse_categorical_accuracy: 0.4652 - val_loss: 1.1294 - val_sparse_categorical_accuracy: 0.4591\n",
      "Epoch 321/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1094 - sparse_categorical_accuracy: 0.4769 - val_loss: 1.1333 - val_sparse_categorical_accuracy: 0.4547\n",
      "Epoch 322/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1151 - sparse_categorical_accuracy: 0.4691 - val_loss: 1.1307 - val_sparse_categorical_accuracy: 0.4484\n",
      "Epoch 323/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1138 - sparse_categorical_accuracy: 0.4664 - val_loss: 1.1447 - val_sparse_categorical_accuracy: 0.4471\n",
      "Epoch 324/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1295 - sparse_categorical_accuracy: 0.4571 - val_loss: 1.1354 - val_sparse_categorical_accuracy: 0.4628\n",
      "Epoch 325/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1216 - sparse_categorical_accuracy: 0.4709 - val_loss: 1.1161 - val_sparse_categorical_accuracy: 0.4786\n",
      "Epoch 326/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1194 - sparse_categorical_accuracy: 0.4583 - val_loss: 1.1349 - val_sparse_categorical_accuracy: 0.4484\n",
      "Epoch 327/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1088 - sparse_categorical_accuracy: 0.4745 - val_loss: 1.1219 - val_sparse_categorical_accuracy: 0.4666\n",
      "Epoch 328/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1118 - sparse_categorical_accuracy: 0.4673 - val_loss: 1.1165 - val_sparse_categorical_accuracy: 0.4704\n",
      "Epoch 329/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1176 - sparse_categorical_accuracy: 0.4739 - val_loss: 1.1170 - val_sparse_categorical_accuracy: 0.4824\n",
      "Epoch 330/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1216 - sparse_categorical_accuracy: 0.4649 - val_loss: 1.1140 - val_sparse_categorical_accuracy: 0.4780\n",
      "Epoch 331/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1071 - sparse_categorical_accuracy: 0.4832 - val_loss: 1.1352 - val_sparse_categorical_accuracy: 0.4616\n",
      "Epoch 332/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1259 - sparse_categorical_accuracy: 0.4550 - val_loss: 1.1689 - val_sparse_categorical_accuracy: 0.4358\n",
      "Epoch 333/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1313 - sparse_categorical_accuracy: 0.4676 - val_loss: 1.1243 - val_sparse_categorical_accuracy: 0.4597\n",
      "Epoch 334/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1193 - sparse_categorical_accuracy: 0.4694 - val_loss: 1.1405 - val_sparse_categorical_accuracy: 0.4622\n",
      "Epoch 335/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1272 - sparse_categorical_accuracy: 0.4763 - val_loss: 1.1350 - val_sparse_categorical_accuracy: 0.4610\n",
      "Epoch 336/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1138 - sparse_categorical_accuracy: 0.4727 - val_loss: 1.1141 - val_sparse_categorical_accuracy: 0.4641\n",
      "Epoch 337/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1261 - sparse_categorical_accuracy: 0.4634 - val_loss: 1.1255 - val_sparse_categorical_accuracy: 0.4635\n",
      "Epoch 338/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1272 - sparse_categorical_accuracy: 0.4628 - val_loss: 1.1213 - val_sparse_categorical_accuracy: 0.4710\n",
      "Epoch 339/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1208 - sparse_categorical_accuracy: 0.4703 - val_loss: 1.1306 - val_sparse_categorical_accuracy: 0.4673\n",
      "Epoch 340/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1208 - sparse_categorical_accuracy: 0.4682 - val_loss: 1.1377 - val_sparse_categorical_accuracy: 0.4584\n",
      "Epoch 341/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1201 - sparse_categorical_accuracy: 0.4709 - val_loss: 1.1238 - val_sparse_categorical_accuracy: 0.4641\n",
      "Epoch 342/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1137 - sparse_categorical_accuracy: 0.4754 - val_loss: 1.1311 - val_sparse_categorical_accuracy: 0.4635\n",
      "Epoch 343/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1209 - sparse_categorical_accuracy: 0.4592 - val_loss: 1.1473 - val_sparse_categorical_accuracy: 0.4673\n",
      "Epoch 344/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1215 - sparse_categorical_accuracy: 0.4649 - val_loss: 1.1201 - val_sparse_categorical_accuracy: 0.4792\n",
      "Epoch 345/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1107 - sparse_categorical_accuracy: 0.4739 - val_loss: 1.1276 - val_sparse_categorical_accuracy: 0.4534\n",
      "Epoch 346/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1101 - sparse_categorical_accuracy: 0.4844 - val_loss: 1.1205 - val_sparse_categorical_accuracy: 0.4484\n",
      "Epoch 347/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1170 - sparse_categorical_accuracy: 0.4682 - val_loss: 1.1346 - val_sparse_categorical_accuracy: 0.4528\n",
      "Epoch 348/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1134 - sparse_categorical_accuracy: 0.4682 - val_loss: 1.1386 - val_sparse_categorical_accuracy: 0.4559\n",
      "Epoch 349/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1168 - sparse_categorical_accuracy: 0.4682 - val_loss: 1.1230 - val_sparse_categorical_accuracy: 0.4736\n",
      "Epoch 350/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1117 - sparse_categorical_accuracy: 0.4781 - val_loss: 1.1717 - val_sparse_categorical_accuracy: 0.4270\n",
      "Epoch 351/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1207 - sparse_categorical_accuracy: 0.4706 - val_loss: 1.1384 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 352/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1200 - sparse_categorical_accuracy: 0.4682 - val_loss: 1.1456 - val_sparse_categorical_accuracy: 0.4597\n",
      "Epoch 353/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1038 - sparse_categorical_accuracy: 0.4763 - val_loss: 1.1140 - val_sparse_categorical_accuracy: 0.4647\n",
      "Epoch 354/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1151 - sparse_categorical_accuracy: 0.4733 - val_loss: 1.1244 - val_sparse_categorical_accuracy: 0.4628\n",
      "Epoch 355/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1187 - sparse_categorical_accuracy: 0.4721 - val_loss: 1.1263 - val_sparse_categorical_accuracy: 0.4767\n",
      "Epoch 356/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1179 - sparse_categorical_accuracy: 0.4742 - val_loss: 1.1155 - val_sparse_categorical_accuracy: 0.4767\n",
      "Epoch 357/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1061 - sparse_categorical_accuracy: 0.4742 - val_loss: 1.1198 - val_sparse_categorical_accuracy: 0.4710\n",
      "Epoch 358/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1077 - sparse_categorical_accuracy: 0.4793 - val_loss: 1.1291 - val_sparse_categorical_accuracy: 0.4691\n",
      "Epoch 359/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1096 - sparse_categorical_accuracy: 0.4736 - val_loss: 1.1271 - val_sparse_categorical_accuracy: 0.4622\n",
      "Epoch 360/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1283 - sparse_categorical_accuracy: 0.4550 - val_loss: 1.1149 - val_sparse_categorical_accuracy: 0.4654\n",
      "Epoch 361/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1122 - sparse_categorical_accuracy: 0.4715 - val_loss: 1.1397 - val_sparse_categorical_accuracy: 0.4729\n",
      "Epoch 362/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1221 - sparse_categorical_accuracy: 0.4670 - val_loss: 1.1262 - val_sparse_categorical_accuracy: 0.4540\n",
      "Epoch 363/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1143 - sparse_categorical_accuracy: 0.4730 - val_loss: 1.1204 - val_sparse_categorical_accuracy: 0.4761\n",
      "Epoch 364/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1137 - sparse_categorical_accuracy: 0.4772 - val_loss: 1.1641 - val_sparse_categorical_accuracy: 0.4194\n",
      "Epoch 365/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1155 - sparse_categorical_accuracy: 0.4718 - val_loss: 1.1440 - val_sparse_categorical_accuracy: 0.4641\n",
      "Epoch 366/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1092 - sparse_categorical_accuracy: 0.4790 - val_loss: 1.1388 - val_sparse_categorical_accuracy: 0.4515\n",
      "Epoch 367/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1112 - sparse_categorical_accuracy: 0.4742 - val_loss: 1.1796 - val_sparse_categorical_accuracy: 0.4106\n",
      "Epoch 368/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1230 - sparse_categorical_accuracy: 0.4598 - val_loss: 1.1322 - val_sparse_categorical_accuracy: 0.4597\n",
      "Epoch 369/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1148 - sparse_categorical_accuracy: 0.4754 - val_loss: 1.1501 - val_sparse_categorical_accuracy: 0.4723\n",
      "Epoch 370/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1180 - sparse_categorical_accuracy: 0.4718 - val_loss: 1.1330 - val_sparse_categorical_accuracy: 0.4465\n",
      "Epoch 371/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1168 - sparse_categorical_accuracy: 0.4697 - val_loss: 1.1103 - val_sparse_categorical_accuracy: 0.4742\n",
      "Epoch 372/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1093 - sparse_categorical_accuracy: 0.4691 - val_loss: 1.1226 - val_sparse_categorical_accuracy: 0.4691\n",
      "Epoch 373/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1094 - sparse_categorical_accuracy: 0.4781 - val_loss: 1.1173 - val_sparse_categorical_accuracy: 0.4786\n",
      "Epoch 374/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1058 - sparse_categorical_accuracy: 0.4799 - val_loss: 1.1271 - val_sparse_categorical_accuracy: 0.4691\n",
      "Epoch 375/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1135 - sparse_categorical_accuracy: 0.4589 - val_loss: 1.1182 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 376/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1178 - sparse_categorical_accuracy: 0.4745 - val_loss: 1.1245 - val_sparse_categorical_accuracy: 0.4628\n",
      "Epoch 377/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1168 - sparse_categorical_accuracy: 0.4631 - val_loss: 1.1437 - val_sparse_categorical_accuracy: 0.4446\n",
      "Epoch 378/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1092 - sparse_categorical_accuracy: 0.4751 - val_loss: 1.1136 - val_sparse_categorical_accuracy: 0.4736\n",
      "Epoch 379/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1177 - sparse_categorical_accuracy: 0.4730 - val_loss: 1.1305 - val_sparse_categorical_accuracy: 0.4647\n",
      "Epoch 380/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1160 - sparse_categorical_accuracy: 0.4712 - val_loss: 1.1160 - val_sparse_categorical_accuracy: 0.4748\n",
      "Epoch 381/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1154 - sparse_categorical_accuracy: 0.4766 - val_loss: 1.1374 - val_sparse_categorical_accuracy: 0.4610\n",
      "Epoch 382/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1198 - sparse_categorical_accuracy: 0.4736 - val_loss: 1.1105 - val_sparse_categorical_accuracy: 0.4628\n",
      "Epoch 383/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1234 - sparse_categorical_accuracy: 0.4664 - val_loss: 1.1164 - val_sparse_categorical_accuracy: 0.4736\n",
      "Epoch 384/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1127 - sparse_categorical_accuracy: 0.4730 - val_loss: 1.1206 - val_sparse_categorical_accuracy: 0.4811\n",
      "Epoch 385/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1234 - sparse_categorical_accuracy: 0.4598 - val_loss: 1.1208 - val_sparse_categorical_accuracy: 0.4685\n",
      "Epoch 386/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1254 - sparse_categorical_accuracy: 0.4724 - val_loss: 1.1131 - val_sparse_categorical_accuracy: 0.4773\n",
      "Epoch 387/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1038 - sparse_categorical_accuracy: 0.4802 - val_loss: 1.1125 - val_sparse_categorical_accuracy: 0.4849\n",
      "Epoch 388/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1178 - sparse_categorical_accuracy: 0.4682 - val_loss: 1.1379 - val_sparse_categorical_accuracy: 0.4679\n",
      "Epoch 389/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1099 - sparse_categorical_accuracy: 0.4820 - val_loss: 1.1314 - val_sparse_categorical_accuracy: 0.4603\n",
      "Epoch 390/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1231 - sparse_categorical_accuracy: 0.4640 - val_loss: 1.1129 - val_sparse_categorical_accuracy: 0.4666\n",
      "Epoch 391/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1221 - sparse_categorical_accuracy: 0.4616 - val_loss: 1.1099 - val_sparse_categorical_accuracy: 0.4710\n",
      "Epoch 392/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1149 - sparse_categorical_accuracy: 0.4718 - val_loss: 1.1255 - val_sparse_categorical_accuracy: 0.4666\n",
      "Epoch 393/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1116 - sparse_categorical_accuracy: 0.4697 - val_loss: 1.1168 - val_sparse_categorical_accuracy: 0.4773\n",
      "Epoch 394/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1099 - sparse_categorical_accuracy: 0.4664 - val_loss: 1.1178 - val_sparse_categorical_accuracy: 0.4868\n",
      "Epoch 395/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1165 - sparse_categorical_accuracy: 0.4691 - val_loss: 1.1236 - val_sparse_categorical_accuracy: 0.4698\n",
      "Epoch 396/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1163 - sparse_categorical_accuracy: 0.4676 - val_loss: 1.1401 - val_sparse_categorical_accuracy: 0.4641\n",
      "Epoch 397/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1095 - sparse_categorical_accuracy: 0.4721 - val_loss: 1.1114 - val_sparse_categorical_accuracy: 0.4723\n",
      "Epoch 398/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1208 - sparse_categorical_accuracy: 0.4730 - val_loss: 1.1214 - val_sparse_categorical_accuracy: 0.4647\n",
      "Epoch 399/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1139 - sparse_categorical_accuracy: 0.4874 - val_loss: 1.1234 - val_sparse_categorical_accuracy: 0.4729\n",
      "Epoch 400/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1156 - sparse_categorical_accuracy: 0.4775 - val_loss: 1.1186 - val_sparse_categorical_accuracy: 0.4685\n",
      "Epoch 401/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1116 - sparse_categorical_accuracy: 0.4667 - val_loss: 1.1093 - val_sparse_categorical_accuracy: 0.4843\n",
      "Epoch 402/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1130 - sparse_categorical_accuracy: 0.4712 - val_loss: 1.1362 - val_sparse_categorical_accuracy: 0.4503\n",
      "Epoch 403/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1141 - sparse_categorical_accuracy: 0.4709 - val_loss: 1.1251 - val_sparse_categorical_accuracy: 0.4717\n",
      "Epoch 404/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1064 - sparse_categorical_accuracy: 0.4745 - val_loss: 1.1278 - val_sparse_categorical_accuracy: 0.4635\n",
      "Epoch 405/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1196 - sparse_categorical_accuracy: 0.4706 - val_loss: 1.1260 - val_sparse_categorical_accuracy: 0.4773\n",
      "Epoch 406/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1212 - sparse_categorical_accuracy: 0.4682 - val_loss: 1.1120 - val_sparse_categorical_accuracy: 0.4767\n",
      "Epoch 407/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1084 - sparse_categorical_accuracy: 0.4700 - val_loss: 1.1202 - val_sparse_categorical_accuracy: 0.4679\n",
      "Epoch 408/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1108 - sparse_categorical_accuracy: 0.4769 - val_loss: 1.1289 - val_sparse_categorical_accuracy: 0.4679\n",
      "Epoch 409/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1143 - sparse_categorical_accuracy: 0.4808 - val_loss: 1.1486 - val_sparse_categorical_accuracy: 0.4364\n",
      "Epoch 410/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1024 - sparse_categorical_accuracy: 0.4781 - val_loss: 1.1264 - val_sparse_categorical_accuracy: 0.4691\n",
      "Epoch 411/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1035 - sparse_categorical_accuracy: 0.4796 - val_loss: 1.1216 - val_sparse_categorical_accuracy: 0.4496\n",
      "Epoch 412/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1129 - sparse_categorical_accuracy: 0.4811 - val_loss: 1.1213 - val_sparse_categorical_accuracy: 0.4861\n",
      "Epoch 413/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1141 - sparse_categorical_accuracy: 0.4676 - val_loss: 1.1213 - val_sparse_categorical_accuracy: 0.4610\n",
      "Epoch 414/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1184 - sparse_categorical_accuracy: 0.4850 - val_loss: 1.1384 - val_sparse_categorical_accuracy: 0.4584\n",
      "Epoch 415/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1281 - sparse_categorical_accuracy: 0.4736 - val_loss: 1.1142 - val_sparse_categorical_accuracy: 0.4742\n",
      "Epoch 416/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1111 - sparse_categorical_accuracy: 0.4700 - val_loss: 1.1167 - val_sparse_categorical_accuracy: 0.4786\n",
      "Epoch 417/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1047 - sparse_categorical_accuracy: 0.4799 - val_loss: 1.1201 - val_sparse_categorical_accuracy: 0.4736\n",
      "Epoch 418/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1128 - sparse_categorical_accuracy: 0.4736 - val_loss: 1.1129 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 419/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1101 - sparse_categorical_accuracy: 0.4712 - val_loss: 1.1296 - val_sparse_categorical_accuracy: 0.4710\n",
      "Epoch 420/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1103 - sparse_categorical_accuracy: 0.4814 - val_loss: 1.1209 - val_sparse_categorical_accuracy: 0.4849\n",
      "Epoch 421/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1113 - sparse_categorical_accuracy: 0.4802 - val_loss: 1.1162 - val_sparse_categorical_accuracy: 0.4736\n",
      "Epoch 422/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1045 - sparse_categorical_accuracy: 0.4820 - val_loss: 1.1318 - val_sparse_categorical_accuracy: 0.4761\n",
      "Epoch 423/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1067 - sparse_categorical_accuracy: 0.4862 - val_loss: 1.1300 - val_sparse_categorical_accuracy: 0.4767\n",
      "Epoch 424/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1132 - sparse_categorical_accuracy: 0.4748 - val_loss: 1.1455 - val_sparse_categorical_accuracy: 0.4521\n",
      "Epoch 425/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1196 - sparse_categorical_accuracy: 0.4727 - val_loss: 1.1377 - val_sparse_categorical_accuracy: 0.4503\n",
      "Epoch 426/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1176 - sparse_categorical_accuracy: 0.4667 - val_loss: 1.1165 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 427/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1065 - sparse_categorical_accuracy: 0.4820 - val_loss: 1.1168 - val_sparse_categorical_accuracy: 0.4610\n",
      "Epoch 428/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1115 - sparse_categorical_accuracy: 0.4739 - val_loss: 1.1142 - val_sparse_categorical_accuracy: 0.4773\n",
      "Epoch 429/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1119 - sparse_categorical_accuracy: 0.4700 - val_loss: 1.1189 - val_sparse_categorical_accuracy: 0.4698\n",
      "Epoch 430/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1055 - sparse_categorical_accuracy: 0.4715 - val_loss: 1.1296 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 431/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1132 - sparse_categorical_accuracy: 0.4742 - val_loss: 1.1121 - val_sparse_categorical_accuracy: 0.4723\n",
      "Epoch 432/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1034 - sparse_categorical_accuracy: 0.4817 - val_loss: 1.1053 - val_sparse_categorical_accuracy: 0.4710\n",
      "Epoch 433/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1129 - sparse_categorical_accuracy: 0.4682 - val_loss: 1.1341 - val_sparse_categorical_accuracy: 0.4647\n",
      "Epoch 434/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1020 - sparse_categorical_accuracy: 0.4823 - val_loss: 1.1253 - val_sparse_categorical_accuracy: 0.4654\n",
      "Epoch 435/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1117 - sparse_categorical_accuracy: 0.4778 - val_loss: 1.1164 - val_sparse_categorical_accuracy: 0.4628\n",
      "Epoch 436/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1004 - sparse_categorical_accuracy: 0.4820 - val_loss: 1.1299 - val_sparse_categorical_accuracy: 0.4528\n",
      "Epoch 437/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1111 - sparse_categorical_accuracy: 0.4793 - val_loss: 1.1313 - val_sparse_categorical_accuracy: 0.4673\n",
      "Epoch 438/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1034 - sparse_categorical_accuracy: 0.4826 - val_loss: 1.1096 - val_sparse_categorical_accuracy: 0.4742\n",
      "Epoch 439/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1143 - sparse_categorical_accuracy: 0.4763 - val_loss: 1.1364 - val_sparse_categorical_accuracy: 0.4641\n",
      "Epoch 440/1200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 1.1045 - sparse_categorical_accuracy: 0.4892 - val_loss: 1.1084 - val_sparse_categorical_accuracy: 0.4691\n",
      "Epoch 441/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1218 - sparse_categorical_accuracy: 0.4784 - val_loss: 1.1091 - val_sparse_categorical_accuracy: 0.4817\n",
      "Epoch 442/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1171 - sparse_categorical_accuracy: 0.4781 - val_loss: 1.1551 - val_sparse_categorical_accuracy: 0.4610\n",
      "Epoch 443/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1111 - sparse_categorical_accuracy: 0.4766 - val_loss: 1.1189 - val_sparse_categorical_accuracy: 0.4780\n",
      "Epoch 444/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1052 - sparse_categorical_accuracy: 0.4718 - val_loss: 1.1175 - val_sparse_categorical_accuracy: 0.4679\n",
      "Epoch 445/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1140 - sparse_categorical_accuracy: 0.4778 - val_loss: 1.1292 - val_sparse_categorical_accuracy: 0.4654\n",
      "Epoch 446/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1102 - sparse_categorical_accuracy: 0.4793 - val_loss: 1.1048 - val_sparse_categorical_accuracy: 0.4754\n",
      "Epoch 447/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1101 - sparse_categorical_accuracy: 0.4775 - val_loss: 1.1472 - val_sparse_categorical_accuracy: 0.4402\n",
      "Epoch 448/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1159 - sparse_categorical_accuracy: 0.4778 - val_loss: 1.1217 - val_sparse_categorical_accuracy: 0.4610\n",
      "Epoch 449/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1065 - sparse_categorical_accuracy: 0.4706 - val_loss: 1.1114 - val_sparse_categorical_accuracy: 0.4773\n",
      "Epoch 450/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1180 - sparse_categorical_accuracy: 0.4685 - val_loss: 1.1224 - val_sparse_categorical_accuracy: 0.4754\n",
      "Epoch 451/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1131 - sparse_categorical_accuracy: 0.4772 - val_loss: 1.1172 - val_sparse_categorical_accuracy: 0.4698\n",
      "Epoch 452/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1142 - sparse_categorical_accuracy: 0.4730 - val_loss: 1.1316 - val_sparse_categorical_accuracy: 0.4389\n",
      "Epoch 453/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1030 - sparse_categorical_accuracy: 0.4811 - val_loss: 1.1158 - val_sparse_categorical_accuracy: 0.4509\n",
      "Epoch 454/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1025 - sparse_categorical_accuracy: 0.4820 - val_loss: 1.1449 - val_sparse_categorical_accuracy: 0.4377\n",
      "Epoch 455/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1060 - sparse_categorical_accuracy: 0.4799 - val_loss: 1.1124 - val_sparse_categorical_accuracy: 0.4754\n",
      "Epoch 456/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1182 - sparse_categorical_accuracy: 0.4598 - val_loss: 1.1134 - val_sparse_categorical_accuracy: 0.4597\n",
      "Epoch 457/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.0997 - sparse_categorical_accuracy: 0.4874 - val_loss: 1.1361 - val_sparse_categorical_accuracy: 0.4761\n",
      "Epoch 458/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1013 - sparse_categorical_accuracy: 0.4853 - val_loss: 1.1221 - val_sparse_categorical_accuracy: 0.4767\n",
      "Epoch 459/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1104 - sparse_categorical_accuracy: 0.4757 - val_loss: 1.1091 - val_sparse_categorical_accuracy: 0.4874\n",
      "Epoch 460/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1063 - sparse_categorical_accuracy: 0.4712 - val_loss: 1.1291 - val_sparse_categorical_accuracy: 0.4761\n",
      "Epoch 461/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.0989 - sparse_categorical_accuracy: 0.4820 - val_loss: 1.1084 - val_sparse_categorical_accuracy: 0.4717\n",
      "Epoch 462/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1167 - sparse_categorical_accuracy: 0.4739 - val_loss: 1.1289 - val_sparse_categorical_accuracy: 0.4736\n",
      "Epoch 463/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.0973 - sparse_categorical_accuracy: 0.4808 - val_loss: 1.1314 - val_sparse_categorical_accuracy: 0.4616\n",
      "Epoch 464/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1064 - sparse_categorical_accuracy: 0.4817 - val_loss: 1.1208 - val_sparse_categorical_accuracy: 0.4591\n",
      "Epoch 465/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.0991 - sparse_categorical_accuracy: 0.4853 - val_loss: 1.1060 - val_sparse_categorical_accuracy: 0.4767\n",
      "Epoch 466/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1134 - sparse_categorical_accuracy: 0.4760 - val_loss: 1.1423 - val_sparse_categorical_accuracy: 0.4509\n",
      "Epoch 467/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1177 - sparse_categorical_accuracy: 0.4622 - val_loss: 1.1352 - val_sparse_categorical_accuracy: 0.4641\n",
      "Epoch 468/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1138 - sparse_categorical_accuracy: 0.4643 - val_loss: 1.1275 - val_sparse_categorical_accuracy: 0.4622\n",
      "Epoch 469/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1122 - sparse_categorical_accuracy: 0.4730 - val_loss: 1.1405 - val_sparse_categorical_accuracy: 0.4723\n",
      "Epoch 470/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.0969 - sparse_categorical_accuracy: 0.4883 - val_loss: 1.1063 - val_sparse_categorical_accuracy: 0.4736\n",
      "Epoch 471/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1087 - sparse_categorical_accuracy: 0.4886 - val_loss: 1.1077 - val_sparse_categorical_accuracy: 0.4717\n",
      "Epoch 472/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1175 - sparse_categorical_accuracy: 0.4730 - val_loss: 1.1148 - val_sparse_categorical_accuracy: 0.4628\n",
      "Epoch 473/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1288 - sparse_categorical_accuracy: 0.4721 - val_loss: 1.1303 - val_sparse_categorical_accuracy: 0.4610\n",
      "Epoch 474/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1102 - sparse_categorical_accuracy: 0.4805 - val_loss: 1.1157 - val_sparse_categorical_accuracy: 0.4761\n",
      "Epoch 475/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.0957 - sparse_categorical_accuracy: 0.4964 - val_loss: 1.1163 - val_sparse_categorical_accuracy: 0.4855\n",
      "Epoch 476/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1069 - sparse_categorical_accuracy: 0.4688 - val_loss: 1.1235 - val_sparse_categorical_accuracy: 0.4798\n",
      "Epoch 477/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1112 - sparse_categorical_accuracy: 0.4808 - val_loss: 1.1221 - val_sparse_categorical_accuracy: 0.4761\n",
      "Epoch 478/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.0980 - sparse_categorical_accuracy: 0.4940 - val_loss: 1.1281 - val_sparse_categorical_accuracy: 0.4364\n",
      "Epoch 479/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 2ms/step - loss: 1.0991 - sparse_categorical_accuracy: 0.4862 - val_loss: 1.1431 - val_sparse_categorical_accuracy: 0.4622\n",
      "Epoch 480/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1097 - sparse_categorical_accuracy: 0.4754 - val_loss: 1.1255 - val_sparse_categorical_accuracy: 0.4654\n",
      "Epoch 481/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.0976 - sparse_categorical_accuracy: 0.4808 - val_loss: 1.1166 - val_sparse_categorical_accuracy: 0.4729\n",
      "Epoch 482/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1024 - sparse_categorical_accuracy: 0.4808 - val_loss: 1.1430 - val_sparse_categorical_accuracy: 0.4528\n",
      "Epoch 483/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1021 - sparse_categorical_accuracy: 0.4865 - val_loss: 1.1116 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 484/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1061 - sparse_categorical_accuracy: 0.4823 - val_loss: 1.1339 - val_sparse_categorical_accuracy: 0.4660\n",
      "Epoch 485/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.0997 - sparse_categorical_accuracy: 0.4847 - val_loss: 1.1166 - val_sparse_categorical_accuracy: 0.4666\n",
      "Epoch 486/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1160 - sparse_categorical_accuracy: 0.4742 - val_loss: 1.1156 - val_sparse_categorical_accuracy: 0.4698\n",
      "Epoch 487/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1040 - sparse_categorical_accuracy: 0.4799 - val_loss: 1.1018 - val_sparse_categorical_accuracy: 0.4742\n",
      "Epoch 488/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1174 - sparse_categorical_accuracy: 0.4739 - val_loss: 1.1165 - val_sparse_categorical_accuracy: 0.4654\n",
      "Epoch 489/1200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.1137 - sparse_categorical_accuracy: 0.4736 - val_loss: 1.1041 - val_sparse_categorical_accuracy: 0.4742\n",
      "Accuracy of the model on test set: 48.866%\n",
      "Accuracy of the model on validation set: 46.631%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "np.random.seed = 123\n",
    "\n",
    "y = Data_train.Emotion\n",
    "X = pd.DataFrame(Data_train.drop(['Emotion','User'], axis = 1))\n",
    "\n",
    "#y_val = Data_val.Emotion\n",
    "#X_val = pd.DataFrame(Data_val.drop(['Emotion', 'User'], axis = 1))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 123)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 123)\n",
    "\n",
    "\n",
    "\n",
    "model = initModelBasic(X.shape[1], 7)\n",
    "model.compile(\n",
    "    optimizer= 'adam',\n",
    "    loss='sparse_categorical_crossentropy', # sparse because using integer labels for emotions (not OHE)\n",
    "    metrics=[ 'sparse_categorical_accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    #validation_split = 0.3,\n",
    "    #validation_data = (X_val, y_val),\n",
    "    validation_data = (X_test, y_test),\n",
    "    epochs=1200,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_sparse_categorical_accuracy',\n",
    "            patience=200,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Result on test data\n",
    "model_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(\"Accuracy of the model on test set: {:.3f}%\".format(model_acc * 100))\n",
    "\n",
    "#Result on val data\n",
    "model_acc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "print(\"Accuracy of the model on validation set: {:.3f}%\".format(model_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f77d41c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on test set: 48.992%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on validation set: 52.022%\n",
      "2\n",
      "[5, 0, 6, 5, 2, 1, 6, 0, 4, 1, 6, 6, 5, 6, 3, 5, 1, 4, 6, 5, 0, 0, 3, 0, 3, 3, 3, 5, 2, 6, 4, 0, 3, 1, 0, 5, 6, 1, 6, 5, 0, 4, 3, 1, 6, 5, 2, 5, 0, 6, 6, 3, 5, 6, 5, 3, 0, 6, 0, 4, 6, 3, 0, 3, 5, 0, 6, 6, 6, 6, 3, 6, 0, 3, 5, 4, 5, 0, 1, 6, 2, 5, 4, 0, 6, 5, 3, 0, 5, 6, 6, 0, 5, 5, 6, 3, 4, 0, 6, 0, 0, 5, 2, 0, 0, 4, 0, 1, 3, 2, 3, 1, 0, 5, 0, 4, 3, 5, 0, 2, 0, 3, 0, 5, 3, 5, 6, 6, 0, 1, 0, 1, 4, 6, 6, 5, 6, 2, 2, 1, 5, 5, 6, 2, 6, 4, 3, 3, 6, 0, 0, 2, 0, 0, 6, 3, 3, 3, 3, 3, 0, 5, 5, 0, 3, 6, 0, 5, 0, 5, 5, 0, 6, 3, 1, 5, 5, 4, 3, 0, 2, 3, 5, 0, 0, 2, 6, 4, 3, 2, 6, 6, 0, 6, 5, 1, 3, 6, 0, 5, 6, 2, 2, 6, 6, 5, 1, 6, 0, 4, 1, 2, 3, 5, 1, 0, 2, 5, 6, 4, 3, 3, 6, 2, 6, 5, 0, 3, 4, 6, 3, 6, 3, 5, 5, 3, 6, 5, 3, 5, 6, 6, 3, 2, 5, 6, 2, 0, 5, 5, 0, 0, 1, 3, 6, 2, 2, 5, 6, 4, 3, 0, 0, 4, 6, 0, 5, 4, 6, 1, 1, 3, 6, 0, 5, 5, 5, 0, 5, 1, 5, 1, 6, 4, 3, 2, 5, 0, 3, 0, 3, 5, 5, 5, 5, 2, 5, 3, 5, 0, 6, 6, 6, 3, 0, 6, 0, 5, 2, 0, 0, 6, 3, 0, 5, 2, 5, 3, 1, 6, 6, 5, 2, 5, 6, 5, 6, 3, 0, 0, 3, 3, 0, 5, 3, 0, 6, 5, 5, 5, 3, 2, 0, 3, 6, 6, 1, 1, 3, 5, 3, 3, 0, 0, 2, 2, 5, 2, 1, 0, 5, 1, 6, 6, 4, 4, 1, 5, 0, 5, 0]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "#model.save('8_features_train_test_16.983')\n",
    "#test 60.691  val 16.983\n",
    "#model = load_model('8_features_train_test') #val 19%!\n",
    "\n",
    "\n",
    "\n",
    "model_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(\"Accuracy of the model on test set: {:.3f}%\".format(model_acc * 100))\n",
    "\n",
    "\n",
    "\n",
    "# Plot the accuracy curve for training\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], color='r', label=\"Accuracy\")\n",
    "\n",
    "plt.title(\"Validation accuracy\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "model_acc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "print(\"Accuracy of the model on validation set: {:.3f}%\".format(model_acc * 100))\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_pred = [np.argmax(pre) for pre in y_val_pred]\n",
    "print(np.argmax(y_val_pred))\n",
    "print(y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f2f7d63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 9)]               0         \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda)  (None, 9, 1)             0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 9, 256)            198912    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 16135     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 215,047\n",
      "Trainable params: 215,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "38/38 [==============================] - 4s 47ms/step - loss: 1.9661 - accuracy: 0.1556 - val_loss: 1.9222 - val_accuracy: 0.1762\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.9319 - accuracy: 0.1835 - val_loss: 1.9217 - val_accuracy: 0.1820\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.9220 - accuracy: 0.1811 - val_loss: 1.9028 - val_accuracy: 0.2107\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.9161 - accuracy: 0.1942 - val_loss: 1.9073 - val_accuracy: 0.2165\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.9197 - accuracy: 0.1778 - val_loss: 1.9098 - val_accuracy: 0.2241\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.9153 - accuracy: 0.2074 - val_loss: 1.8978 - val_accuracy: 0.1935\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.9063 - accuracy: 0.1959 - val_loss: 1.8900 - val_accuracy: 0.2414\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.9046 - accuracy: 0.2008 - val_loss: 1.8857 - val_accuracy: 0.2280\n",
      "Epoch 9/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8964 - accuracy: 0.2115 - val_loss: 1.8606 - val_accuracy: 0.2682\n",
      "Epoch 10/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8970 - accuracy: 0.2049 - val_loss: 1.8765 - val_accuracy: 0.2222\n",
      "Epoch 11/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8959 - accuracy: 0.2025 - val_loss: 1.8642 - val_accuracy: 0.2759\n",
      "Epoch 12/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.8876 - accuracy: 0.2354 - val_loss: 1.8639 - val_accuracy: 0.2395\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.8827 - accuracy: 0.2280 - val_loss: 1.8542 - val_accuracy: 0.2510\n",
      "Epoch 14/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8719 - accuracy: 0.2255 - val_loss: 1.8634 - val_accuracy: 0.2490\n",
      "Epoch 15/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8747 - accuracy: 0.2337 - val_loss: 1.8859 - val_accuracy: 0.2126\n",
      "Epoch 16/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8710 - accuracy: 0.2494 - val_loss: 1.8212 - val_accuracy: 0.2682\n",
      "Epoch 17/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8537 - accuracy: 0.2502 - val_loss: 1.8272 - val_accuracy: 0.2414\n",
      "Epoch 18/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.8570 - accuracy: 0.2519 - val_loss: 1.8242 - val_accuracy: 0.2625\n",
      "Epoch 19/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8554 - accuracy: 0.2510 - val_loss: 1.8168 - val_accuracy: 0.3161\n",
      "Epoch 20/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.8521 - accuracy: 0.2494 - val_loss: 1.8458 - val_accuracy: 0.2816\n",
      "Epoch 21/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.8397 - accuracy: 0.2486 - val_loss: 1.8150 - val_accuracy: 0.2778\n",
      "Epoch 22/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8284 - accuracy: 0.2724 - val_loss: 1.8165 - val_accuracy: 0.2931\n",
      "Epoch 23/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8334 - accuracy: 0.2576 - val_loss: 1.8035 - val_accuracy: 0.2816\n",
      "Epoch 24/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8292 - accuracy: 0.2626 - val_loss: 1.8061 - val_accuracy: 0.2720\n",
      "Epoch 25/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8171 - accuracy: 0.2642 - val_loss: 1.7945 - val_accuracy: 0.3027\n",
      "Epoch 26/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.8026 - accuracy: 0.2840 - val_loss: 1.7890 - val_accuracy: 0.2701\n",
      "Epoch 27/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.7913 - accuracy: 0.2955 - val_loss: 1.7922 - val_accuracy: 0.2989\n",
      "Epoch 28/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.7942 - accuracy: 0.2856 - val_loss: 1.7721 - val_accuracy: 0.2778\n",
      "Epoch 29/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7994 - accuracy: 0.2733 - val_loss: 1.8004 - val_accuracy: 0.3046\n",
      "Epoch 30/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7787 - accuracy: 0.2922 - val_loss: 1.7713 - val_accuracy: 0.2950\n",
      "Epoch 31/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7845 - accuracy: 0.2765 - val_loss: 1.7789 - val_accuracy: 0.3372\n",
      "Epoch 32/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.7715 - accuracy: 0.2914 - val_loss: 1.7928 - val_accuracy: 0.2739\n",
      "Epoch 33/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7793 - accuracy: 0.2782 - val_loss: 1.7694 - val_accuracy: 0.2931\n",
      "Epoch 34/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7575 - accuracy: 0.3111 - val_loss: 1.7505 - val_accuracy: 0.2874\n",
      "Epoch 35/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7412 - accuracy: 0.2947 - val_loss: 1.7608 - val_accuracy: 0.3142\n",
      "Epoch 36/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.7309 - accuracy: 0.3062 - val_loss: 1.7236 - val_accuracy: 0.2912\n",
      "Epoch 37/1000\n",
      "38/38 [==============================] - 1s 40ms/step - loss: 1.7269 - accuracy: 0.3062 - val_loss: 1.7549 - val_accuracy: 0.2893\n",
      "Epoch 38/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.7238 - accuracy: 0.3045 - val_loss: 1.7565 - val_accuracy: 0.2893\n",
      "Epoch 39/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.7044 - accuracy: 0.3095 - val_loss: 1.7531 - val_accuracy: 0.2605\n",
      "Epoch 40/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.7036 - accuracy: 0.3226 - val_loss: 1.7157 - val_accuracy: 0.3276\n",
      "Epoch 41/1000\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 1.6841 - accuracy: 0.3144 - val_loss: 1.6986 - val_accuracy: 0.3142\n",
      "Epoch 42/1000\n",
      "38/38 [==============================] - 2s 48ms/step - loss: 1.6689 - accuracy: 0.3300 - val_loss: 1.7188 - val_accuracy: 0.3276\n",
      "Epoch 43/1000\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 1.6689 - accuracy: 0.3185 - val_loss: 1.6751 - val_accuracy: 0.3525\n",
      "Epoch 44/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.6648 - accuracy: 0.3267 - val_loss: 1.6855 - val_accuracy: 0.3257\n",
      "Epoch 45/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.6372 - accuracy: 0.3366 - val_loss: 1.6817 - val_accuracy: 0.3276\n",
      "Epoch 46/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.6425 - accuracy: 0.3267 - val_loss: 1.6552 - val_accuracy: 0.3640\n",
      "Epoch 47/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.6398 - accuracy: 0.3317 - val_loss: 1.6644 - val_accuracy: 0.3391\n",
      "Epoch 48/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.6132 - accuracy: 0.3481 - val_loss: 1.6434 - val_accuracy: 0.3716\n",
      "Epoch 49/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.5937 - accuracy: 0.3597 - val_loss: 1.6387 - val_accuracy: 0.3391\n",
      "Epoch 50/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.5942 - accuracy: 0.3457 - val_loss: 1.6051 - val_accuracy: 0.3525\n",
      "Epoch 51/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.5897 - accuracy: 0.3449 - val_loss: 1.6380 - val_accuracy: 0.3429\n",
      "Epoch 52/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.5639 - accuracy: 0.3728 - val_loss: 1.5930 - val_accuracy: 0.3544\n",
      "Epoch 53/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.5433 - accuracy: 0.3720 - val_loss: 1.6207 - val_accuracy: 0.3640\n",
      "Epoch 54/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5675 - accuracy: 0.3663 - val_loss: 1.6187 - val_accuracy: 0.3602\n",
      "Epoch 55/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5494 - accuracy: 0.3770 - val_loss: 1.5902 - val_accuracy: 0.3755\n",
      "Epoch 56/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.5262 - accuracy: 0.3712 - val_loss: 1.5532 - val_accuracy: 0.3640\n",
      "Epoch 57/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5206 - accuracy: 0.3761 - val_loss: 1.5460 - val_accuracy: 0.4023\n",
      "Epoch 58/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5175 - accuracy: 0.4016 - val_loss: 1.5668 - val_accuracy: 0.3602\n",
      "Epoch 59/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5154 - accuracy: 0.3860 - val_loss: 1.5388 - val_accuracy: 0.3774\n",
      "Epoch 60/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.5000 - accuracy: 0.3893 - val_loss: 1.5381 - val_accuracy: 0.3774\n",
      "Epoch 61/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4843 - accuracy: 0.4123 - val_loss: 1.5952 - val_accuracy: 0.3238\n",
      "Epoch 62/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4773 - accuracy: 0.3959 - val_loss: 1.5598 - val_accuracy: 0.3448\n",
      "Epoch 63/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4781 - accuracy: 0.4074 - val_loss: 1.4844 - val_accuracy: 0.4272\n",
      "Epoch 64/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4428 - accuracy: 0.3992 - val_loss: 1.5117 - val_accuracy: 0.4368\n",
      "Epoch 65/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4390 - accuracy: 0.3926 - val_loss: 1.5630 - val_accuracy: 0.3927\n",
      "Epoch 66/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4525 - accuracy: 0.3951 - val_loss: 1.5329 - val_accuracy: 0.3621\n",
      "Epoch 67/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4327 - accuracy: 0.4288 - val_loss: 1.5145 - val_accuracy: 0.3870\n",
      "Epoch 68/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4532 - accuracy: 0.3934 - val_loss: 1.4805 - val_accuracy: 0.4330\n",
      "Epoch 69/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4135 - accuracy: 0.4313 - val_loss: 1.4607 - val_accuracy: 0.4253\n",
      "Epoch 70/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4071 - accuracy: 0.4214 - val_loss: 1.5036 - val_accuracy: 0.4042\n",
      "Epoch 71/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4097 - accuracy: 0.4239 - val_loss: 1.4817 - val_accuracy: 0.4119\n",
      "Epoch 72/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4084 - accuracy: 0.4091 - val_loss: 1.5304 - val_accuracy: 0.3870\n",
      "Epoch 73/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.3759 - accuracy: 0.4535 - val_loss: 1.4497 - val_accuracy: 0.4138\n",
      "Epoch 74/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3731 - accuracy: 0.4362 - val_loss: 1.4643 - val_accuracy: 0.4330\n",
      "Epoch 75/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3753 - accuracy: 0.4576 - val_loss: 1.4655 - val_accuracy: 0.4368\n",
      "Epoch 76/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3693 - accuracy: 0.4502 - val_loss: 1.4518 - val_accuracy: 0.4425\n",
      "Epoch 77/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3566 - accuracy: 0.4436 - val_loss: 1.4169 - val_accuracy: 0.4176\n",
      "Epoch 78/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.3651 - accuracy: 0.4387 - val_loss: 1.4515 - val_accuracy: 0.4004\n",
      "Epoch 79/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.3593 - accuracy: 0.4543 - val_loss: 1.4112 - val_accuracy: 0.4579\n",
      "Epoch 80/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.3385 - accuracy: 0.4543 - val_loss: 1.4286 - val_accuracy: 0.4502\n",
      "Epoch 81/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3449 - accuracy: 0.4568 - val_loss: 1.4086 - val_accuracy: 0.4272\n",
      "Epoch 82/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.3381 - accuracy: 0.4601 - val_loss: 1.4298 - val_accuracy: 0.4540\n",
      "Epoch 83/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.3181 - accuracy: 0.4708 - val_loss: 1.3983 - val_accuracy: 0.4655\n",
      "Epoch 84/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.3264 - accuracy: 0.4658 - val_loss: 1.4243 - val_accuracy: 0.4004\n",
      "Epoch 85/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.3292 - accuracy: 0.4543 - val_loss: 1.4357 - val_accuracy: 0.4310\n",
      "Epoch 86/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.2780 - accuracy: 0.4872 - val_loss: 1.3853 - val_accuracy: 0.4406\n",
      "Epoch 87/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2921 - accuracy: 0.4675 - val_loss: 1.4128 - val_accuracy: 0.4272\n",
      "Epoch 88/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2789 - accuracy: 0.4765 - val_loss: 1.4092 - val_accuracy: 0.4444\n",
      "Epoch 89/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.2640 - accuracy: 0.4947 - val_loss: 1.3904 - val_accuracy: 0.4732\n",
      "Epoch 90/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2964 - accuracy: 0.4642 - val_loss: 1.4073 - val_accuracy: 0.4655\n",
      "Epoch 91/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2739 - accuracy: 0.4782 - val_loss: 1.3893 - val_accuracy: 0.4425\n",
      "Epoch 92/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.2584 - accuracy: 0.4930 - val_loss: 1.4007 - val_accuracy: 0.4444\n",
      "Epoch 93/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2714 - accuracy: 0.4848 - val_loss: 1.3558 - val_accuracy: 0.4847\n",
      "Epoch 94/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2566 - accuracy: 0.4938 - val_loss: 1.3715 - val_accuracy: 0.4713\n",
      "Epoch 95/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.2834 - accuracy: 0.4757 - val_loss: 1.3602 - val_accuracy: 0.4770\n",
      "Epoch 96/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.2656 - accuracy: 0.4864 - val_loss: 1.3667 - val_accuracy: 0.4713\n",
      "Epoch 97/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.2624 - accuracy: 0.4905 - val_loss: 1.3592 - val_accuracy: 0.4483\n",
      "Epoch 98/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.2294 - accuracy: 0.4996 - val_loss: 1.3742 - val_accuracy: 0.4464\n",
      "Epoch 99/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.2351 - accuracy: 0.4971 - val_loss: 1.3108 - val_accuracy: 0.4962\n",
      "Epoch 100/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2187 - accuracy: 0.5045 - val_loss: 1.2828 - val_accuracy: 0.5172\n",
      "Epoch 101/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.2010 - accuracy: 0.5021 - val_loss: 1.3359 - val_accuracy: 0.4483\n",
      "Epoch 102/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2150 - accuracy: 0.5029 - val_loss: 1.3436 - val_accuracy: 0.4674\n",
      "Epoch 103/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.2199 - accuracy: 0.5226 - val_loss: 1.3288 - val_accuracy: 0.4981\n",
      "Epoch 104/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.2127 - accuracy: 0.5103 - val_loss: 1.3377 - val_accuracy: 0.4866\n",
      "Epoch 105/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.1954 - accuracy: 0.5119 - val_loss: 1.3275 - val_accuracy: 0.4713\n",
      "Epoch 106/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.1776 - accuracy: 0.5226 - val_loss: 1.3134 - val_accuracy: 0.5057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.2008 - accuracy: 0.5053 - val_loss: 1.3129 - val_accuracy: 0.4866\n",
      "Epoch 108/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1968 - accuracy: 0.5251 - val_loss: 1.2973 - val_accuracy: 0.4789\n",
      "Epoch 109/1000\n",
      "38/38 [==============================] - 2s 57ms/step - loss: 1.1777 - accuracy: 0.5136 - val_loss: 1.3076 - val_accuracy: 0.5077\n",
      "Epoch 110/1000\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.1519 - accuracy: 0.5284 - val_loss: 1.3027 - val_accuracy: 0.5077\n",
      "Epoch 111/1000\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 1.1545 - accuracy: 0.5333 - val_loss: 1.3478 - val_accuracy: 0.5096\n",
      "Epoch 112/1000\n",
      "38/38 [==============================] - 3s 92ms/step - loss: 1.1566 - accuracy: 0.5202 - val_loss: 1.3114 - val_accuracy: 0.4981\n",
      "Epoch 113/1000\n",
      "38/38 [==============================] - 3s 84ms/step - loss: 1.1667 - accuracy: 0.5284 - val_loss: 1.2720 - val_accuracy: 0.5268\n",
      "Epoch 114/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.1552 - accuracy: 0.5350 - val_loss: 1.2924 - val_accuracy: 0.5268\n",
      "Epoch 115/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.1688 - accuracy: 0.5202 - val_loss: 1.2600 - val_accuracy: 0.5230\n",
      "Epoch 116/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1511 - accuracy: 0.5235 - val_loss: 1.2568 - val_accuracy: 0.5249\n",
      "Epoch 117/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1509 - accuracy: 0.5465 - val_loss: 1.2540 - val_accuracy: 0.5172\n",
      "Epoch 118/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1255 - accuracy: 0.5440 - val_loss: 1.3337 - val_accuracy: 0.5038\n",
      "Epoch 119/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.1638 - accuracy: 0.5243 - val_loss: 1.2599 - val_accuracy: 0.5192\n",
      "Epoch 120/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1287 - accuracy: 0.5440 - val_loss: 1.3064 - val_accuracy: 0.4904\n",
      "Epoch 121/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.1218 - accuracy: 0.5374 - val_loss: 1.2939 - val_accuracy: 0.4904\n",
      "Epoch 122/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.1298 - accuracy: 0.5391 - val_loss: 1.3516 - val_accuracy: 0.5000\n",
      "Epoch 123/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1211 - accuracy: 0.5547 - val_loss: 1.2625 - val_accuracy: 0.5268\n",
      "Epoch 124/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0960 - accuracy: 0.5613 - val_loss: 1.3190 - val_accuracy: 0.4904\n",
      "Epoch 125/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1141 - accuracy: 0.5547 - val_loss: 1.2439 - val_accuracy: 0.5441\n",
      "Epoch 126/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1070 - accuracy: 0.5440 - val_loss: 1.2560 - val_accuracy: 0.5192\n",
      "Epoch 127/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1127 - accuracy: 0.5424 - val_loss: 1.3472 - val_accuracy: 0.4962\n",
      "Epoch 128/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1242 - accuracy: 0.5597 - val_loss: 1.2408 - val_accuracy: 0.5460\n",
      "Epoch 129/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.0925 - accuracy: 0.5646 - val_loss: 1.3133 - val_accuracy: 0.5000\n",
      "Epoch 130/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1287 - accuracy: 0.5399 - val_loss: 1.2655 - val_accuracy: 0.5077\n",
      "Epoch 131/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.1264 - accuracy: 0.5284 - val_loss: 1.2549 - val_accuracy: 0.5498\n",
      "Epoch 132/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.1118 - accuracy: 0.5490 - val_loss: 1.2450 - val_accuracy: 0.5498\n",
      "Epoch 133/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.0891 - accuracy: 0.5588 - val_loss: 1.3179 - val_accuracy: 0.5153\n",
      "Epoch 134/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0706 - accuracy: 0.5539 - val_loss: 1.2552 - val_accuracy: 0.5402\n",
      "Epoch 135/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.1007 - accuracy: 0.5547 - val_loss: 1.2381 - val_accuracy: 0.5268\n",
      "Epoch 136/1000\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 1.1005 - accuracy: 0.5473 - val_loss: 1.2956 - val_accuracy: 0.4828\n",
      "Epoch 137/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.0820 - accuracy: 0.5350 - val_loss: 1.2561 - val_accuracy: 0.5287\n",
      "Epoch 138/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0846 - accuracy: 0.5317 - val_loss: 1.2588 - val_accuracy: 0.5517\n",
      "Epoch 139/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.0544 - accuracy: 0.5770 - val_loss: 1.2545 - val_accuracy: 0.5211\n",
      "Epoch 140/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.0725 - accuracy: 0.5737 - val_loss: 1.2638 - val_accuracy: 0.5134\n",
      "Epoch 141/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0633 - accuracy: 0.5580 - val_loss: 1.2467 - val_accuracy: 0.5307\n",
      "Epoch 142/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0681 - accuracy: 0.5588 - val_loss: 1.2845 - val_accuracy: 0.5211\n",
      "Epoch 143/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.0552 - accuracy: 0.5506 - val_loss: 1.2927 - val_accuracy: 0.5230\n",
      "Epoch 144/1000\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 1.0753 - accuracy: 0.5490 - val_loss: 1.2338 - val_accuracy: 0.5479\n",
      "Epoch 145/1000\n",
      "38/38 [==============================] - 2s 43ms/step - loss: 1.0703 - accuracy: 0.5564 - val_loss: 1.2353 - val_accuracy: 0.5230\n",
      "Epoch 146/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.0432 - accuracy: 0.5687 - val_loss: 1.2340 - val_accuracy: 0.5460\n",
      "Epoch 147/1000\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 1.0201 - accuracy: 0.5638 - val_loss: 1.2059 - val_accuracy: 0.5364\n",
      "Epoch 148/1000\n",
      "38/38 [==============================] - 5s 121ms/step - loss: 1.0312 - accuracy: 0.5794 - val_loss: 1.2329 - val_accuracy: 0.5326\n",
      "Epoch 149/1000\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 1.0429 - accuracy: 0.5794 - val_loss: 1.2605 - val_accuracy: 0.5307\n",
      "Epoch 150/1000\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 1.0575 - accuracy: 0.5605 - val_loss: 1.2892 - val_accuracy: 0.5230\n",
      "Epoch 151/1000\n",
      "38/38 [==============================] - 3s 82ms/step - loss: 1.0228 - accuracy: 0.5868 - val_loss: 1.2095 - val_accuracy: 0.5517\n",
      "Epoch 152/1000\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 1.0542 - accuracy: 0.5712 - val_loss: 1.2583 - val_accuracy: 0.5211\n",
      "Epoch 153/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.0466 - accuracy: 0.5621 - val_loss: 1.2808 - val_accuracy: 0.5268\n",
      "Epoch 154/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.0291 - accuracy: 0.5753 - val_loss: 1.2825 - val_accuracy: 0.5192\n",
      "Epoch 155/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0197 - accuracy: 0.5745 - val_loss: 1.2422 - val_accuracy: 0.5402\n",
      "Epoch 156/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0166 - accuracy: 0.5663 - val_loss: 1.2389 - val_accuracy: 0.5670\n",
      "Epoch 157/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.0266 - accuracy: 0.5770 - val_loss: 1.2478 - val_accuracy: 0.5172\n",
      "Epoch 158/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0267 - accuracy: 0.5613 - val_loss: 1.2382 - val_accuracy: 0.5460\n",
      "Epoch 159/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0198 - accuracy: 0.5737 - val_loss: 1.2647 - val_accuracy: 0.5287\n",
      "Epoch 160/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0273 - accuracy: 0.5802 - val_loss: 1.2397 - val_accuracy: 0.5345\n",
      "Epoch 161/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0164 - accuracy: 0.5819 - val_loss: 1.2616 - val_accuracy: 0.5268\n",
      "Epoch 162/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9815 - accuracy: 0.5951 - val_loss: 1.2715 - val_accuracy: 0.5479\n",
      "Epoch 163/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9969 - accuracy: 0.5753 - val_loss: 1.2420 - val_accuracy: 0.5556\n",
      "Epoch 164/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0304 - accuracy: 0.5728 - val_loss: 1.2265 - val_accuracy: 0.5441\n",
      "Epoch 165/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.0132 - accuracy: 0.5844 - val_loss: 1.2195 - val_accuracy: 0.5862\n",
      "Epoch 166/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.0023 - accuracy: 0.5802 - val_loss: 1.2264 - val_accuracy: 0.5536\n",
      "Epoch 167/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.0126 - accuracy: 0.5737 - val_loss: 1.2459 - val_accuracy: 0.5077\n",
      "Epoch 168/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9591 - accuracy: 0.5926 - val_loss: 1.2415 - val_accuracy: 0.5517\n",
      "Epoch 169/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9744 - accuracy: 0.5893 - val_loss: 1.2400 - val_accuracy: 0.5556\n",
      "Epoch 170/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9802 - accuracy: 0.5901 - val_loss: 1.2125 - val_accuracy: 0.5651\n",
      "Epoch 171/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9986 - accuracy: 0.5860 - val_loss: 1.2370 - val_accuracy: 0.5728\n",
      "Epoch 172/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9966 - accuracy: 0.5695 - val_loss: 1.2548 - val_accuracy: 0.5479\n",
      "Epoch 173/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.0015 - accuracy: 0.5720 - val_loss: 1.2497 - val_accuracy: 0.5556\n",
      "Epoch 174/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.9670 - accuracy: 0.5877 - val_loss: 1.2200 - val_accuracy: 0.5613\n",
      "Epoch 175/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9572 - accuracy: 0.6099 - val_loss: 1.2546 - val_accuracy: 0.5613\n",
      "Epoch 176/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9871 - accuracy: 0.5827 - val_loss: 1.2441 - val_accuracy: 0.5536\n",
      "Epoch 177/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9680 - accuracy: 0.5959 - val_loss: 1.2285 - val_accuracy: 0.5785\n",
      "Epoch 178/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9736 - accuracy: 0.6049 - val_loss: 1.2644 - val_accuracy: 0.5613\n",
      "Epoch 179/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9641 - accuracy: 0.6016 - val_loss: 1.3206 - val_accuracy: 0.5498\n",
      "Epoch 180/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9605 - accuracy: 0.6091 - val_loss: 1.2341 - val_accuracy: 0.5747\n",
      "Epoch 181/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9496 - accuracy: 0.6033 - val_loss: 1.2518 - val_accuracy: 0.5747\n",
      "Epoch 182/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.9524 - accuracy: 0.6148 - val_loss: 1.2432 - val_accuracy: 0.5441\n",
      "Epoch 183/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.9716 - accuracy: 0.5835 - val_loss: 1.2157 - val_accuracy: 0.5651\n",
      "Epoch 184/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9385 - accuracy: 0.6156 - val_loss: 1.2059 - val_accuracy: 0.5785\n",
      "Epoch 185/1000\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.9583 - accuracy: 0.6140 - val_loss: 1.1834 - val_accuracy: 0.5728\n",
      "Epoch 186/1000\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 0.9726 - accuracy: 0.5918 - val_loss: 1.1975 - val_accuracy: 0.5709\n",
      "Epoch 187/1000\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.9400 - accuracy: 0.5909 - val_loss: 1.2023 - val_accuracy: 0.5613\n",
      "Epoch 188/1000\n",
      "38/38 [==============================] - 3s 83ms/step - loss: 0.9652 - accuracy: 0.5992 - val_loss: 1.2433 - val_accuracy: 0.5632\n",
      "Epoch 189/1000\n",
      "38/38 [==============================] - 4s 93ms/step - loss: 0.9928 - accuracy: 0.5852 - val_loss: 1.2802 - val_accuracy: 0.5383\n",
      "Epoch 190/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9612 - accuracy: 0.5819 - val_loss: 1.1950 - val_accuracy: 0.5766\n",
      "Epoch 191/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9697 - accuracy: 0.5901 - val_loss: 1.2398 - val_accuracy: 0.5441\n",
      "Epoch 192/1000\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.9453 - accuracy: 0.6033 - val_loss: 1.2272 - val_accuracy: 0.5709\n",
      "Epoch 193/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9606 - accuracy: 0.6173 - val_loss: 1.2493 - val_accuracy: 0.5805\n",
      "Epoch 194/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9383 - accuracy: 0.6049 - val_loss: 1.1945 - val_accuracy: 0.5632\n",
      "Epoch 195/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.9598 - accuracy: 0.5959 - val_loss: 1.2030 - val_accuracy: 0.5843\n",
      "Epoch 196/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.9407 - accuracy: 0.6049 - val_loss: 1.2183 - val_accuracy: 0.5900\n",
      "Epoch 197/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.9099 - accuracy: 0.6165 - val_loss: 1.1710 - val_accuracy: 0.5958\n",
      "Epoch 198/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9545 - accuracy: 0.6058 - val_loss: 1.2426 - val_accuracy: 0.5498\n",
      "Epoch 199/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.9410 - accuracy: 0.5959 - val_loss: 1.2218 - val_accuracy: 0.5556\n",
      "Epoch 200/1000\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.9250 - accuracy: 0.6058 - val_loss: 1.2301 - val_accuracy: 0.5651\n",
      "Epoch 201/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9173 - accuracy: 0.6247 - val_loss: 1.2187 - val_accuracy: 0.5843\n",
      "Epoch 202/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9334 - accuracy: 0.6099 - val_loss: 1.2843 - val_accuracy: 0.5421\n",
      "Epoch 203/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9277 - accuracy: 0.6140 - val_loss: 1.2395 - val_accuracy: 0.5613\n",
      "Epoch 204/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9284 - accuracy: 0.6082 - val_loss: 1.1955 - val_accuracy: 0.5728\n",
      "Epoch 205/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.9155 - accuracy: 0.6189 - val_loss: 1.2985 - val_accuracy: 0.5383\n",
      "Epoch 206/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9458 - accuracy: 0.6058 - val_loss: 1.1895 - val_accuracy: 0.5785\n",
      "Epoch 207/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8789 - accuracy: 0.6362 - val_loss: 1.1923 - val_accuracy: 0.5900\n",
      "Epoch 208/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9195 - accuracy: 0.6132 - val_loss: 1.2108 - val_accuracy: 0.5594\n",
      "Epoch 209/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9222 - accuracy: 0.6189 - val_loss: 1.2136 - val_accuracy: 0.5747\n",
      "Epoch 210/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8959 - accuracy: 0.6255 - val_loss: 1.1964 - val_accuracy: 0.5824\n",
      "Epoch 211/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9292 - accuracy: 0.6016 - val_loss: 1.1987 - val_accuracy: 0.5575\n",
      "Epoch 212/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9126 - accuracy: 0.6025 - val_loss: 1.2278 - val_accuracy: 0.5709\n",
      "Epoch 213/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9079 - accuracy: 0.6370 - val_loss: 1.2206 - val_accuracy: 0.5747\n",
      "Epoch 214/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8949 - accuracy: 0.6091 - val_loss: 1.1984 - val_accuracy: 0.5766\n",
      "Epoch 215/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8658 - accuracy: 0.6403 - val_loss: 1.2174 - val_accuracy: 0.5805\n",
      "Epoch 216/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8831 - accuracy: 0.6239 - val_loss: 1.2579 - val_accuracy: 0.5402\n",
      "Epoch 217/1000\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.9174 - accuracy: 0.6272 - val_loss: 1.2453 - val_accuracy: 0.5824\n",
      "Epoch 218/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9270 - accuracy: 0.6041 - val_loss: 1.2090 - val_accuracy: 0.5632\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8975 - accuracy: 0.6255 - val_loss: 1.1933 - val_accuracy: 0.6054\n",
      "Epoch 220/1000\n",
      "38/38 [==============================] - 2s 47ms/step - loss: 0.8827 - accuracy: 0.6362 - val_loss: 1.2186 - val_accuracy: 0.5747\n",
      "Epoch 221/1000\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 0.8770 - accuracy: 0.6370 - val_loss: 1.2194 - val_accuracy: 0.5690\n",
      "Epoch 222/1000\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 0.8879 - accuracy: 0.6354 - val_loss: 1.2194 - val_accuracy: 0.5977\n",
      "Epoch 223/1000\n",
      "38/38 [==============================] - 5s 119ms/step - loss: 0.8923 - accuracy: 0.6387 - val_loss: 1.2297 - val_accuracy: 0.5728\n",
      "Epoch 224/1000\n",
      "38/38 [==============================] - 3s 79ms/step - loss: 0.8979 - accuracy: 0.6272 - val_loss: 1.2010 - val_accuracy: 0.5690\n",
      "Epoch 225/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8750 - accuracy: 0.6263 - val_loss: 1.2033 - val_accuracy: 0.5958\n",
      "Epoch 226/1000\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 0.8973 - accuracy: 0.6156 - val_loss: 1.1807 - val_accuracy: 0.5881\n",
      "Epoch 227/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.8932 - accuracy: 0.6156 - val_loss: 1.2052 - val_accuracy: 0.6034\n",
      "Epoch 228/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8771 - accuracy: 0.6346 - val_loss: 1.2351 - val_accuracy: 0.5843\n",
      "Epoch 229/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9087 - accuracy: 0.6239 - val_loss: 1.1978 - val_accuracy: 0.5594\n",
      "Epoch 230/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8660 - accuracy: 0.6280 - val_loss: 1.2104 - val_accuracy: 0.5805\n",
      "Epoch 231/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8682 - accuracy: 0.6247 - val_loss: 1.1774 - val_accuracy: 0.5881\n",
      "Epoch 232/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8650 - accuracy: 0.6362 - val_loss: 1.1920 - val_accuracy: 0.6130\n",
      "Epoch 233/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9083 - accuracy: 0.6313 - val_loss: 1.2133 - val_accuracy: 0.5785\n",
      "Epoch 234/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8709 - accuracy: 0.6181 - val_loss: 1.1856 - val_accuracy: 0.5824\n",
      "Epoch 235/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9061 - accuracy: 0.6033 - val_loss: 1.2361 - val_accuracy: 0.5843\n",
      "Epoch 236/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8646 - accuracy: 0.6370 - val_loss: 1.2156 - val_accuracy: 0.5556\n",
      "Epoch 237/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8579 - accuracy: 0.6321 - val_loss: 1.1983 - val_accuracy: 0.5824\n",
      "Epoch 238/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8866 - accuracy: 0.6280 - val_loss: 1.2180 - val_accuracy: 0.5690\n",
      "Epoch 239/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8685 - accuracy: 0.6354 - val_loss: 1.2503 - val_accuracy: 0.5575\n",
      "Epoch 240/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8477 - accuracy: 0.6436 - val_loss: 1.1771 - val_accuracy: 0.6092\n",
      "Epoch 241/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8720 - accuracy: 0.6247 - val_loss: 1.2104 - val_accuracy: 0.5670\n",
      "Epoch 242/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8717 - accuracy: 0.6420 - val_loss: 1.1836 - val_accuracy: 0.6245\n",
      "Epoch 243/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8613 - accuracy: 0.6288 - val_loss: 1.2509 - val_accuracy: 0.5920\n",
      "Epoch 244/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8667 - accuracy: 0.6370 - val_loss: 1.2103 - val_accuracy: 0.5785\n",
      "Epoch 245/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8409 - accuracy: 0.6494 - val_loss: 1.2403 - val_accuracy: 0.5651\n",
      "Epoch 246/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8555 - accuracy: 0.6477 - val_loss: 1.2451 - val_accuracy: 0.6034\n",
      "Epoch 247/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8745 - accuracy: 0.6247 - val_loss: 1.2194 - val_accuracy: 0.5785\n",
      "Epoch 248/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8323 - accuracy: 0.6362 - val_loss: 1.2419 - val_accuracy: 0.6034\n",
      "Epoch 249/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8488 - accuracy: 0.6379 - val_loss: 1.2185 - val_accuracy: 0.5900\n",
      "Epoch 250/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.8748 - accuracy: 0.6305 - val_loss: 1.1968 - val_accuracy: 0.6015\n",
      "Epoch 251/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8556 - accuracy: 0.6329 - val_loss: 1.1659 - val_accuracy: 0.6054\n",
      "Epoch 252/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8362 - accuracy: 0.6576 - val_loss: 1.1999 - val_accuracy: 0.6054\n",
      "Epoch 253/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8444 - accuracy: 0.6403 - val_loss: 1.1905 - val_accuracy: 0.5996\n",
      "Epoch 254/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8179 - accuracy: 0.6494 - val_loss: 1.2465 - val_accuracy: 0.5958\n",
      "Epoch 255/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8491 - accuracy: 0.6510 - val_loss: 1.2265 - val_accuracy: 0.5843\n",
      "Epoch 256/1000\n",
      "38/38 [==============================] - 3s 80ms/step - loss: 0.9059 - accuracy: 0.6305 - val_loss: 1.1837 - val_accuracy: 0.5977\n",
      "Epoch 257/1000\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.8496 - accuracy: 0.6412 - val_loss: 1.1859 - val_accuracy: 0.5881\n",
      "Epoch 258/1000\n",
      "38/38 [==============================] - 4s 95ms/step - loss: 0.8367 - accuracy: 0.6379 - val_loss: 1.2009 - val_accuracy: 0.6130\n",
      "Epoch 259/1000\n",
      "38/38 [==============================] - 4s 97ms/step - loss: 0.8341 - accuracy: 0.6461 - val_loss: 1.2062 - val_accuracy: 0.5805\n",
      "Epoch 260/1000\n",
      "38/38 [==============================] - 3s 79ms/step - loss: 0.8519 - accuracy: 0.6379 - val_loss: 1.2824 - val_accuracy: 0.5690\n",
      "Epoch 261/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8310 - accuracy: 0.6568 - val_loss: 1.2163 - val_accuracy: 0.5805\n",
      "Epoch 262/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8705 - accuracy: 0.6346 - val_loss: 1.2696 - val_accuracy: 0.5747\n",
      "Epoch 263/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8795 - accuracy: 0.6214 - val_loss: 1.2437 - val_accuracy: 0.5900\n",
      "Epoch 264/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8289 - accuracy: 0.6494 - val_loss: 1.2222 - val_accuracy: 0.5920\n",
      "Epoch 265/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8548 - accuracy: 0.6494 - val_loss: 1.2161 - val_accuracy: 0.5939\n",
      "Epoch 266/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8381 - accuracy: 0.6486 - val_loss: 1.1846 - val_accuracy: 0.6149\n",
      "Epoch 267/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8122 - accuracy: 0.6609 - val_loss: 1.2365 - val_accuracy: 0.6092\n",
      "Epoch 268/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8396 - accuracy: 0.6395 - val_loss: 1.2846 - val_accuracy: 0.6073\n",
      "Epoch 269/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8182 - accuracy: 0.6560 - val_loss: 1.2851 - val_accuracy: 0.6015\n",
      "Epoch 270/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8192 - accuracy: 0.6535 - val_loss: 1.2270 - val_accuracy: 0.5900\n",
      "Epoch 271/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8289 - accuracy: 0.6420 - val_loss: 1.2611 - val_accuracy: 0.6226\n",
      "Epoch 272/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8135 - accuracy: 0.6601 - val_loss: 1.2795 - val_accuracy: 0.5766\n",
      "Epoch 273/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8595 - accuracy: 0.6395 - val_loss: 1.2891 - val_accuracy: 0.5805\n",
      "Epoch 274/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8147 - accuracy: 0.6724 - val_loss: 1.2620 - val_accuracy: 0.6111\n",
      "Epoch 275/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8085 - accuracy: 0.6519 - val_loss: 1.2263 - val_accuracy: 0.6015\n",
      "Epoch 276/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8309 - accuracy: 0.6494 - val_loss: 1.2252 - val_accuracy: 0.5920\n",
      "Epoch 277/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8286 - accuracy: 0.6403 - val_loss: 1.2703 - val_accuracy: 0.5632\n",
      "Epoch 278/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8438 - accuracy: 0.6362 - val_loss: 1.2111 - val_accuracy: 0.6073\n",
      "Epoch 279/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8163 - accuracy: 0.6576 - val_loss: 1.2538 - val_accuracy: 0.6015\n",
      "Epoch 280/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.8339 - accuracy: 0.6560 - val_loss: 1.2512 - val_accuracy: 0.5939\n",
      "Epoch 281/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8290 - accuracy: 0.6477 - val_loss: 1.2405 - val_accuracy: 0.5881\n",
      "Epoch 282/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8358 - accuracy: 0.6510 - val_loss: 1.2704 - val_accuracy: 0.5651\n",
      "Epoch 283/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8177 - accuracy: 0.6519 - val_loss: 1.2122 - val_accuracy: 0.5958\n",
      "Epoch 284/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.8122 - accuracy: 0.6510 - val_loss: 1.2605 - val_accuracy: 0.5747\n",
      "Epoch 285/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8199 - accuracy: 0.6486 - val_loss: 1.2512 - val_accuracy: 0.6149\n",
      "Epoch 286/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8105 - accuracy: 0.6576 - val_loss: 1.2188 - val_accuracy: 0.6245\n",
      "Epoch 287/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7880 - accuracy: 0.6626 - val_loss: 1.3096 - val_accuracy: 0.5843\n",
      "Epoch 288/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8253 - accuracy: 0.6576 - val_loss: 1.2674 - val_accuracy: 0.6188\n",
      "Epoch 289/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.7991 - accuracy: 0.6568 - val_loss: 1.2404 - val_accuracy: 0.6054\n",
      "Epoch 290/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7936 - accuracy: 0.6634 - val_loss: 1.2423 - val_accuracy: 0.6130\n",
      "Epoch 291/1000\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.7945 - accuracy: 0.6543 - val_loss: 1.2750 - val_accuracy: 0.6034\n",
      "Epoch 292/1000\n",
      "38/38 [==============================] - 4s 118ms/step - loss: 0.8217 - accuracy: 0.6461 - val_loss: 1.2304 - val_accuracy: 0.6092\n",
      "Epoch 293/1000\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 0.8030 - accuracy: 0.6617 - val_loss: 1.2410 - val_accuracy: 0.6111\n",
      "Epoch 294/1000\n",
      "38/38 [==============================] - 4s 95ms/step - loss: 0.8204 - accuracy: 0.6576 - val_loss: 1.2987 - val_accuracy: 0.5709\n",
      "Epoch 295/1000\n",
      "38/38 [==============================] - 2s 47ms/step - loss: 0.8318 - accuracy: 0.6362 - val_loss: 1.2765 - val_accuracy: 0.5766\n",
      "Epoch 296/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.8267 - accuracy: 0.6420 - val_loss: 1.2606 - val_accuracy: 0.6015\n",
      "Epoch 297/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8095 - accuracy: 0.6617 - val_loss: 1.2833 - val_accuracy: 0.5900\n",
      "Epoch 298/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8045 - accuracy: 0.6667 - val_loss: 1.2069 - val_accuracy: 0.6398\n",
      "Epoch 299/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8091 - accuracy: 0.6444 - val_loss: 1.2112 - val_accuracy: 0.6034\n",
      "Epoch 300/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8028 - accuracy: 0.6626 - val_loss: 1.2234 - val_accuracy: 0.6111\n",
      "Epoch 301/1000\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.7981 - accuracy: 0.6749 - val_loss: 1.2077 - val_accuracy: 0.6207\n",
      "Epoch 302/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7891 - accuracy: 0.6626 - val_loss: 1.2448 - val_accuracy: 0.5881\n",
      "Epoch 303/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7988 - accuracy: 0.6543 - val_loss: 1.2783 - val_accuracy: 0.5996\n",
      "Epoch 304/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.7971 - accuracy: 0.6527 - val_loss: 1.2485 - val_accuracy: 0.6264\n",
      "Epoch 305/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7934 - accuracy: 0.6650 - val_loss: 1.2263 - val_accuracy: 0.6149\n",
      "Epoch 306/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7813 - accuracy: 0.6716 - val_loss: 1.3060 - val_accuracy: 0.5939\n",
      "Epoch 307/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.8110 - accuracy: 0.6617 - val_loss: 1.2526 - val_accuracy: 0.5996\n",
      "Epoch 308/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7887 - accuracy: 0.6658 - val_loss: 1.2693 - val_accuracy: 0.5881\n",
      "Epoch 309/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7991 - accuracy: 0.6749 - val_loss: 1.2614 - val_accuracy: 0.6073\n",
      "Epoch 310/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7716 - accuracy: 0.6733 - val_loss: 1.2964 - val_accuracy: 0.5920\n",
      "Epoch 311/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.8059 - accuracy: 0.6576 - val_loss: 1.2691 - val_accuracy: 0.5766\n",
      "Epoch 312/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.8201 - accuracy: 0.6337 - val_loss: 1.2712 - val_accuracy: 0.5977\n",
      "Epoch 313/1000\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.7745 - accuracy: 0.6675 - val_loss: 1.2468 - val_accuracy: 0.6073\n",
      "Epoch 314/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7899 - accuracy: 0.6551 - val_loss: 1.2350 - val_accuracy: 0.6207\n",
      "Epoch 315/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.8136 - accuracy: 0.6494 - val_loss: 1.3031 - val_accuracy: 0.5881\n",
      "Epoch 316/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7614 - accuracy: 0.6848 - val_loss: 1.2412 - val_accuracy: 0.6360\n",
      "Epoch 317/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.8030 - accuracy: 0.6510 - val_loss: 1.2350 - val_accuracy: 0.6073\n",
      "Epoch 318/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7831 - accuracy: 0.6576 - val_loss: 1.2431 - val_accuracy: 0.6073\n",
      "Epoch 319/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7870 - accuracy: 0.6700 - val_loss: 1.2667 - val_accuracy: 0.6054\n",
      "Epoch 320/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7764 - accuracy: 0.6700 - val_loss: 1.2237 - val_accuracy: 0.6092\n",
      "Epoch 321/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7716 - accuracy: 0.6642 - val_loss: 1.2303 - val_accuracy: 0.6073\n",
      "Epoch 322/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7716 - accuracy: 0.6642 - val_loss: 1.3363 - val_accuracy: 0.5881\n",
      "Epoch 323/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7783 - accuracy: 0.6601 - val_loss: 1.2119 - val_accuracy: 0.6130\n",
      "Epoch 324/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7872 - accuracy: 0.6675 - val_loss: 1.2256 - val_accuracy: 0.6130\n",
      "Epoch 325/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7774 - accuracy: 0.6765 - val_loss: 1.3077 - val_accuracy: 0.5594\n",
      "Epoch 326/1000\n",
      "38/38 [==============================] - 2s 48ms/step - loss: 0.7710 - accuracy: 0.6749 - val_loss: 1.2657 - val_accuracy: 0.6169\n",
      "Epoch 327/1000\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.7575 - accuracy: 0.6749 - val_loss: 1.2670 - val_accuracy: 0.6245\n",
      "Epoch 328/1000\n",
      "38/38 [==============================] - 4s 100ms/step - loss: 0.7873 - accuracy: 0.6609 - val_loss: 1.3344 - val_accuracy: 0.6054\n",
      "Epoch 329/1000\n",
      "38/38 [==============================] - 3s 86ms/step - loss: 0.7985 - accuracy: 0.6733 - val_loss: 1.2898 - val_accuracy: 0.5996\n",
      "Epoch 330/1000\n",
      "38/38 [==============================] - 4s 97ms/step - loss: 0.7795 - accuracy: 0.6798 - val_loss: 1.2858 - val_accuracy: 0.5996\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 2s 57ms/step - loss: 0.7569 - accuracy: 0.6741 - val_loss: 1.2542 - val_accuracy: 0.6456\n",
      "Epoch 332/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7976 - accuracy: 0.6650 - val_loss: 1.2216 - val_accuracy: 0.6245\n",
      "Epoch 333/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7627 - accuracy: 0.6642 - val_loss: 1.2549 - val_accuracy: 0.5977\n",
      "Epoch 334/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7383 - accuracy: 0.6724 - val_loss: 1.2573 - val_accuracy: 0.6226\n",
      "Epoch 335/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7911 - accuracy: 0.6560 - val_loss: 1.3300 - val_accuracy: 0.5728\n",
      "Epoch 336/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7552 - accuracy: 0.6683 - val_loss: 1.2894 - val_accuracy: 0.6111\n",
      "Epoch 337/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7837 - accuracy: 0.6708 - val_loss: 1.3041 - val_accuracy: 0.5958\n",
      "Epoch 338/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7804 - accuracy: 0.6650 - val_loss: 1.2878 - val_accuracy: 0.5824\n",
      "Epoch 339/1000\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.7608 - accuracy: 0.6774 - val_loss: 1.2711 - val_accuracy: 0.5862\n",
      "Epoch 340/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7631 - accuracy: 0.6733 - val_loss: 1.2505 - val_accuracy: 0.6226\n",
      "Epoch 341/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7487 - accuracy: 0.6675 - val_loss: 1.2879 - val_accuracy: 0.5900\n",
      "Epoch 342/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7629 - accuracy: 0.6782 - val_loss: 1.2361 - val_accuracy: 0.6073\n",
      "Epoch 343/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7788 - accuracy: 0.6658 - val_loss: 1.2899 - val_accuracy: 0.6149\n",
      "Epoch 344/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7675 - accuracy: 0.6634 - val_loss: 1.2440 - val_accuracy: 0.5843\n",
      "Epoch 345/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7846 - accuracy: 0.6601 - val_loss: 1.2380 - val_accuracy: 0.5862\n",
      "Epoch 346/1000\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7747 - accuracy: 0.6584 - val_loss: 1.2826 - val_accuracy: 0.6149\n",
      "Epoch 347/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7888 - accuracy: 0.6634 - val_loss: 1.2206 - val_accuracy: 0.6379\n",
      "Epoch 348/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7307 - accuracy: 0.6897 - val_loss: 1.2334 - val_accuracy: 0.6456\n",
      "Epoch 349/1000\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7458 - accuracy: 0.6782 - val_loss: 1.2157 - val_accuracy: 0.6130\n",
      "Epoch 350/1000\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7320 - accuracy: 0.6979 - val_loss: 1.3067 - val_accuracy: 0.5651\n",
      "Epoch 351/1000\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7757 - accuracy: 0.6807 - val_loss: 1.2217 - val_accuracy: 0.6379\n",
      "Validation Accuracy: 60.536%\n"
     ]
    }
   ],
   "source": [
    "# # Training on validation data (Experimental)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# y_val = Data_val.Emotion\n",
    "# X_val = pd.DataFrame(Data_val.drop(['Emotion', 'User'], axis = 1))\n",
    "\n",
    "# X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(X_val, y_val, test_size = 0.3, random_state = 123)\n",
    "\n",
    "\n",
    "# #Trying adam optimizer\n",
    "# modelVal = initModelGRU(X.shape[1], 7, 'softmax')\n",
    "# modelVal.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# historyVal = modelVal.fit(\n",
    "#     X_train_val,\n",
    "#     y_train_val,\n",
    "#     validation_data = (X_test_val, y_test_val),\n",
    "#     epochs=1000,\n",
    "#     callbacks=[\n",
    "#         tf.keras.callbacks.EarlyStopping(\n",
    "#             monitor='val_loss',\n",
    "#             patience=100,\n",
    "#             restore_best_weights=True\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# #Result of adam optimizer on validation data\n",
    "# model_acc = modelVal.evaluate(X_test_val, y_test_val, verbose=0)[1]\n",
    "# print(\"Validation Accuracy: {:.3f}%\".format(model_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cd3b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the accuracy curve for validation set\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(historyVal.history['val_accuracy'], color='r', label=\"Accuracy\")\n",
    "\n",
    "# plt.title(\"Val accuracy\")\n",
    "# plt.xlabel(\"Number of Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b225588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict = model.predict(X_test)[0]\n",
    "# predict = [np.argmax(pre) for pre in predict]\n",
    "# print(predict)\n",
    "# y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e5e15a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
